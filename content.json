{"pages":[{"title":"Categories","permalink":"http://smanist.github.io/categories/index.html","text":""},{"title":"","permalink":"http://smanist.github.io/about/index.html","text":"Hi, I am an aerospace engineer as well as a programmer. You can find links to my professional profile on the right column."},{"title":"Tagcloud","permalink":"http://smanist.github.io/tags/index.html","text":""}],"posts":[{"title":"Writing plan","permalink":"http://smanist.github.io/2242/01/01/Writing-Plan/","text":"Some topics I plan to write about (or never). Interesting Topics Development of modern university. The precursor appears to be cathedral school with faculty of arts. Maybe start with examining the early universities and colleges in the US, such as UPenn. Another start could be the Humboldt University of Berlin, which appears to have the first modern university system. A third start is the Bologna University, which is among the earliest universities. Parkinson&#x2019;s law and Peter&#x2019;s principle Kakeya set A Kakeya set, or Besicovitch set, is a set of points in Euclidean space which contains a unit line segment in every direction. Besicovitch found a surprising result that the minimum area, or measure, of the set is zero. A Kakeya needle set is a set in the plane with a stronger property, that a unit line segment can be rotated continuously. A yet surprising result is that the measure of such set can be arbitrarily small. Ref1, Ref2 Miura-ori and Theorema Egregium How to fold an A4 paper to reduce its area by an order of magnitude, while still easy to unfold? Miura folding is one answer. An introductory article is found here. More interesting applications are found here, where a scholar developed some computational origami software. Concerning computational origami, there is another guy that must be mentioned: Robert Lang. He was a NASA physicist, but later became an origami artist. Now he is recognized as one of the leading theorists of the mathematics of origami and has developed ways to algorithmetize the design process for origami. Another seemingly vague connection to origami is the shell structure. This starts with Theorema Egregium, or Remarkable Theorem. It is stated by Carl Friedrich Gauss that If a curved surface is developed upon any other surface whatever, the measure of curvature in each point remains unchanged. Essentially, the so-called Gaussian curvature is an intrinsic invariant of a surface. The curvature does not change if the surface deforms by bending only and not stretching. The implication of this result in engineering is the application of shell structure - thin and light, but strong. A flat paper can be folded into complex curved surfaces using generalized Miura-ori. Such folded structure is orders of magnitude stronger than the flat paper. SPRITE SPRITE for Sample Parameter Reconstruction via Iterative TEchniques. It is an awesome tool (pre-print) that enables the examination of statistical results in research papers that do not include the raw data - are they made up or fudged? One case found by the authors of SPRITE is related to the carrots. Game of life on manifold Conway&#x2019;s Game of Life is initially defined on a 2D flat discrete grid. However, nothing prevents it from generalization to grids of higher dimensions, or continous Euclidean spaces, or any proper metric spaces. A good example is found here and here. NSF Survey of Science &amp; Engineering Doctorates It turns out NSF has been surveying the doctorates earned each year in the US. It would be fun to dig into the data and explore. Optimal control for frying steaks A tasty steak is made by precisely controlling the temperature distribution of the steak on the frying pan. The evolution of the temperature in the steak is governed by the heat conduction equation. The control variables are the duration and magnitude of the heat flux from the frying pan. The question is, is it possible to achieve the given temperature response in the steak using an optimal control approach? More Serious Topics DMD and Higher-Order DMD Dynamic Mode Decomposition is a useful tool for post-processing spatiotemporal data (resulting from generally nonlinear dynamics) as an expansion of spatial modes times exponentials in the time variable, which exhibit generally nonzero growth rates. It has extentions like Higher Order Dynamic Mode Decomposition. Polynomial rational interpolation and iSINDy Polynomial curve fitting is one of the simplest tools for data modeling. However, it suffers from various issues, such as discussed here. A better model would be polynomial rationals. But its mathematical properties are not as clear as polynomials - some materials are found here. Also, practical algorithms are developed only recently, i.e.&#xA0;the Barycentric interpolation. The iSINDy method is the implicit version of the SINDy (Sparse Identification of Nonlinear Dynamics) method. As their names imply, the methods are used to infer the analytical form of a nonlinear dynamical system from the samples of its response. The sparsity ensures that the analytical form is as simple as possible. In SINDy, the system equation is represented by a linear combination of nonlinear features, e.g.&#xA0;polynomials, that are constructed from the state variables. In iSINDy, the system equation is represented by a rational fraction, similar to Barycentric interpolation. However, the difference is that in iSINDy the number of terms in the rational fraction is minimized, while in the latter all the possible terms might be involved. Multi-fidelity surrogate Some surrogate models take in data from both high- and low-fidelity models. Usually such a &#x201C;multi-fidelity&#x201D; model is hierarchical, e.g.&#xA0;a fusion of multiple separate surrogates. This paper proposed a unified formulation for multi-fidelity surrogate, which seems to have some values in applications like surrogate-based optimization. Gaussian process regression with discrete variables There is an approach based on latent variables that makes the discrete variables smooth. An application of this approach found here shows that it is better than some conventional approaches. Non-Intrusive Polynomial Chaos Expansion Polynomial chaos expansion (PCE) is one approach for uncertainty quantification. However, PCE is intrusive as it requires the modification of the deterministic version of the analysis code. One way to mitigate this problem is the non-intrusive version of PCE, as discussed in this paper. One example of application is found here. Methodology for uncertainty quantification Nowadays people expect not only high-fidelity results from CFD-based simulation, but also its uncertainty, which may be quantified through rigorous verification, validation and uncertainty quantification (VVUQ) procedures. One such procedural framework is proposed by Roy and Oberkampf. In general, a solution for UQ is provided by the DAKOTA software from the Sandia National Lab. One application of Dakota is found here. Sobol sampling v.s. Latin hypercube sampling Two sampling methods for Gaussian process regression. Also Halton sampling. Non-Intrusive Least Squares Shadowing Optimization of a chaotic system can be challenging, because the gradients w.r.t. to the design variables computed naively could be &#x201C;noisy&#x201D;. This can be mitigated by the shadowing approach, which generates smooth gradients suitable for optimization. A non-intrusive version of the shadowing approach has been developed in this paper. OpenMDAO The OpenMDAO package has evolved in the recent years into a quite comprehensive framework for large-scale multi-disciplinary optimization problems. Besides conventional aerostructural optimization, it has encompassed some interesting capabilities, e.g. optimal control and topology optimization. It seems Bayesian optimization is supported too, at least in some of the versions and some branches."},{"title":"IFASD 2019 Digest","permalink":"http://smanist.github.io/2019/07/02/IFASD_2019_digest/","text":"What I found interesting. IFASD stands for The International Forum on Aeroelasticity and Structural Dynamics. It was held during June 10-13 in Savannah, Georgia. The bracketed number is the paper number (if applicable). Aeroelastic Design and Optimization Passive aeroelastic tailoring of high aspect ratio wings By Karen Taminger. Three approaches were highlighted that optimize the stiffness distribution of a wing to improve its aeroelastic performance: Curvilinear Spars and Ribs (SpaRibs), e.g. Locatelli2011, Zhao2019 Structural topology optimization Tow-steered composite wings Sizing and topology design of an aeroelastic wingbox under uncertainty By Bret K. Stanford (058) A neat work on optimization under uncertainty. A two-level approach is employed. On the higher level, a non-gradient approach is employed to explore different wingbox topologies. The sizing of the wingbox topology is done by a gradient approach on the lower level. Uncertainties are introduced to the safety factors for the stress and buckling constraints, and modelled using the non-intrusive polynomial chaos expansion method. The sobol indices are used to explain the results. Aeroelastic prediction workshop, No. 3 This will be discussed separately. Reduced Order Modeling Self adaptive POD based ROM 3D aeroelastic simulations By Ruben Moreno-Ramos (024) Switch between CFD and ROM solvers during the aeroelastic simulation based on an error estimation. The CFD stage is used to generate data that updates POD modes in the projection-based ROM. Model order reduction for coupled nonlinear aeroelastic-flight mechanics of very flexible aircraft By Carlos E.S. Cesnik (095) The goal is to reduce the coupled system of flight dynamics and aeroelastic model to a level that can be used for control-oriented applications for the flight envelope. This is achieved by combining the techniques of piecewise linear basis, local basis interpolation, and balanced truncation, where the composition of local basis is achieved using a weighted sum approach. Aeroelastic loads predictions using CFD-based reduced order models By Philipp Bekemeyer (105) An interesting POD approach is used. The snapshots for POD are not only the aerodynamic loading, but concatenated vectors of aerodynamic loading and structural displacements. This approach requires very few samples and handles the static aeroelastic trimming problem well. The code implementation is based on the SMARTy toolbox. A noteworthy method in SMARTy is the Isomap with interpolation approach. Modal rotations: A modal-based method for large structural deformations By Ariel Drachinsky (135) A modal rotation method (MRM) is developed for the static analysis of slender structures accounting for large deformations. The modes are obtained from linear modal analysis as usual. However, the modes are not defined by displacements, but by curvatures. The curvature-based formulation enables a linearized evaluation of the bending rotation change based on nonlinear kinematics. Reduced order time spectral model for the ALE formulation of the compressible Navier-Stokes equations By Fabrizio Di Donfrancesco (134) The time spectral equations are projected on to a set of POD basis. However, the issue is that generating the basis requires the unsteady simulation, but the purpose of time spectral method is usually to avoid the computationally expensive unsteady simulation. Flutter Analysis Flutter sensitivity analysis for wing planform optimization By Francesco Torrigiani (029) The unsteady aerodynamic analysis is carried out with the boundary element method by Morino, which accounts for generic 3D body shapes. Analysis of light dynamic stall using dynamic mode decomposition By Wrik Mallik (036). An application of DMD. A state-space model for loads analysis based on tangential interpolation By David Martin (066) The Loewner rational interpolation is employed to develop a state-space model for the aerodynamics that Has complex poles - so that it works for transonic flow. Does not need Hankel metrix for more efficient computation. Works for delayed input (e.g.&#xA0;gust) and singularity (e.g.&#xA0;rigid modes that introduces infinite eigenvalues). Describes distributed aerodynamic loading. A new flutter prediction algorithm to avoid p-k method shortcomings By Ludovic Colo (072) For a nonlinear eigenvalue problem like flutter analysis, the conventional p-k method may fail when the eigen modes merge. This study develops a new block Newton algorithm based on the invariant pairs theory (e.g. here and here). Dassault Aviation has systematically employed a hybrid p-k and block Newton methods for automated, robust, and efficient flutter analysis. Structural damping models for passive aeroelastic control By Marco Eugeni (085) Three damping models suitable for finite-element-based aeroelastic analysis are compared: the viscous model, the hysteretic model, and a generalized Biot model. Mechanisms of transonic single degree of freedom flutter of a laminar airfoil By Marc Braune (132) An energy transfer analysis is used to connect the effects of boundary layer transition, shock movement, and shock-boundary layer interaction to the aeroelastic instability and the LCO amplitude. It appears that the LCO is not due to a pure 1-DOF flutter mechanism, but introduced by the combination of the bending and heave motion. Flutter mechanisms characterization using distributed aeroelastic energy analysis By Michael Iovnovich (016) The goal is to systematically classify and understand the flutter mechanisms of an aircraft with many jet store configurations. The concept of power per flutter cycle (PPC) is introduced and the PPC distribution indicates a quantitative approach to identifying the flutter mechanisms. Panel Flutter Flutter and limit cycle oscillations of a cantilevered plate in supersonic.hypersonic flow By Kevin A. McHugh (017) Extended the piston theory to account for the large slope effect due to the cantilevered configuration. However, the boundary layer effect is not included. The plan is to correlate the theoretical results with experiments. Computational study for the design of a hypersonic panel flutter experiment By Maxim Freydin (138) A theoretical analysis of clamped panel flutter response, including the geometrical nonlinearity, non-ideally clamped boundary stiffness, distributed static pressure differential across the panel, and a temperature differential between the panel and its support. Flutter and LCO predictions are done by a linear eigenvalue method and direct time-marching solution in modal coordinates. Experiments are panned in the University of Southern Queensland. The panel is extremely thin, around 0.1 mm, and the experiment will run for approximately 200 ms. Aerospace Systems Aeroelastic role in the road to a fully automated refuelling system By J. Barrera Rodr&#xED;guez (048) This is an interesting paper describing the development of a real Automated Air-to-Air Refuelling (A3R) system in the industry. The system consists of an extensible mast with a &#x201C;ruddervator&#x201D; connected to the aircraft with a roll/pitch joint. Modeling difficulties include the elastic response of the mast, variable mass and the boundary conditions (free or attached to another aircraft). The structural response of the mast is modelled using the finite element method and the aerodynamic force of the ruddervator is modelled using the doublet lattice method. The other unmodelled effects, which may be nonlinear, include gravity, drag of mast, etc. These effects are identified from the flight data and incorporated into the model via a convolutional nonlinear forcing term. Flight mechanical analysis and test of unmanned multi-body aircraft By An Chao (083) Learned about the concept of Multi-body Aircraft (MBA) as a alternative to the aircraft with ultra-high aspect ratio. The MBA configuration alleviates the wing loading and its modeling does not require the nonlinear aeroelastic analysis. However, the MBA has its own instability modes that need to be mitigated."},{"title":"Trying Out RNN Regressor - Part I","permalink":"http://smanist.github.io/2019/07/01/Trying-out-RNN-regressor-part-1/","text":"I am almost new to this field. Still learning. Introduction In the field of engineering, frequently we need to do system identification (SI), i.e.&#xA0;to infer the mathematical model of a dynamical system based on a set of time series data. A classical problem is the SI of a linear system 1, h&#x2D9;=Ah+Bxy=Ch+Dx\\displaystyle \\begin{aligned} \\dot{\\mathbf{h}}&amp;= {\\mathbf{A}}{\\mathbf{h}}+ {\\mathbf{B}}{\\mathbf{x}}\\\\ {\\mathbf{y}}&amp;= {\\mathbf{C}}{\\mathbf{h}}+ {\\mathbf{D}}{\\mathbf{x}}\\end{aligned} &#x200B;&#x200B;h&#x200B;&#x2D9;&#x200B;&#x200B;&#x200B;y&#x200B;&#x200B;&#x200B;=Ah+Bx&#x200B;=Ch+Dx&#x200B;&#x200B; Given input x{\\mathbf{x}}x and output y{\\mathbf{y}}y, how does one determine the system matrices A,B,C,D{\\mathbf{A}},{\\mathbf{B}},{\\mathbf{C}},{\\mathbf{D}}A,B,C,D? Note that the system states h{\\mathbf{h}}h are not directly observed in the time series data, i.e.&#xA0;they are hidden. Over the long history of SI, many successful methods and algorithms have been developed. Some model the hidden states explicitly and some do not. Some can handle nonlinear systems and some do not. I am not an expert in SI and not going to talk about these algorithms. In the machine learning community, it appears that people tend to reorganize and reformulate some old concepts into some &#x201C;new ideas&#x201D;. No offense. Indeed this is sometimes useful. In Hinton2013, several modeling methods for sequential data are divided into two categories: memoryless models and memoryful models. The memoryless models have limited memory window and the hidden state cannot be used efficiently. One example is the autoregressive model, which predicts the next term in a sequence from a fixed number of previous terms. Another example is the feed-forward neural nets, which generalize autoregressive models by using one or more layers of non-linear hidden units. The memoryful models infer the hidden state distribution at the cost of higher computational burden. One example is the linear systems algorithms that can be viewed as generative models with real-valued hidden states that cannot be observed directly. Another example is the hidden Markov models (HMM), which have a discrete one-of-N hidden state. In HMM, transitions between states are stochastic and controlled by a transition matrix. The outputs produced by a state are stochastic. The last example of the memoryful models is the recurrent neural network (RNN), the topic of this post. It updates the hidden state in a deterministic nonlinear way. Compared to the aformentioned models, the RNN has the following advantages: Distributed hidden state allows the efficient storage of information about the past. Non-linear dynamics allows the update of hidden state in complicated ways. No need to infer hidden state, whose evolution is purely deterministic. Parameters in the RNN, i.e.&#xA0;the weights, are shared, which makes the model compact. Mathematical Models of RNN Vanilla RNN This section is based on this. The RNN centers around the following equation that describes the evolution of the hidden state, ht=fW(ht&#x2212;1,xt)\\displaystyle {\\mathbf{h}}_t = {\\mathbf{f}}_W({\\mathbf{h}}_{t-1}, {\\mathbf{x}}_t) h&#x200B;t&#x200B;&#x200B;=f&#x200B;W&#x200B;&#x200B;(h&#x200B;t&#x2212;1&#x200B;&#x200B;,x&#x200B;t&#x200B;&#x200B;) where fW{\\mathbf{f}}_Wf&#x200B;W&#x200B;&#x200B; is an activation function with weights W{\\mathbf{W}}W. The time steps ttt and t&#x2212;1t-1t&#x2212;1 makes the formula recurrent. The function fW{\\mathbf{f}}_Wf&#x200B;W&#x200B;&#x200B; and W{\\mathbf{W}}W may be shared between different layers/time steps. A vanilla RNN is ht=tanh(Whhht&#x2212;1+Wxhxt)yt=Whyht\\displaystyle \\begin{aligned} {\\mathbf{h}}_t &amp;= \\tanh({\\mathbf{W}}_{hh} {\\mathbf{h}}_{t-1} + {\\mathbf{W}}_{xh} {\\mathbf{x}}_t) \\\\ {\\mathbf{y}}_t &amp;= {\\mathbf{W}}_{hy} {\\mathbf{h}}_t \\end{aligned} &#x200B;h&#x200B;t&#x200B;&#x200B;&#x200B;y&#x200B;t&#x200B;&#x200B;&#x200B;&#x200B;&#x200B;=tanh(W&#x200B;hh&#x200B;&#x200B;h&#x200B;t&#x2212;1&#x200B;&#x200B;+W&#x200B;xh&#x200B;&#x200B;x&#x200B;t&#x200B;&#x200B;)&#x200B;=W&#x200B;hy&#x200B;&#x200B;h&#x200B;t&#x200B;&#x200B;&#x200B;&#x200B; It looks very much like the linear system discussed above, except that it has a nonlinear state equation. There are multiple types of RNNs: one-to-one, one-to-many, many-to-one, many-to-many, etc. In other words, the inputs xt{\\mathbf{x}}_tx&#x200B;t&#x200B;&#x200B; and outputs yt{\\mathbf{y}}_ty&#x200B;t&#x200B;&#x200B; are not necessarily nonzero. For example, an RNN is many-to-one when all of its inputs are assumed to be nonzero and only one output is expected (e.g.&#xA0;at the end) - this could be the case for a sequence classification problem. Gradient Problem There is an infamous issue with RNN: the gradient problem, which prevented the effective training of RNNs for a period of time. The training of an RNN requires a proper definition of the error, or the scalar loss function EEE, E=&#x2211;t=1&#x2026;sEt(yt,y&#xAF;t)\\displaystyle E = \\sum_{t=1\\ldots s} E_t({\\mathbf{y}}_t, {\\bar{\\mathbf{y}}}_t) E=&#x200B;t=1&#x2026;s&#x200B;&#x2211;&#x200B;&#x200B;E&#x200B;t&#x200B;&#x200B;(y&#x200B;t&#x200B;&#x200B;,&#x200B;y&#x200B;&#xAF;&#x200B;&#x200B;&#x200B;t&#x200B;&#x200B;) where sss time steps are assumed, and y&#xAF;t{\\bar{\\mathbf{y}}}_t&#x200B;y&#x200B;&#xAF;&#x200B;&#x200B;&#x200B;t&#x200B;&#x200B; represent the ground truth. The weights W{\\mathbf{W}}W are computed by the gradient descent method, where the gradient is computed from the back propagation (BP) of the error. In other words, one needs to obtain the derivative of EEE w.r.t. W{\\mathbf{W}}W via the chain rule, &#x2202;E&#x2202;W=&#x2211;t=1,&#x2026;,s&#x2202;Et&#x2202;W\\displaystyle {\\frac{\\partial E}{\\partial {\\mathbf{W}}}} = \\sum_{t=1,\\ldots,s} {\\frac{\\partial E_t}{\\partial {\\mathbf{W}}}} &#x200B;&#x2202;W&#x200B;&#x200B;&#x2202;E&#x200B;&#x200B;=&#x200B;t=1,&#x2026;,s&#x200B;&#x2211;&#x200B;&#x200B;&#x200B;&#x2202;W&#x200B;&#x200B;&#x2202;E&#x200B;t&#x200B;&#x200B;&#x200B;&#x200B; where &#x2202;Et&#x2202;W=&#x2202;Et&#x2202;yt&#x2202;yt&#x2202;ht&#x2202;ht&#x2202;W\\displaystyle {\\frac{\\partial E_t}{\\partial {\\mathbf{W}}}} = {\\frac{\\partial E_t}{\\partial {\\mathbf{y}}_t}} {\\frac{\\partial {\\mathbf{y}}_t}{\\partial {\\mathbf{h}}_t}} {\\frac{\\partial {\\mathbf{h}}_t}{\\partial {\\mathbf{W}}}} &#x200B;&#x2202;W&#x200B;&#x200B;&#x2202;E&#x200B;t&#x200B;&#x200B;&#x200B;&#x200B;=&#x200B;&#x2202;y&#x200B;t&#x200B;&#x200B;&#x200B;&#x200B;&#x2202;E&#x200B;t&#x200B;&#x200B;&#x200B;&#x200B;&#x200B;&#x2202;h&#x200B;t&#x200B;&#x200B;&#x200B;&#x200B;&#x2202;y&#x200B;t&#x200B;&#x200B;&#x200B;&#x200B;&#x200B;&#x2202;W&#x200B;&#x200B;&#x2202;h&#x200B;t&#x200B;&#x200B;&#x200B;&#x200B; Now, focus on the weights for h{\\mathbf{h}}h, i.e. Whh{\\mathbf{W}}_{hh}W&#x200B;hh&#x200B;&#x200B;, which will be written as W{\\mathbf{W}}W for simplicity in the following. There is a &#x201C;double dependency&#x201D; in the gradient &#x2202;ht&#x2202;W{\\frac{\\partial {\\mathbf{h}}_t}{\\partial {\\mathbf{W}}}}&#x200B;&#x2202;W&#x200B;&#x200B;&#x2202;h&#x200B;t&#x200B;&#x200B;&#x200B;&#x200B;: (1) ht{\\mathbf{h}}_th&#x200B;t&#x200B;&#x200B; itself depends on all the past states; (2) a past state depends on the states prior to that state, too. Mathematically, &#x2202;ht&#x2202;W=&#x2211;k=1,&#x2026;,t&#x2202;ht&#x2202;hk&#x2202;hk&#x2202;W&#x2202;ht&#x2202;hk=&#x220F;i=k+1,&#x2026;,t&#x2202;hi&#x2202;hi&#x2212;1\\displaystyle \\begin{aligned} {\\frac{\\partial {\\mathbf{h}}_t}{\\partial {\\mathbf{W}}}} &amp;= \\sum_{k=1,\\ldots,t} {\\frac{\\partial {\\mathbf{h}}_t}{\\partial {\\mathbf{h}}_k}} {\\frac{\\partial {\\mathbf{h}}_k}{\\partial {\\mathbf{W}}}} \\\\ {\\frac{\\partial {\\mathbf{h}}_t}{\\partial {\\mathbf{h}}_k}} &amp;= \\prod_{i=k+1,\\ldots,t} {\\frac{\\partial {\\mathbf{h}}_i}{\\partial {\\mathbf{h}}_{i-1}}} \\end{aligned} &#x200B;&#x200B;&#x2202;W&#x200B;&#x200B;&#x2202;h&#x200B;t&#x200B;&#x200B;&#x200B;&#x200B;&#x200B;&#x200B;&#x2202;h&#x200B;k&#x200B;&#x200B;&#x200B;&#x200B;&#x2202;h&#x200B;t&#x200B;&#x200B;&#x200B;&#x200B;&#x200B;&#x200B;&#x200B;=&#x200B;k=1,&#x2026;,t&#x200B;&#x2211;&#x200B;&#x200B;&#x200B;&#x2202;h&#x200B;k&#x200B;&#x200B;&#x200B;&#x200B;&#x2202;h&#x200B;t&#x200B;&#x200B;&#x200B;&#x200B;&#x200B;&#x2202;W&#x200B;&#x200B;&#x2202;h&#x200B;k&#x200B;&#x200B;&#x200B;&#x200B;&#x200B;=&#x200B;i=k+1,&#x2026;,t&#x200B;&#x220F;&#x200B;&#x200B;&#x200B;&#x2202;h&#x200B;i&#x2212;1&#x200B;&#x200B;&#x200B;&#x200B;&#x2202;h&#x200B;i&#x200B;&#x200B;&#x200B;&#x200B;&#x200B;&#x200B; where &#x2202;hi&#x2202;hi&#x2212;1=&#x39B;[fW&#x2032;]W\\displaystyle {\\frac{\\partial {\\mathbf{h}}_i}{\\partial {\\mathbf{h}}_{i-1}}} = \\Lambda[{\\mathbf{f}}_W&apos;]{\\mathbf{W}}&#x200B;&#x2202;h&#x200B;i&#x2212;1&#x200B;&#x200B;&#x200B;&#x200B;&#x2202;h&#x200B;i&#x200B;&#x200B;&#x200B;&#x200B;=&#x39B;[f&#x200B;W&#x200B;&#x2032;&#x200B;&#x200B;]W where &#x39B;\\Lambda&#x39B; makes the vector fW&#x2032;{\\mathbf{f}}_W&apos;f&#x200B;W&#x200B;&#x2032;&#x200B;&#x200B; a diagonal matrix. The gradient problem comes from the product in &#x2202;ht&#x2202;hk{\\frac{\\partial {\\mathbf{h}}_t}{\\partial {\\mathbf{h}}_k}}&#x200B;&#x2202;h&#x200B;k&#x200B;&#x200B;&#x200B;&#x200B;&#x2202;h&#x200B;t&#x200B;&#x200B;&#x200B;&#x200B;. For each term of the product &#x2225;&#x2202;ht&#x2202;hk&#x2225;&#x2264;&#x2225;&#x39B;[fW&#x2032;]&#x2225;&#x2225;W&#x2225;&#x2264;&#x3B3;f&#x3B3;W\\displaystyle \\left\\lVert {\\frac{\\partial {\\mathbf{h}}_t}{\\partial {\\mathbf{h}}_k}} \\right\\rVert \\le \\lVert\\Lambda[{\\mathbf{f}}_W&apos;]\\rVert \\lVert {\\mathbf{W}}\\rVert \\le \\gamma_f \\gamma_W &#x200B;&#x2225;&#x200B;&#x2225;&#x200B;&#x2225;&#x200B;&#x2225;&#x200B;&#x200B;&#x200B;&#x2202;h&#x200B;k&#x200B;&#x200B;&#x200B;&#x200B;&#x2202;h&#x200B;t&#x200B;&#x200B;&#x200B;&#x200B;&#x200B;&#x2225;&#x200B;&#x2225;&#x200B;&#x2225;&#x200B;&#x2225;&#x200B;&#x200B;&#x2264;&#x2225;&#x39B;[f&#x200B;W&#x200B;&#x2032;&#x200B;&#x200B;]&#x2225;&#x2225;W&#x2225;&#x2264;&#x3B3;&#x200B;f&#x200B;&#x200B;&#x3B3;&#x200B;W&#x200B;&#x200B; where &#x3B3;f\\gamma_f&#x3B3;&#x200B;f&#x200B;&#x200B; and &#x3B3;W\\gamma_W&#x3B3;&#x200B;W&#x200B;&#x200B; are the maximum singular values of &#x39B;[fW&#x2032;]\\Lambda[{\\mathbf{f}}_W&apos;]&#x39B;[f&#x200B;W&#x200B;&#x2032;&#x200B;&#x200B;] and W{\\mathbf{W}}W, respectively. For the product &#x2225;&#x2202;ht&#x2202;hk&#x2225;&#x2264;(&#x3B3;f&#x3B3;W)t&#x2212;k\\displaystyle \\left\\lVert {\\frac{\\partial {\\mathbf{h}}_t}{\\partial {\\mathbf{h}}_k}} \\right\\rVert \\le (\\gamma_f \\gamma_W)^{t-k} &#x200B;&#x2225;&#x200B;&#x2225;&#x200B;&#x2225;&#x200B;&#x2225;&#x200B;&#x200B;&#x200B;&#x2202;h&#x200B;k&#x200B;&#x200B;&#x200B;&#x200B;&#x2202;h&#x200B;t&#x200B;&#x200B;&#x200B;&#x200B;&#x200B;&#x2225;&#x200B;&#x2225;&#x200B;&#x2225;&#x200B;&#x2225;&#x200B;&#x200B;&#x2264;(&#x3B3;&#x200B;f&#x200B;&#x200B;&#x3B3;&#x200B;W&#x200B;&#x200B;)&#x200B;t&#x2212;k&#x200B;&#x200B; When fW{\\mathbf{f}}_Wf&#x200B;W&#x200B;&#x200B; is a function like tanh\\tanhtanh, &#x3B3;f\\gamma_f&#x3B3;&#x200B;f&#x200B;&#x200B; would be close to zero as the input moves away from zero. As for W{\\mathbf{W}}W, &#x3B3;W\\gamma_W&#x3B3;&#x200B;W&#x200B;&#x200B; is probably either &lt;1&lt;1&lt;1 or &gt;1&gt;1&gt;1. Therefore, a sufficiently large t&#x2212;kt-kt&#x2212;k, i.e.&#xA0;time span of dependency, can cause two issues for the BP, Vanishing gradients: &#x2225;&#x2202;ht&#x2202;hk&#x2225;&#x2192;0\\left\\lVert {\\frac{\\partial {\\mathbf{h}}_t}{\\partial {\\mathbf{h}}_k}} \\right\\rVert \\rightarrow 0&#x200B;&#x2225;&#x200B;&#x2225;&#x200B;&#x2225;&#x200B;&#x200B;&#x200B;&#x2202;h&#x200B;k&#x200B;&#x200B;&#x200B;&#x200B;&#x2202;h&#x200B;t&#x200B;&#x200B;&#x200B;&#x200B;&#x200B;&#x2225;&#x200B;&#x2225;&#x200B;&#x2225;&#x200B;&#x200B;&#x2192;0, making &#x2202;Et&#x2202;W&#x223C;0{\\frac{\\partial E_t}{\\partial {\\mathbf{W}}}}\\sim 0&#x200B;&#x2202;W&#x200B;&#x200B;&#x2202;E&#x200B;t&#x200B;&#x200B;&#x200B;&#x200B;&#x223C;0. In other words, the past states cannot be practically involved in BP. Exploding gradients: &#x2225;&#x2202;ht&#x2202;hk&#x2225;&#x226B;1\\left\\lVert {\\frac{\\partial {\\mathbf{h}}_t}{\\partial {\\mathbf{h}}_k}} \\right\\rVert \\gg 1&#x200B;&#x2225;&#x200B;&#x2225;&#x200B;&#x2225;&#x200B;&#x200B;&#x200B;&#x2202;h&#x200B;k&#x200B;&#x200B;&#x200B;&#x200B;&#x2202;h&#x200B;t&#x200B;&#x200B;&#x200B;&#x200B;&#x200B;&#x2225;&#x200B;&#x2225;&#x200B;&#x2225;&#x200B;&#x200B;&#x226B;1, making &#x2202;Et&#x2202;W&#x226B;1{\\frac{\\partial E_t}{\\partial {\\mathbf{W}}}}\\gg 1&#x200B;&#x2202;W&#x200B;&#x200B;&#x2202;E&#x200B;t&#x200B;&#x200B;&#x200B;&#x200B;&#x226B;1. In other words, the BP may experience a computational overflow. Another way to see the gradient problem in the vanilla RNN is via the propagation of the variation/error of the hidden state h{\\mathbf{h}}h. This way is somewhat hand-waving but more concise. The error of ht{\\mathbf{h}}_th&#x200B;t&#x200B;&#x200B; is, &#x3B4;ht=fW&#x2032;&#x2299;(&#x3B4;Wht&#x2212;1+W&#x3B4;ht&#x2212;1)\\displaystyle \\delta {\\mathbf{h}}_t = {\\mathbf{f}}_W&apos; \\odot (\\delta {\\mathbf{W}}{\\mathbf{h}}_{t-1} + {\\mathbf{W}}\\delta {\\mathbf{h}}_{t-1}) &#x3B4;h&#x200B;t&#x200B;&#x200B;=f&#x200B;W&#x200B;&#x2032;&#x200B;&#x200B;&#x2299;(&#x3B4;Wh&#x200B;t&#x2212;1&#x200B;&#x200B;+W&#x3B4;h&#x200B;t&#x2212;1&#x200B;&#x200B;) where &#x2299;\\odot&#x2299; is element-wise vector product and the variation associated with the input is ignored. The second term in the bracket represents the contribution of the error of the previous states to the error of the current state, &#x3B4;ht&#x223C;(fW&#x2032;&#x2299;W)k&#x3B4;ht&#x2212;k\\displaystyle \\delta {\\mathbf{h}}_t \\sim ({\\mathbf{f}}_W&apos;\\odot {\\mathbf{W}})^k \\delta {\\mathbf{h}}_{t-k} &#x3B4;h&#x200B;t&#x200B;&#x200B;&#x223C;(f&#x200B;W&#x200B;&#x2032;&#x200B;&#x200B;&#x2299;W)&#x200B;k&#x200B;&#x200B;&#x3B4;h&#x200B;t&#x2212;k&#x200B;&#x200B; For situations discussed in the previous paragraph, the factor (fW&#x2032;&#x2299;W)k({\\mathbf{f}}_W&apos;\\odot {\\mathbf{W}})^k(f&#x200B;W&#x200B;&#x2032;&#x200B;&#x200B;&#x2299;W)&#x200B;k&#x200B;&#x200B; can be (1) vanishing, so that &#x3B4;ht&#x2212;k\\delta{\\mathbf{h}}_{t-k}&#x3B4;h&#x200B;t&#x2212;k&#x200B;&#x200B; almost does not contribute to &#x3B4;ht\\delta{\\mathbf{h}}_t&#x3B4;h&#x200B;t&#x200B;&#x200B;; (2) exploding, so that the contribution of &#x3B4;ht&#x2212;k\\delta{\\mathbf{h}}_{t-k}&#x3B4;h&#x200B;t&#x2212;k&#x200B;&#x200B; overwhelms the contributions of the other states. The issue of vanishing and exploding gradients does not mean the RNN model is impractical, but rather means that the gradient descent becomes increasingly inefficient when the temporal span of the dependencies increases. There are some fixes to circumvent the gradient issue while retaining the vanilla RNN structure, For vanishing gradients, one can perform a proper initialization of the weights, and incorporate a more well-behaved activation function, such as the rectified linear unit (ReLU): f(x)=max(0,x)f(x)=\\max(0,x)f(x)=max(0,x) For exploding gradient, one can do a clipping trick with a threshold TTT for the gradient &#x2207;\\nabla&#x2207;, &#x2207;&#x2032;=T&#x2225;&#x2207;&#x2225;2&#x2207;,if&#x2225;&#x2207;&#x2225;2&gt;T\\displaystyle \\nabla&apos; = \\frac{T}{\\lVert\\nabla\\rVert^2}\\nabla,\\quad \\mathrm{if}\\quad \\lVert\\nabla\\rVert^2 &gt; T &#x2207;&#x200B;&#x2032;&#x200B;&#x200B;=&#x200B;&#x2225;&#x2207;&#x2225;&#x200B;2&#x200B;&#x200B;&#x200B;&#x200B;T&#x200B;&#x200B;&#x2207;,if&#x2225;&#x2207;&#x2225;&#x200B;2&#x200B;&#x200B;&gt;T Long Short Term Memory A more systematic solution to the vanishing gradient problem is the Long Short Term Memory (LSTM) model (Hochreiter1997) 2. It introduces a &#x201C;memory cell&#x201D; that enables the storage and access of information over long periods of time. The state equation for LSTM is now significantly expanded from the vanilla RNN, it=&#x3C3;(Whiht&#x2212;1+Wxixt+bi)ft=&#x3C3;(Whfht&#x2212;1+Wxfxt+bf)ot=&#x3C3;(Whoht&#x2212;1+Wxoxt+bo)gt=tanh(Whght&#x2212;1+Wxgxt+bg)ct=ft&#x2299;ct&#x2212;1+it&#x2299;gtht=ot&#x2299;tanh(ct)\\displaystyle \\begin{array}{rl} {\\mathbf{i}}_t &amp;= \\sigma({\\mathbf{W}}_{hi} {\\mathbf{h}}_{t-1} + {\\mathbf{W}}_{xi} {\\mathbf{x}}_t + {\\mathbf{b}}_i) \\\\ {\\mathbf{f}}_t &amp;= \\sigma({\\mathbf{W}}_{hf} {\\mathbf{h}}_{t-1} + {\\mathbf{W}}_{xf} {\\mathbf{x}}_t + {\\mathbf{b}}_f) \\\\ {\\mathbf{o}}_t &amp;= \\sigma({\\mathbf{W}}_{ho} {\\mathbf{h}}_{t-1} + {\\mathbf{W}}_{xo} {\\mathbf{x}}_t + {\\mathbf{b}}_o) \\\\ {\\mathbf{g}}_t &amp;= \\tanh( {\\mathbf{W}}_{hg} {\\mathbf{h}}_{t-1} + {\\mathbf{W}}_{xg} {\\mathbf{x}}_t + {\\mathbf{b}}_g) \\\\ {\\mathbf{c}}_t &amp;= {\\mathbf{f}}_t \\odot {\\mathbf{c}}_{t-1} + {\\mathbf{i}}_t \\odot {\\mathbf{g}}_t \\\\ {\\mathbf{h}}_t &amp;= {\\mathbf{o}}_t \\odot \\tanh({\\mathbf{c}}_t) \\end{array} &#x200B;i&#x200B;t&#x200B;&#x200B;&#x200B;f&#x200B;t&#x200B;&#x200B;&#x200B;o&#x200B;t&#x200B;&#x200B;&#x200B;g&#x200B;t&#x200B;&#x200B;&#x200B;c&#x200B;t&#x200B;&#x200B;&#x200B;h&#x200B;t&#x200B;&#x200B;&#x200B;&#x200B;&#x200B;=&#x3C3;(W&#x200B;hi&#x200B;&#x200B;h&#x200B;t&#x2212;1&#x200B;&#x200B;+W&#x200B;xi&#x200B;&#x200B;x&#x200B;t&#x200B;&#x200B;+b&#x200B;i&#x200B;&#x200B;)&#x200B;=&#x3C3;(W&#x200B;hf&#x200B;&#x200B;h&#x200B;t&#x2212;1&#x200B;&#x200B;+W&#x200B;xf&#x200B;&#x200B;x&#x200B;t&#x200B;&#x200B;+b&#x200B;f&#x200B;&#x200B;)&#x200B;=&#x3C3;(W&#x200B;ho&#x200B;&#x200B;h&#x200B;t&#x2212;1&#x200B;&#x200B;+W&#x200B;xo&#x200B;&#x200B;x&#x200B;t&#x200B;&#x200B;+b&#x200B;o&#x200B;&#x200B;)&#x200B;=tanh(W&#x200B;hg&#x200B;&#x200B;h&#x200B;t&#x2212;1&#x200B;&#x200B;+W&#x200B;xg&#x200B;&#x200B;x&#x200B;t&#x200B;&#x200B;+b&#x200B;g&#x200B;&#x200B;)&#x200B;=f&#x200B;t&#x200B;&#x200B;&#x2299;c&#x200B;t&#x2212;1&#x200B;&#x200B;+i&#x200B;t&#x200B;&#x200B;&#x2299;g&#x200B;t&#x200B;&#x200B;&#x200B;=o&#x200B;t&#x200B;&#x200B;&#x2299;tanh(c&#x200B;t&#x200B;&#x200B;)&#x200B;&#x200B; where &#x3C3;\\sigma&#x3C3; is the sigmoid function acting as a switch and b{\\mathbf{b}}b is a constant offset vector. In the LSTM model, the current hidden state is no longer directly related to the current input and the previous hidden state. Rather, it is now an output from the memory cell ct{\\mathbf{c}}_tc&#x200B;t&#x200B;&#x200B;. The memory cell is essentially a weighted sum of the past memory and the current information. In other words, it determines: (1) whether to activate the information from past steps, and (2) whether to overwrite the memory with the information from the current step. Specifically, three new gates are introduced, Input gate: Scale input to cell (write) Output gate: Scale output from cell (read) Forget gate: Scale old cell values (reset) The effect of the gates is better seen via the variation approach w.r.t. the hidden states, the memory cells, and the weights Whg{\\mathbf{W}}_{hg}W&#x200B;hg&#x200B;&#x200B;. Note that Whg{\\mathbf{W}}_{hg}W&#x200B;hg&#x200B;&#x200B; corresponds to Whh{\\mathbf{W}}_{hh}W&#x200B;hh&#x200B;&#x200B; in the vanilla version and will again be written as W{\\mathbf{W}}W below for simplicity. Also note that, &#x3B4;(x&#x2299;y)=&#x3B4;x&#x2299;y+x&#x2299;&#x3B4;y\\displaystyle \\delta ({\\mathbf{x}}\\odot {\\mathbf{y}}) = \\delta {\\mathbf{x}}\\odot {\\mathbf{y}}+ {\\mathbf{x}}\\odot \\delta {\\mathbf{y}}&#x3B4;(x&#x2299;y)=&#x3B4;x&#x2299;y+x&#x2299;&#x3B4;y The variations of ct{\\mathbf{c}}_tc&#x200B;t&#x200B;&#x200B; and ht{\\mathbf{h}}_th&#x200B;t&#x200B;&#x200B; are, &#x3B4;ct=ft&#x2299;&#x3B4;ct&#x2212;1+W&#x203E;&#x3B4;ht&#x2212;1+it&#x2299;&#x3B4;Wht&#x2212;1&#x3B4;ht=&#x3B4;ot&#x2299;tanh(ct)+ot&#x2299;tanh&#x2032;&#x2299;&#x3B4;ct\\displaystyle \\begin{aligned} \\delta {\\mathbf{c}}_t &amp;= {\\mathbf{f}}_t\\odot\\delta {\\mathbf{c}}_{t-1} + {\\overline{\\mathbf{W}}}\\delta {\\mathbf{h}}_{t-1} + {\\mathbf{i}}_t\\odot\\delta {\\mathbf{W}}{\\mathbf{h}}_{t-1} \\\\ \\delta {\\mathbf{h}}_t &amp;= \\delta {\\mathbf{o}}_t \\odot \\tanh({\\mathbf{c}}_t) + {\\mathbf{o}}_t \\odot \\tanh&apos; \\odot \\delta {\\mathbf{c}}_t \\end{aligned} &#x200B;&#x3B4;c&#x200B;t&#x200B;&#x200B;&#x200B;&#x3B4;h&#x200B;t&#x200B;&#x200B;&#x200B;&#x200B;&#x200B;=f&#x200B;t&#x200B;&#x200B;&#x2299;&#x3B4;c&#x200B;t&#x2212;1&#x200B;&#x200B;+&#x200B;W&#x200B;&#x200B;&#x200B;&#x3B4;h&#x200B;t&#x2212;1&#x200B;&#x200B;+i&#x200B;t&#x200B;&#x200B;&#x2299;&#x3B4;Wh&#x200B;t&#x2212;1&#x200B;&#x200B;&#x200B;=&#x3B4;o&#x200B;t&#x200B;&#x200B;&#x2299;tanh(c&#x200B;t&#x200B;&#x200B;)+o&#x200B;t&#x200B;&#x200B;&#x2299;tanh&#x200B;&#x2032;&#x200B;&#x200B;&#x2299;&#x3B4;c&#x200B;t&#x200B;&#x200B;&#x200B;&#x200B; where W&#x203E;{\\overline{\\mathbf{W}}}&#x200B;W&#x200B;&#x200B;&#x200B; is a condensed term containing several weights, including Whg{\\mathbf{W}}_{hg}W&#x200B;hg&#x200B;&#x200B;. Note that Whg{\\mathbf{W}}_{hg}W&#x200B;hg&#x200B;&#x200B; only appears in the errors in the memory cell. Now, &#x3B4;ht\\delta {\\mathbf{h}}_t&#x3B4;h&#x200B;t&#x200B;&#x200B; propagates into &#x3B4;ct\\delta {\\mathbf{c}}_t&#x3B4;c&#x200B;t&#x200B;&#x200B; but &#x3B4;ct\\delta {\\mathbf{c}}_t&#x3B4;c&#x200B;t&#x200B;&#x200B; does not necessarily propagate into ht&#x2212;1{\\mathbf{h}}_{t-1}h&#x200B;t&#x2212;1&#x200B;&#x200B;. Instead, &#x3B4;ct\\delta {\\mathbf{c}}_t&#x3B4;c&#x200B;t&#x200B;&#x200B; may be directly passed to &#x3B4;ct&#x2212;1\\delta {\\mathbf{c}}_{t-1}&#x3B4;c&#x200B;t&#x2212;1&#x200B;&#x200B; without being affected by Whg{\\mathbf{W}}_{hg}W&#x200B;hg&#x200B;&#x200B;, thus avoiding the products of Whg{\\mathbf{W}}_{hg}W&#x200B;hg&#x200B;&#x200B; and the gradient problems. Gated Recurrent Unit The gated recurrent unit (GRU) is another RNN variant Chung2015. It is similar to LSTM, but computationally more efficient, as there are less parameters and less complex structure. Mathematically, GRU is represented as, rt=&#x3C3;(Whrht&#x2212;1+Wxrxt+br)ut=&#x3C3;(Whzht&#x2212;1+Wxzxt+bz)gt=tanh(Whg(rt&#x2299;ht&#x2212;1)+Wxgxt+bg)ht=ut&#x2299;ht&#x2212;1+(1&#x2212;ut)&#x2299;gt\\displaystyle \\begin{aligned} {\\mathbf{r}}_t &amp;= \\sigma({\\mathbf{W}}_{hr} {\\mathbf{h}}_{t-1} + {\\mathbf{W}}_{xr} {\\mathbf{x}}_t + {\\mathbf{b}}_r) \\\\ {\\mathbf{u}}_t &amp;= \\sigma({\\mathbf{W}}_{hz} {\\mathbf{h}}_{t-1} + {\\mathbf{W}}_{xz} {\\mathbf{x}}_t + {\\mathbf{b}}_z) \\\\ {\\mathbf{g}}_t &amp;= \\tanh({\\mathbf{W}}_{hg}({\\mathbf{r}}_t\\odot {\\mathbf{h}}_{t-1}) + {\\mathbf{W}}_{xg} {\\mathbf{x}}_t + {\\mathbf{b}}_g) \\\\ {\\mathbf{h}}_t &amp;= {\\mathbf{u}}_t \\odot {\\mathbf{h}}_{t-1} + (1-{\\mathbf{u}}_t) \\odot {\\mathbf{g}}_t \\end{aligned} &#x200B;r&#x200B;t&#x200B;&#x200B;&#x200B;u&#x200B;t&#x200B;&#x200B;&#x200B;g&#x200B;t&#x200B;&#x200B;&#x200B;h&#x200B;t&#x200B;&#x200B;&#x200B;&#x200B;&#x200B;=&#x3C3;(W&#x200B;hr&#x200B;&#x200B;h&#x200B;t&#x2212;1&#x200B;&#x200B;+W&#x200B;xr&#x200B;&#x200B;x&#x200B;t&#x200B;&#x200B;+b&#x200B;r&#x200B;&#x200B;)&#x200B;=&#x3C3;(W&#x200B;hz&#x200B;&#x200B;h&#x200B;t&#x2212;1&#x200B;&#x200B;+W&#x200B;xz&#x200B;&#x200B;x&#x200B;t&#x200B;&#x200B;+b&#x200B;z&#x200B;&#x200B;)&#x200B;=tanh(W&#x200B;hg&#x200B;&#x200B;(r&#x200B;t&#x200B;&#x200B;&#x2299;h&#x200B;t&#x2212;1&#x200B;&#x200B;)+W&#x200B;xg&#x200B;&#x200B;x&#x200B;t&#x200B;&#x200B;+b&#x200B;g&#x200B;&#x200B;)&#x200B;=u&#x200B;t&#x200B;&#x200B;&#x2299;h&#x200B;t&#x2212;1&#x200B;&#x200B;+(1&#x2212;u&#x200B;t&#x200B;&#x200B;)&#x2299;g&#x200B;t&#x200B;&#x200B;&#x200B;&#x200B; The GRU merges the cell state and hidden state, and thus h{\\mathbf{h}}h replaces c{\\mathbf{c}}c and the output gate ot{\\mathbf{o}}_to&#x200B;t&#x200B;&#x200B; is no longer needed. Next, the GRU combines the forget and input gates into a single &#x201C;update gate&#x201D; ut{\\mathbf{u}}_tu&#x200B;t&#x200B;&#x200B;, which enables the inclusion of long-term behaviors in the RNN. Finally, a reset gate rt{\\mathbf{r}}_tr&#x200B;t&#x200B;&#x200B; is added to control the contribution of the previous states to the current prediction. While many alternative LSTM architectures have been proposed, in Greff2016, it was found that the original LSTM performs reasonably well on various datasets and none of the eight investigated modifications (including GRU) significantly improves performance. Furthermore, it was found that the forget gate and the output activation function as its most critical components. Example PyTorch: Windows with Anaconda Among the popular machine learning frameworks, I chose PyTorch for its mild learning curve. I planed to try RNN on my Windows laptop, but it turns out PyTorch does not support Python 2 on Windows/Anaconda. So I did the following to install a minimal working PyTorch. A Python 3 environment has to be created first by 1conda create -n py36 python=3.6 anaconda After a lengthy installation, the environment is then deployed by 1conda activate py36 The command for installing PyTorch is found here. In my case where a GPU is not available, the PyTorch ecosystem is installed by, 1conda install pytorch-cpu torchvision-cpu -c pytorch The Python 3 installation might alter the default browser for the Jupyter Notebook. To reset the browser, first fo the following in the command line, 1jupyter notebook --generate-config And next specify the path to the browser in the config file, 1c.NotebookApp.browser = u&apos;path_to_browser %s&apos; Note that %s has to be in the string. Toy Problem The dynamical system considered in this example is the forced Van der Pol (VdP) oscillator, x&#xA8;=&#x3BC;(1&#x2212;x2)x&#x2D9;&#x2212;x+Asin(&#x3C9;t)\\displaystyle \\ddot x = \\mu (1-x^2) \\dot x - x + A \\sin(\\omega t) &#x200B;x&#x200B;&#xA8;&#x200B;&#x200B;=&#x3BC;(1&#x2212;x&#x200B;2&#x200B;&#x200B;)&#x200B;x&#x200B;&#x2D9;&#x200B;&#x200B;&#x2212;x+Asin(&#x3C9;t) where x&#x2D9;\\dot x&#x200B;x&#x200B;&#x2D9;&#x200B;&#x200B; and xxx are considered the states of this second-order ODE. The first term on the RHS is a nonlinear damping term that introduced rich dynamical properties to the oscillator. The third term on the RHS is considered the input to the system. In this study, the following parameters are used, &#x3BC;=0.1,A=1.2,x(0)=x&#x2D9;(0)=0,t&#x2208;[0,50],&#x394;t=0.25\\displaystyle \\mu = 0.1,\\quad A = 1.2,\\quad x(0)=\\dot x(0)=0,\\quad t\\in [0, 50],\\quad \\Delta t=0.25 &#x3BC;=0.1,A=1.2,x(0)=&#x200B;x&#x200B;&#x2D9;&#x200B;&#x200B;(0)=0,t&#x2208;[0,50],&#x394;t=0.25 Given the sinusoidal input associated with a certain value of &#x3C9;\\omega&#x3C9;, one can numerically integrate the system to obtain the response of the VdP oscillator. The goal of this exercise is to fit an RNN based on the VdP responses for several &#x3C9;\\omega&#x3C9;&#x2019;s, such that the RNN can reproduce the VdP responses for some other &#x3C9;\\omega&#x3C9;&#x2019;s. The code implementation is adapted from here, and can be found from my github repo. Four types of RNNs are examined, Vanilla RNN with tanh\\tanhtanh as activation function. Vanilla RNN with ReLU as activation function. LSTM RNN GRU RNN All the RNNs have one hidden layer with 32 states and one linear output layer. The RNNs are trained via the MSE loss function using the Adam algorithm with a learning rate of 0.01 and 10000 epochs. The training data set includes the VdP responses for &#x3C9;=0.3&#x3C0;,0.4&#x3C0;,0.5&#x3C0;,0.6&#x3C0;\\omega=0.3\\pi,0.4\\pi,0.5\\pi,0.6\\pi&#x3C9;=0.3&#x3C0;,0.4&#x3C0;,0.5&#x3C0;,0.6&#x3C0;. The testing data sets includes the VdP responses for &#x3C9;=0.35&#x3C0;,0.45&#x3C0;,0.55&#x3C0;\\omega=0.35\\pi,0.45\\pi,0.55\\pi&#x3C9;=0.35&#x3C0;,0.45&#x3C0;,0.55&#x3C0;. In each training epoch, the data for gradient decent is a random segment (starts from beginning) of a VdP response randomly chosen from the training data set. A maximum of 120 time steps is used in the training. In other words, the last 80 time steps of the VdP response in the training data set are unseen by the RNN. Finally, the initial hidden states are set to be zero. The results are shown in the figures below. The solid blue and red lines are the VdP responses found directly using numerical integration. The dashed lines are the RNN prediction. The vanilla RNNs do not do well in this problem. The failure probably can be explained the gradient vanishing problem that prevents the vanilla RNN to capture the long term periodic behavior. Both the LSTM and GRU do well. Note that the RNN predictions extrapolates well beyond the data used for training, as well as between the different values of &#x3C9;\\omega&#x3C9;&#x2019;s. There are apprarently many tweaks and tunable parameters in the RNNs that can improve the prediction or generalize the model. For example, What are the optimal numbers of layers and hidden states for the RNN? What is the best way to utilize the training data set? How to take care of different initial conditions? Maybe via infering the proper initial hidden state in RNN? How to efficiently train the RNN for a larger parameter space that includes, e.g. &#x3BC;,A,&#x3C9;\\mu, A, \\omega&#x3BC;,A,&#x3C9;? These might be done in a future post. Vanilla RNN with tanh. Vanilla RNN with ReLU. LSTM RNN. GRU RNN. More References Bengio et al, &#x201C;Learning long-term dependencies with gradient descent is difficult&#x201D; Pascanu et al, &#x201C;On the difficulty of training recurrent neural networks&#x201D; Recurrent Nets and LSTM RNN Tutorial Tips for training RNNs Initial states for RNN Note that the notation is slightly different from the engineering convention, so as to conform with the notation in RNN.&#x21A9; One can see that even LSTM is not a recent concept.&#x21A9;"},{"title":"Interesting Websites","permalink":"http://smanist.github.io/2019/02/15/Interesting-websites/","text":"This is a gathering of websites that are interesting and useful. The list is in alphabetical order and could be updated from time to time. amCharts The website provides a set of visualization tools, including an online chart editor and an online map generator. These applications are free and fully-functional. The free image has a website logo that can be removed by paying for a license. But the most powerful tool from amCharts is its libraries for plugging interactive visualizations into a webpage. One can write a relatively simple JavaScript/JSON file (or TypeScript, which I am not familiar with) to generate a fancy complex image, such as chord diagrams, sankey diagrams, and annotated world maps. The only inconvenient part is that the library is a little bit heavy if one only wants to make figures for a paper or presentation. The library does provide an export function, but requires some manual operations. COCA, Linggle and Netspeak These are websites for improving English usage/writing by checking/finding the proper combination of words, i.e.&#xA0;phrases. For example, on Linggle, one can find the best combination of words that looks native to English, * for filling in a blank of a phrase with multiple words. _ for filling in a blank of a phrase with one word. ?word for checking if word is needed in the phrase. word1/word2 for choosing the best word from word1 and word2 for the phrase. pos. for finding a word of the specified part of speech for the phrase. pos. can be v., n., adj., prop., det., conj., pron. COCA and Netspeak are other two websites for the similar purpose, and its usage is self-explanatory from the website instruction. Wordart The website is for generating a cloud of words, e.g.&#xA0;keywords of a research project. The resulting image can be highly-customized. One has to pay for high resolution image. However, I think the resolution of the free version is high enough for regular usage."},{"title":"Rays v.s. Skates","permalink":"http://smanist.github.io/2019/01/27/Rays_vs_Skates/","text":"Flat fish flying in the water. Recently I visited an aquarium and encountered with these &#x201C;flying&#x201D; fish, rays and skates. They looks the same to me: flat, kite-like fish. In fact, rays and skates are dorsoventrally flattened fish that belong to the same superorder Batoidea, which contains four orders. Skates are in Rajiformes, while rays are in Myliobatiformes, Rhinopristiformes, Torpediniformes. Historically, due to morphological reasons, some rays were classified as skates, and vice versa. Furthermore, rays, skates, and their close relatives, sharks, are considered to be within a subclass of (primitive) fish called Elasmobranchii in the class Chondrichthyes. Chondrichthyes contains the cartilaginous fish. From wikipedia: They are jawed vertebrates with paired fins, paired nares, scales, a heart with its chambers in series, and skeletons made of cartilage rather than bone. In a word, these fish have soft skeletons 1. Furthermore, Elasmobranchs have five to seven pairs of gill clefts opening individually to the exterior, rigid dorsal fins and small placoid scales on the skin. The pelvic fins in males are modified to create claspers for the transfer of sperm. There is no swim bladder; instead, these fish maintain buoyancy with large livers rich in oil. Sometimes it is hard to differentiate rays and skates from sharks, as illustrated in this short video. However, a rule of thumb is that, sharks have gill slits on the side, rays and skates have theirs on the bottom. Now the diffeences between rays and skates. The major difference is in the reproductive strategies: Rays are viviparous while skates are oviparous. The skate eggs are a little peculiar, because they are released in hard rectangular cases nicknamed &#x201C;mermaid&#x2019;s purses&#x201D;. Morphologically, skates typically have a prominent dorsal fin while the dorsal fin is absent or greatly reduced in rays. Most rays are kite-shaped with whip-like tails having stinging spines (hence &#x201C;stingray&#x201D;) while skates have fleshier tails and lack spines 2. While some rays have stings to protect them, the electric rays have kidney-shaped electric organs that are visible through the skin on the dorsal surface to generate and discharge a strong electric current to stun prey and for defense from potential predators. As for skates, they rely on thorny projections on their backs and tails to for protection. For more differences between rays and skates, see here. It is said that rays are generally much larger than skates. Nevertheless, the variance of the sizes of rays is huge. The largest ray (Manta birostris) reaches up to 9 meters in width, while the smaller ray (Narcine bancroftii) is only 20 cm. The sizes of skates are in between. The largest skate (Dipturus batis) reaches up to 2.5 meters in length, while the smaller skate (Raja straeleni) reaches to a maximum total length of 68 cm. The last interesting thing I would like to mention is the osmoregulation of cartilaginous fishes, i.e.&#xA0;the passive regulation of the osmotic pressure of an organism&#x2019;s body fluids for the water-salt balance. For adaptation to high-salinity marine environments, cartilaginous fishes adopt a unique urea-based osmoregulation strategy. Their kidneys reabsorb nearly all filtered urea from the primary urine, and this is an essential component of urea retention in their body fluid. Due to urea retention, the meat of cartilaginous fishes is usually poisonous, due to the high content of urea and sometimes trimethylamine oxide. Nevertheless, human managed to process the meat, e.g.&#xA0;via fermentation, and eat without costing their lives. For example, hongeo-hoe from Korea is made from skate and emits a very strong ammonia-like odor. And h&#xE1;karl from Iceland is made from sharks and has a strong ammonia-rich smell and fishy taste. The ammonia produced during fermentation actually helps the preservation of the food. I personally have tried h&#xE1;karl, which tasted good if the ammonia smell is accepted. I like the texture. References: Florida Museum See more differences between cartilaginous and bony fishes here.&#x21A9; The spines of stingrays are often removed for safety reasons when displayed in aquariums.&#x21A9;"},{"title":"Notes on Julia","permalink":"http://smanist.github.io/2018/12/21/Notes-on-Julia/","text":"&#x201C;Looks like Python, feels like lisp, runs like C.&#x201D; Introduction As discussed in the previous article, I plan to explore the capability of Julia in scientific computing, esp. in applications like computational mechanics and optimization. I have gotten even more attracted to Julia when I heard that it has joined the Petaflop Club: achieved peak performance exceeding one petaflop per second on supercomputers. Julia appears to be the only &#x201C;high-level&#x201D; language in the Petaflop club - the others are C, C++ and Fortran. This article is a digest of the basics of Julia that I have learned recently. The syntax of Julia will not be discussed in detail, as it could be mastered by actaully writing the code - So there will not be many examples. Instead, in this article, I would focus more on the features and highlights of Julia. In addition, due to my background, I tend to highlight the similarities and differences between Julia and Python/C++. Overview Two-Language Problem One of the goals of Julia is to solve the two-language problem: one can either have a programming language that&#x2019;s easy to use, or fast. There are indeed some existing solutions, e.g.&#xA0;those from the Python ecosystem. In the standard CPython implementation, the Python code is interpreted as bytecodes that run on the virtual machine, which is of course slower than compiled machine code that runs on the actual machine. Three representative approaches to accelerate Python include PyPy, Cython, and Numba. PyPy is basically an implementation different from CPython using a just-in-time (JIT) compiler. Cython generates C code from Python code - or wraps C libraries for Python 1. Numba compiles Python snippets in a JIT manner. I myself have mainly used Python with Cython-wrapped C++ library. So I am really using two languages to &#x201C;solve&#x201D; the two-language problem. The three approaches have been discussed and compared in this post. These approaches are not perfect. To accelerate a given Python code, some extra work are involved, e.g.&#xA0;annotating the code using certain &#x201C;peculiar&#x201D; syntaxes. The two-language problem had been even more challenging when the Julia project started in 2009, since the Python ecosystem has not matured enough to solve the problem. As one of the developers discussed in this post: The initial version of Cython was released in 2007; The first working verion of PyPy was released in 2007; Numpy was yet not mature at the time; Numba would not be released until 2012. 2 Solution by Julia Julia is mainly written in Julia with some dependencies on C, Fortran, and assembly. However, in the core, there is a Scheme parser FemtoLisp and a LLVM compiler in C++. They are responsible for gluing Julia and the underlying operating system together. The Julia solution to the two-language problem is best described by the quote at the beginning of this article: Writes like Python: The user writes Julia like a high-level dynamic language. Feels like Lisp: The Julia code is parsed into abstract syntax trees (ASTs) using FemtoLisp (lowered, typed). Runs like C: The LLVM generates the intermediate representation (IR) of the ASTs, which would run on the virtual machine (llvm), and compiles the IR into the native code optimized for the local machine (native) 3. The user essentially only needs to care about writing their applications. The compiler takes care of the rest. Of course, the code would be faster if it is written with care taken for the parsing and compiling stages. Key Features As I understand, Julia as a dynamic programming language is made distinct from the others by its type system combined with multiple dispatch. Well, I am not a computer scientist, I could be wrong in this assertion and some of the concepts discussed in this section. Dynamic languages are usually considered &#x201C;typeless&#x201D;. However, more precisely speaking, types do exist, but what lacks is type declaration. The user cannot explicitly instruct the compiler to specify certain types for certain values. On the other hand, in static languages, type declaration is mandatory. And that is one reason why static languages are usually faster than dynamic languages, as some optimizations of the machine code can be done based on the types. Cython and Numba are like patches of partial type declaration for accelerating Python. Julia takes a step further, as it has the complete type system and the type inference mechanism. Like static language, all the values in Julia can be assigned a type by the user. Like dynamic language, not all values require a type - the most suitable type can be inferred by the compiler. Based on the type system, the multiple dispatch mechanism is enabled with parametric polymorphism. In polymorphism, a single interface, or method, is provided to values of different types 4. Typically, the polymorphic methods are stored in a virtual method table, a.k.a. vtable. In the run-time, the specific method is chosen from the vtable. In single dispatch, the vtable is stored with the classes. The calling of a method can be written as object.action(args), because the choice of polymorphic method is solely determined by the type of the calling object. In multiple dispatch, the vtable is stored with the method itself. The calling of a method should be better written as action(objects, args), as is done in Julia, the choice of polymorphic method is determined by the types of all the arguments. Multiple dispatch has two advantages. First, it is the direct reason for the high performance of Julia. For each polymorphic method, specialized low-level code is generated with all possible optimizations under the host machine. In the run-time, the most suitable/optimized method is called from the vtable. Second, multiple dispatch provides greater flexibility and reusability, as a method is not bound to a type. For example, suppose there is an existing method for LU decomposition for matrices of Float64. To do LU decomposition of matrices of rationals, one only need to define the elementary arithmetic operations for rationals, and call the same LU method. However, in single dispatch languages, one will need to not only define the elementary arithmetic operations, but also rewriting the LU method using the new rational type. Besides the type system and multiple dispatch, another important feature of Julia is its metaprogramming capability: a program can be designed to read, generate, analyse or transform other programs, and even modify itself while running. The roles of code and data are more or less interchangeable. In Julia, everything is an expression that returns a value and an expression can take values and/or expressions as input. The metaprogramming capability directly stems from the lisp core of Julia, that enables the manipulation of the ASTs generated from the Julia code, e.g.&#xA0;using macros 5 - functions that acts on expressions. The metaprogramming capability allows the users to minimize the efforts and computational time for their applications. Learning materials The best learning material for Julia is probably its documentation, which is always (expected to be) update-to-date, and contains both introductory and advanced topics. The official website also provides a large list of learning materials, including videos (e.g. this and this), online documents, and books. Among these are two books that I recommend: (1) Getting Started with Julia by Ivo Balbaert, indeed good for getting started; (2) &#x201C;Julia High Performance&#x201D; by Avik Sengupta, a little advanced but very useful for beginners aiming for performant programs. Another book, &#x201C;Mastering Julia&#x201D; by Malcolm Sherrington, might be good for people who need immediate hands-on experiences. However, a notable issue is that, with the advent of the more stable 1.0 version, some of the syntaxes and claims in the books are outdated. So make sure to practice and verify everything read from the books. Another good source of learning materials are the Julia code itself. As one of the books has suggested, there are several interesting folders in Julia to look at: base: contains a great portion of the standard library and the coding style exemplary. test: has some code that illustrates how to write test scripts and use the Base.Test system. examples: gives Julia&#x2019;s take on some well-known old computing chestnuts. This article is mainly based on materials from Getting Started with Julia by Ivo Balbaert and the official documentation. More on Features Type System Type hierarchy Every value has a type and there are a lot of built-in types. These types are organized in tree, with the root, type Any. The types themselves are of type DataType. A type is either an abstract type or a concrete type. An abstract type can have a lot of children or subtypes but cannot be instantiated, while a concrete type is on the contrary. Essentially, an abstract type is only a name that groups multiple subtypes together, which works in a manner similar to Union that gives a type/alias to a user-specified group of types. Naturally, Any is the supertype of all types (including itself). The opposite of Any is a special type called Union{}, i.e.&#xA0;union of nothing. It is subtype of all other types (even the concrete ones). There is also a special type Nothing. Here, it is stressed again: In the context of multiple dispatch, a subtype do not inherit any methods from its supertype. This is on the contrary to the object-oriented thinking. Conversion, promotion, and annotation Variables of different types can be converted to each other, if the corresponding convert method exists. There is also a built-in system called automatic type promotion to promote arguments of functions so as to match those of the existing functions. This is a key device that facilitates the multi-dispatch mechanism. Additionally, the combination of type promotion and Union could bring some convenience to the user. The user can define one function using data types from a user-defined union and save the effort of defining multiple similar functions for each data type from the union. Variables can be associated to types using two operators for type annotation: :: and &lt;:. Essentially, var::T asserts if the variable var is of type T. This is also used in the sense of a type declaration, but only in local scopes such as in functions. var&lt;:T asserts if the variable var is of the subtype of T. This can be used in, e.g.&#xA0;the restriction of types in composite types. Composite and parametric types The composite types are the types composed of a set of named fields with an optional type annotation (by default Any). A composite type is similar to a struct in C. In fact, the keyword is struct too in Julia. Composite types declared with struct are immutable; they cannot be modified after construction. This design has some advantages, including efficiency in storage and memory allocation, thread safety, and readability. Nevertheless, the contents of a mutable field in an immutable type can be changed, because only the reference is stored. It could be a good practice to define immutable types without mutable fields. When necessary, mutable composite types can be declared with the keywords mutable struct. Composite types can be generalized via parametrization. A parametric type is conceptually similar to templates in C++ and creates a whole family of new possible concrete types. However, the new types are only compiled as needed at runtime. Finally, for better performance, always annotate the type of the fields in a composite type when possible. As a side note, to see whether the two objects x and y are identical, they must be compared with the is function, The is(x, y) function can also be written with the triple-equal operator as x === y. The addresses in memory are compared to check whether they point to the same memory location Constructors Constructors creates and initializes an instance of a type. There is always a default (inner) constructor that comes with a type, if not otherwise specified. One can, of course, define a specific inner constructor in the type declaration, which overrides the default one. The inner constructors are the only constructors that has access to a special locally existent function called new that creates an object of the declared type. Once a type is declared, there is no way to add more inner constructor methods. Instead, one can only add outer constructors, that are defined just like regular methods (due to multiple dispatch). The outer constructors, ultimately, rely on calling one of the inner constructors to complete the instantiation. Special inner constructors are needed in certain cases, e.g.&#xA0;when argument checking is necessary. A good practice is to combine outer constructors with a limited set of inner constructors. Metaprogramming This is the part of Julia that feel like Lisp: &#x201C;code is data and data is code&#x201D;. Every piece of code is internally represented as an expression, Expr, which can be manipulated by other expressions. This characteristic of Julia, homoiconicity, enables the transformation and generation of the code. This is not unfamiliar, if one works with Lisp (e.g.&#xA0;in Emacs) and Mathematica. The homoiconicity facilitates the reflection capability of Julia. The structure of a program and its types can be explored programmatically just like any other data. This means that a running program can dynamically discover its own properties. Reflection is indispensable for tools that need to inspect the internals of the code objects programmatically, such as debugging and profiling. Expressions The Julia code is parsed by FemtoLisp as an AST, a tree representation of the abstract syntactic structure of the source code. The nodes of AST are all of type Expr. A formal definition of the Expr type is 1234type Expr head::Symbol args::Array{Any,1}end The head indicates the type of the expression, e.g. :call as a function call and = as assignment. The args is an array of Symbols and (maybe) Exprs, which recursively represents the AST. One can get a formatted output of the AST of an expression using the dump function. Expressions can be built directly using the constructor for Expr. However, to make life easier, one can create expressions using the quote operator : that treats its argument as data instead of code. It means &#x201C;prevented evaluation&#x201D; in a sense. The quote preceding a symbol makes a Symbol, e.g :sym. The quote preceding a bracketed expression makes an Expr, e.g :(1+2). A compound expression consists of multiple sub-expressions separated by ;. The value of a compound expression is the value of the last sub-expression. For a larger compound expression, it is better to use the quote-end block instead of quote operator. Note that the evaluation of an expression is done in the global scope and the internal variables will be visible to the outside code. Writing expressions is made even simpler with the interpolation operator $. The interpolation is evaluated once an expression is constructed at parse time. This is unlike the quotation itself, which is evaluated by eval at runtime. Macros Macros are like functions, but instead of values, they take expressions, symbols or literals as input arguments. The evaluation of a macro means the expansion of the input expression. This expansion occurs at parse time when the AST is being built. This is different from a function, which takes the input values and returns the computed values at run-time. A macro is hygenic, when it differentiates between the macro context and the calling context. The hygienity is important because the macros inject the code directly in the namespace in which they are called, which may clash with the existing methods in the same module. There are several rules for writing hygienic macros: Declare the variables used in the macro as local, so as not to conflict with the outer variables. Use the escape function esc to make sure that an interpolated expression is not expanded, but instead is used literally. Don&#x2019;t call eval inside a macro. Note that escaping is similar to Hold in Mathematica. An expression wrapped in this manner is left alone by the macro expander and simply pasted into the output verbatim. Therefore it will be resolved when the macro is called, instead of when it is defined. Notes on the Usage This section highlights some basic functionalities of Julia. General Behaviors and Conventions Julia behaves similarly to Python in many senses, e.g.&#xA0;all names are just aliases bound to values. However, there are differences. For example, in Julia, arrays are 1-indexed. Negative index is not supported and the last index is end. Refer to this for more differences between Julia and other languages. Entities in Julia must start with a letter or an underscore _. Conventionally variable names consist of lowercase letters with long names separated by underscores rather than using camel case. Numbers can be separated by underscores for readability. It is a good practice to write constant variables in uppercase letters. The package names are kept upper camel case. ! indicates a mutating function that modifies its the first argument. Julia does not have line-continuation operators. It will read until the expression is finished. Julia supports unicode, so that functions and variables can be named using special characters, e.g. &#x2297; instead of * for outer product, and &#x3B1; instead of alpha for a Greek symbol. Data structures Concepts like strings, arrays, dictionaries, tuples, and sets all behave in a manner that is more or less similar to those in Python. Note that except string, all the rest are parametric types. Strings Julia differentiates between single characters and strings. Strings can contain any number of characters and are specified using double quotes &quot; or triple double quotes &quot;&quot;&quot;. The character literals are specified using single quotes &apos;. &quot;&quot;&quot; is used (esp.) when there are double quotes in the string itself. The strings are immutable, which means that they cannot be altered once they have been defined Julia has an elegant string interpolation mechanism for constructing strings using the $ operator (again). $var inside a string is replaced by the value of var, and $(expr) is replaced by the computed value of expression expr. The @printf macro takes a format string and one or more variables to substitute into this string while being formatted. It works in a manner similar to printf in C. In string interpolation, another @sprintf from Printf package is used. Strings are joined by *, unlike + in Python. As a result, ^ applied on a string indicates an implicit multiplication. Unicode characters in a string contains multiple bytes. Therefore, there are two ways to define the length of a string: (1) Number of bytes in string, endof(str); (2) Number of characters in string, length(). There are several special types of string. v&quot;&quot; for version number, which can be compared. r&quot;&quot; for regular expressions, which can be used for pattern matching. b&quot;&quot; for byte array literal, which represents a string using Uint8 values. Arrays An array is of parametric type: Array{Type,Dimension}. For example, Array{Int64,2} means a 2-D array containing values of type Int64. Additionally, there are short-hands for vectors and matrices: Array{Type,1} == Vector{Type} and Array{Type,2} == Matrix{Type}. The arrays are by default &#x201C;real&#x201D; arrays, meaning that the data is stored continuously in memory (column-major). This is in contrast to the list of lists in Python and vectors of vectors in C++. It is possible to create array of arrays in Julia, of course. However, the array would only contain the references to the underlying arrays. There are multiple ways to create an array, Direct specification, e.g. a=[1,2,3]. Using some methods, e.g. collect(range(...)) List comprehension, e.g. [i for i in 1:3]. Multiple for&#x2019;s result in multi-D arrays. Note that due to the column-major storage, 1-D array is logically column vectors. Logically row vectors are essentially 1-by-N matrices. To create row vectors, separate the values by space instead of comma, e.g. a=[1 2 3]. Furthermore, a semicolon ; indicates a new row, leading to a matrix, e.g. a=[1 2 3;4 5 6]. In the creation of an array, constraining the type is often helpful for the performance. Using typed comprehensions everywhere for explicitness and safety in production code is certainly a best practice. For example, use a=Int64[1,2,3] instead of a=[1,2,3]. When dealing with large arrays, it is better to indicate the final number of elements for pre-allocation using the sizehint method to improve the performance. The memory of a large array can be freed by setting the array to nothing. Dictionaries and enumerations A dictionary is of parametric type: Dict{Type_key,Type_value}. It is created by by Dict(key=&gt;val, ...), where =&gt; is a pair operator. All the keys must have the same type, and the same is true for the values. The types can be specified at creation. A good practice is to use immutable types for the key, e.g.&#xA0;a Symbol 6. Dictionaries are mutable. New key-value pairs can be appended to a dictionary without calling method like update in Python. Also, one can directly loop over keys, values, or key-value pairs of a dict. In Python, one need to call iteritems to loops over key-value pairs. Julia does not provide a standard enumeration type. However, there is a @enum macro that creates a type that behaves like a Enum, 1@enum EnumName[::BaseType] key[=val] ... The data is stored as Vector{Tuple{Symbol,Integer}}. Tuples The type of a tuple is just a tuple of the types of the values it contains. Tuples are immutable, just like other languages. A tuple can be unpacked or deconstructed, e.g. a, b = tuple1. Notice that an error will not be raised if the left-hand side cannot take all the values of the tuple. Finally, note that there is a type NamedTuples, which can be considered an ordered dictionary. Its underlying structure consists of a tuple of all the keys as Symbol and a tuple of all the values. Control flow Basic Blocks One thing to be kept in mind is that, everything is an expression that returns a value. That means, structs like if-else-end and try-except-end all return a value, which can be assigned to a variable. The familiar if-elseif-else-end syntax is used for conditionals. There are two short-hand versions: (1) Ternary operators: a ? b : c, and (2) Short-circuit evaluation 7, cond &amp;&amp; expr, if cond=true, do expr cond || expr, if cond=false, do expr Like Python, Julia has no switch/case statement, and the language provides no built-in pattern matching The familiar while-end and for-end syntaxes are used for loops, which can be combined with break and continue. For the for loop, the iteration can be done on a range, a string, an array, or any other iterable collection, just like Python. Furthermore, enumerate also exists in Julia. One thing special, though, is that multiple for loops can be combined into one block - this is how multi-for list comprehension works. Note that for loops are typically faster than vectorization in languages like Python. That is because (1) in Python, the implementation of vectorization (e.g.&#xA0;by Numpy) is faster than naive loops generated by the interpreter; (2) in Julia, vectorization requires extra memory allocation and is thus slower than naive loops. Nevertheless, list comprehension can be far slower than the for loops and vectorizations. The exceptions can be handled using the familiar try-catch-finally-end construct. However, the try-catch should not be used in performance bottlenecks. Whenever possible, all possible exceptions should be handled via conditionals. There are 24 predefined exceptions that Julia can generate, as of writing. These exceptions can be throw&#x2019;d to interrupt the execution. User-defined exceptions can be created by deriving from the base type, Exception. Finally, Exceptions with error/warning/info messages are handled by the error, warn, and info methods. Scopes The for, while, and try blocks (but not the if blocks) all introduce a new scope. There are several things to note. To create a new local binding for a variable, one should use the let block. This is similar to the cell-var-from-loop in Python discussed in a previous article, where a local variable is used in the definition of a function that would be used outside the current block. The for loops and comprehensions differ in the way they scope an iteration variable. When i is initialized before a for loop, after executing a for loop iterating on i, the variable i will be updated. However, this is not true for comprehension. Tasks/Coroutines Julia also supports the yield mechanism, like Python. This can done by the combination of put! and take! methods associated with the Channel type. There is also a more fundamental Task type to define the task to be executed by put! and take!. There is also a convenient @task macro for creating a task from a function. 8 Finally, note that currently Julia tasks are not scheduled to run on separate CPU cores (yet?). Functions There are several ways for creating a function: Code block of function-end One-liner: function(variables) = expression Anonymous function: function = variables -&gt; expression When the performance is important, try to use named functions instead of anonymous ones, because calling anonymous functions involves a huge overhead. Anonymous functions are mostly used when passing a function as an argument to another function, or as output of a function. That latter case is related to closures. The input and output of a function are essentially specified using tuples. There are three types of arguments: (1) Normal arguments; (2) Optional positional arguments; (3) Optional keyword arguments. A typical arglist would be 1func(arg, pos_arg=val1; kw_arg=val2) Only the first two types of arguments, the positional ones, are considered in the multiple dispatch mechanism. The optional keyword arguments are mainly introduced for code clarity. The last positional argument can be &#x201C;spliced&#x201D;: arg..., meaning that it would take all the extra positional arguments into one tuple. Note that the splice operator ..., or splat, can be also used to pass an array to a function as individual arguments rather than an array as a whole. This is similar to the * operator in Python. It is important to realize that in Julia, all the arguments to functions (with the exception of plain data such as numbers and chars) are passed by reference. Their values are not copied when they are passed, which means they can be changed from inside the function, and the changes will be visible to the calling code. Higher-order function in Julia just works like that in Python. There are methods like map, filter, and broadcast. Note that the short-hand for broadcast is the dot .. This is the underlying mechanism for element-wise operations in arrays, such as .*. Also, wise applications of the dot operator can avoid extra memory allocations in vectorized loops, or making a devectorized loop look like a vectorized one - See example #6 here. Here are some general tips for writing performant functions/program: Refrain from using global variables. If unavoidable, make them constant, or at least annotate the types. Split the complete program in functions, small functions, that work on local variables. Types should be stable: Avoid changing the types of variables during execution. Types could be inferred: Always type-annotate the arguments using concrete types or type unions. The return type should only depend on the types of the arguments. Avoid using the splat operator for dynamic lists of keyword arguments. Advanced Topics Two advanced topics in Julia are briefly touched here and will be investigated more in the future. Calling other languages from Julia Shell Julia offers an efficient shell integration through the run function, which creates an object of type Cmd that is defined by enclosing a command string in backticks `. Julia forks commands as child processes from the Julia process. The Cmd object is not executed immediately. It can be run, connected to other commands via pipes, and read or write to it. The pipe operator |&gt; can be used to redirect the output of a Cmd as the input to the following Cmd, just like that in shell environment 9. C and Fortran Julia&#x2019;s LLVM compiler generates native code, the C functions can be called directly by Julia without any glue code. Calling a C function from Julia has exactly the same overhead as calling the same function from C code itself. However, care should be taken when dealing with arguments. First, one needs to work with pointer types, i.e.&#xA0;a native pointer Ptr{T} representing the memory address for a variable of type T. Second, the data consists of bits, e.g.&#xA0;Int8, Uint8, Int32, Float64, Bool, and Char, are considered bitstype. These will be viewed as contiguous byte arrays from C. The calling basically takes the following form, 1result = ccall( (:function, &quot;library&quot;), return_type, (tuple_of_argument_types,), arguments) Arguments to C functions are, in general, automatically converted, and the returned values in C types are also converted to Julia types. Arrays of Booleans are handled differently in C and Julia and cannot be passed directly, so they must be manually converted. The ccall function will also automatically ensure that all of its arguments will be preserved from garbage collection until the call returns. Calling Fortran functions is similar. Just note that all inputs must be passed by reference. The support for C++ is more complex, see packages like Cxx and CxxWrap. Python Calling Python from Julia is done easily using the PyCall package. With the @pyimport macro, one can easily import any Python library, whose functions are called with the familiar dot notation. Parallel Computing Julia&#x2019;s model for building a large parallel application works by means of a global distributed address space. This means that you can hold a reference to an object that lives on another machine participating in a computation. These references are easily manipulated and passed around between machines, making it simple to keep track of what&#x2019;s being computed where. Also, machines can be added in mid computation when needed. Besides manually receiving and sending messages between processes, or workers, Julia also provides some useful wrappers. Parallel macro The @parallel macro acts on a for loop, splitting the range, and distributing it to each process. It optionally takes a &#x201C;reducer&#x201D; as its first argument. If a reducer is specified, the results from each remote procedure will be aggregated using the reducer. If the computational task is to apply a function to all elements in some collection, the parallel map operation can be applied using the pmap function pmap(f, coll). It applies a function on each element of a collection in parallel, while preserving the order of the collection in the result. Distributed array When computations have to be done on a very large array (or arrays), the array can be distributed, so that each process works in parallel on a different part of the array. In this way, we can make use of the memory resources of multiple machines, and allow the manipulation of arrays that would be too large to fit on one machine. The specific data type used here is called a distributed array or DArray; most operations behave exactly as on the normal Array type, so the parallelism is invisible. With DArray, each process has local access to just a part of the data, and no two processes share the same data. More Topics for Later There are yet many more topics to talk about in Julia, e.g. Packages: Julia has a built-in package system with git capability. Graphics: Plotting capability is typically enabled by interfacing to external packages, e.g.&#xA0;Matplotlib from Python. Benchmark: There are some tools/packages for benchmarking, which are critical for developing real performant Julia code. Performance notes: The whole book &#x201C;Julia High Performance&#x201D; by Avik Sengupta is devoted to this topic. These topics (and more) will probably be discussed in future posts. It is also possbile to combine Cython and PyPy for more acceleration. Yet, that requires tweaking the original code even more.&#x21A9; This initial environment also has an influence on the design of Julia - maybe that is why arrays are column-majored instead of row-majored as in Numpy.&#x21A9; Julia provides several methods for inspecting the code generated at each stage: code_lowered, code_typed, code_warntype, code_llvm, code_native.&#x21A9; Note that there is a subtle difference between polymorphism and overloading. Both polymorphic and overloaded methods seem to be &#x201C;methods of the same name that behave differently depending on the arguments and their types.&#x201D; The difference is that the choice of overloaded methods is done in the compilation, while the choice of polymorphic methods is done in the run-time. An example in C++: methods of the same name in the same class are overloaded; virtual functions inherited between classes are polymorphic. Nevertheless, in Julia documentation, it seems the two concepts are not strictly differentiated.&#x21A9; An often-noted difference between macros in Julia and languages like C and C++ is that, macros in the latter are expanded before any actual parsing or interpretation occurs.&#x21A9; Note that the syntax [key=&gt;val, ...] now produces an array of Pairs and the syntax {key=&gt;val, ...} is deprecated.&#x21A9; For non-short-circuit Boolean evaluations, use operators &amp; and |.&#x21A9; Note that there was a produce-consume method combination, but they are already deprecated.&#x21A9; The pipe operators |&gt; works not only with Cmd objects, but also other functions. Essentially it means passing preceding object as the argument to the following function.&#x21A9;"},{"title":"Roast Beef","permalink":"http://smanist.github.io/2018/12/02/Roast-beef/","text":"An (on-going) experiment of roast beef. The recipe This recipe is based on multiple sources: 1, 2, 3, 4. Ingredients Beef Salt Garlic Pepper Steps Preparation Make sure the beef is at room temperature. Rub the surface with salt and smashed garlic, and cover the beef using food wrap for 15-30 min. Option 1: Using frying pan only Recycle the garlic and fry at low heat. Frying: Fry the beef at high heat, 2 min for each side until brown. Cover the pan with lid and turn off the heating, let the beef stand for 5 min. Flip the meat and let stand for a few more minutes, at very low heat. When the center temperature reaches 100 F, get the beef out. Sprinkle pepper and wrap the beef with foil. Let stand for 30 min. Option 2: Using Oven Tieing: Tie the beef with kitchen twine with a 2-3 inch separation. Roasting: Roast the beef at 375 F until the center temperature reaches 150 F. Typically takes 20 min/pound. Let the beef stand for 20 min. Variations One purpose of browning the surface is to &#x201C;lock&#x201D; the juice in the beef. This is done by (1) the Frying step in Option 1, or (2) the Tieing and Roasting steps in Option 2. There are two variants of Option 2. First, in the Roasting step, instead of roasting constantly at 375 F, lower the temperature to 225 F once the beef is browned. Note that this woudl take longer to finish. The second variant is to replace the Tieing and Roasting steps with the Frying step from Option 1. Notes In the rubbing step of preparation, one suggestion is to insert some garlic into the beef for better smell and taste. In Option 1, the center temperature of 100 F results in rare to medium rare texture. Increase if necessary."},{"title":"Julia for Mushin","permalink":"http://smanist.github.io/2018/11/19/Julia-For-Mushin/","text":"A plan to try out the Julia language. Three months ago, Version 1.0 of Julia was released, marking the more-or-less maturing of this language, especially for the field of scientific computation. For Internet applications, some people say everything that can be done using Javascript will eventually be done using Javascript. I wonder if the same thing is true about Julia: In scientific computation, will everything that can be done using Julia eventually be done using Julia? I am not wondering without a solid basis. Julia appears to be fast, maybe close to C, according to the official benchmark. In the meanwhile, Julia is a dynamic language that is probably much easier to use than static languages like C. As the developer indicated, Julia is developed in the hope to &#x201C;eliminate the performance trade-off and provide a single environment productive enough for prototyping and efficient enough for deploying performance-intensive applications&#x201D;. I am particularly interested in a few features of Julia claimed by its developers: (1) Designed for parallelism and distributed computation; (2) Powerful type system where user-defined types are as fast and compact as built-ins; (3) Call C functions directly, without wrappers or special APIs. Item 1 indicates a certain level of automation in parallelizing the code. Item 2 indicates the efficient implementation of some computational techniques, such as automatic differentiation (AD). If that is true, a lot of troubles and pains in AD&#x2019;ing codes in C/C++/Fortran can be avoid. Item 3 could be a huge plus for a Cython user like me - I have been glueing C/C++ libraries using Python all the time. Nevertheless, if Julia is fast enough, maybe there is even no need for the acceleration using C/C++. To try out and assess Julia, my short-term plan is to rewrite and expand the Python library Mushin that I developed earlier. The rewriting will be divided into the following steps/modules, Basics I: The computation of the element internal force vectors and stiffness matrices; the assembly of the element vectors and matrices; the solution of the nonlinear system of static mechanics. Basics II: The inclusion of mass terms and the capability for solving dynamic problems. Parallelization using MPI. Optimization: Development of the adjoint of the problem using AD techniques. Uncertainty quantification (UQ) of the time response. Modules 2, 3 and 4 depend on Module 1 and are parallel to each other. Module 5 depends on Modules 1 and 2. There are a few questions to consider in the implementation of these modules: How to implement sparse and distributed vectors and matrices? Would SparseArrays work? More fundamentally, how to do large-scale linear algebra operations in Julia? Is there something that is AD-able and is like the PETSc library for C? How to solve a large scale nonlinear system? Would NLopt work? How to AD the code? How would JuliaDiff work? Is it better to implement time integration manually, or directly use DifferentialEquations? What impact would be on the UQ applications? The ultimate goal of the short-term plan is to check if Julia is suitable for a computational library: fast, easy parallelization, easy AD and UQ. If everything works out, the long-term plan would be to develop a pure Julia library for general finite element analysis that is parallelized with AD and UQ capabilities enabled. Finally a few notes on the basic aspects in AD. Start with wiki. Mathematically, forward and backward modes of AD are conceptually based on the tangent and dual vectors, respectively. There are basically two strategies for implementation: source code transformation (SCT) and operator overloading (OO). The AD results are usually compared with the complex step method. There are a lot of resources on GitHub, for both SCT and OO. Some references: Website, a collection of libraries for AD. Introduction to AD. Evaluating Derivatives, Griewank2008. Numerical Optimization, Nocedal2006, a chapter is devoted to derivative evaluation, also including coloring scheme. Andersson2012, the library CasADi is presented and eight &#x201C;flavors&#x201D; of AD are discussed. Martins2013."},{"title":"Tips On Scientific Posters","permalink":"http://smanist.github.io/2018/11/19/Tips-On-Scientific-Posters/","text":"Some feedback from my first poster presentation. Recently I got a chance to present my research as a poster. It was fun to think about and make the poster, from which I have learned (what I think are) some basic guidelines. Thanks to Jean-luc Doumont, specialists from a technical communication team, and my friends who criticized my poster. Baseline to Start With What summarizes the essentials of a poster, I think, is Doumont&#x2019;s Three laws of communication, originally from here, Adapt to audience - They will not adapt to you Maximize signal/noise ratio: remove distracting elements on poster Maintain effective redundancy: Using both verbal and nonverbal explanations to make the poster self-explained. My understanding is that, a poster is considered successful if the audience can learn the complete set of information that the poster is intended to convey. Therefore, the poster should be carefully tailored and not as stuffed/technical/detailed as possible, since the audience may not be able to digest. Also, a certain level of noise and redundancy is necessary to ensure the effectiveness of the information transmission. Note that the three laws of communication are apparently applicable to not only posters but also papers and presentations. The central idea in structuring the poster is that a poster is multi-scale. On the top level are the titles and captions, which are the most visible and eye-catching. The lower levels are the texts and figures, which might be read if the audience got interested. On each level, the information should be stated and developed into messages using short full sentences. These messages answer the questions of the audience at different levels of details: What is presented and so what? What is the gap between what people have and want? And where does the authors come in and what are their contributions? In my opinion, the idea of multi-scale presentation is similar to the inverted pyramid structure in journalism. The only difference is the ordering of visibility. A news article is more linear: the most visible part is at the beginning and the visibility decreases towards the end. Format for Navigation The multi-scale nature of the poster determines its layout. Two aspects should be considered: How it looks like as a whole, and how are the items relatively positioned? The basic rules are summarized as: (1) Proximity for relation; (2) Similarity for similar contents; (3) Prominence for importance. Particularly, the items, e.g.&#xA0;text boxes and figures, should be placed with alignment to grid lines to achieve a global level of &#x201C;harmony&#x201D;. For text boxes, make sure to use a fixed set of fontsizes. Furthermore, be cautious of using boldface: Whatever words in bold should make sense on its own. This is another example of how a poster is multi-scale. Next, some people (Like Doumont) suggest no justifications for the text, while I used justification in my poster. I think this is scenario dependent. Finally, it might be beneficial to maximize the contrast, e.g.&#xA0;using color background with white boxes. Figures and Visuals The basic principle is that the visuals should be informative, instead of merely decorative. They should be designed with high proportion of data to ink while remain self-explained via necessary and meaningful captions, legends, narratives, etc. For figures in particular, I do recommend Doumont&#x2019;s suggestions: No need to use grids: Grids are for figures in the past era of printed materials. Only label the significant numbers: Instead of using the conventional uniform axis ticks, which is a waste of ink and does no provide much information. For posters, no need to include figure numbers: Waste of space and ink. Other Tips Think twice if the reference and acknowledgements should be put on the poster. They take some space but do not add much information to the poster. It might make more sense to carry the extra information via some external media. Doumont suggested something like a business card that can be distributed. People who are interested can look into the details themselves later. This time I tried to do things digitally and put a QR code on the poster that links to a temporary post on my website. If PowerPoint is used for making the poster and producing the final PDF file, make sure the slides are exported, instead of printed, as PDF files. The figure resolution would be lost in printed PDF files. Also, whenever possible, use SVG format, instead of PNG format, for the figures. This reduces the file size of the slides while maintaining high resolution. However, note that in the exported PDF file, some features in the SVG figure might be rasterized."},{"title":"Professor Ni Naru III","permalink":"http://smanist.github.io/2018/10/14/Professor-Ni-Naru-III/","text":"How to become a professor (in Engineering)? CV and cover letter for application. These are notes from a workshop on writing CV and cover letters (CL). First, think from institution&#x2019;s point of view: (1) They have spent great effort on creating the position, so the applicants are expected to customize the materials and show excitement for this particular institution. (2) Due to its large volume, the applications will be quickly skimmed and carefully read only when the applicant is seriously under consideration, so the materials are expected to be accessible to the general audience. In addition, the screening process will be in the order of CL, then CV, then research statement. So a certain level of redundancy is expected. CV The CV should demonstrate one&#x2019;s strongest qualifications and the supporting details. Particularly, the following four aspects of the experiences shall be tailored based on the institution: Research: Include short introduction and key results. The research interests should be explained using a short narrative of research and brief conclusion with future program of research, which align with the department. Teaching: Typically teahcing assistant experience. It should be supported by statistical summary of evaluation and highlights of contributions to the course. Grant Professional In addition, care should be taken for the following items: Include the dissertation title and advisor&#x2019;s name(s). Awards: explain the abroad ones if necessary. Publication: Differentiate between accepted, in press, submitted, under review, in progress. Service and membership: List only those to whom contributed. Do not list those obtain by simply paying registration fees. Reference info.: Include names, titles, institutions and contact info. for people who can provide info. on one&#x2019;s espertise, grant, collaboration. Some tips for writing the CV: Clear and concise. Learn from CV&#x2019;s of peers and people slightly ahead of you. Balance the heading and the contents. Always tailor for institutional fit. Show instead of tell, i.e.&#xA0;provide supporting details. Present oneself as a future colleague, not a student. Cover letter Answer two questions: (1) What is one&#x2019;s strength as future faculty, particularly in productivity, fundability, leadership; (2) What is one&#x2019;s strength for the particular position: show the fit. There are four essentials in CL: Reputation: advisor, institution, contribution. This can be done in a short paragraph and serve as opening. Fundability: research vision, past funding future ideas. Productivity: funding, publication, patents. Fit: research focus of the position, institutional culture, department colleagues. This serves as the closing. These essentials can be demonstrated in CL using the following structure: Opening: What position, where you currently are, area of expertise, strength. Body: Research vision, relevancy, fundability, accomplishments to date and highlighted contributions. Teaching and advising experience. Closing: Enthusiasm for position, colleagues, department and institution. A good practice is to start writing a CL even if one is not applying for a position soon. This helps one to identify the areas and interest, articulated in daily networking, and be prepared for (unexpected) interviews."},{"title":"Peking Duck","permalink":"http://smanist.github.io/2018/10/14/Peking-duck/","text":"An (on-going) experiment of Peking-style scrispy skin duck. The recipe This recipe is mainly based on The Ultimate Guide to Making Crispy, Amber-Hued Peking Duck at Home. I have tried the recipe twice, once for a duck and the other time for a chicken. Ingredients Lean duck Chinese five-spice powder (or DIY) Salt Soy sauce Maltose syrup Applewood (optional) Steps Day 1 Clean the duck. Coat the inside of the duck with five-spice powder (f.s.) and seal the body with a stick. Separate the skin and the flesh of the duck. Add salt, f.s., and soy sauce to water and boil for 5 min. Poach the outside of the duck using the boiled water. Mix soysauce with maltose syrup and coat the duck. Now the duck has to be dried for a few days. It has to be somehow lift in the air, so that the extra sauce can drip down. Day X Smoke the duck inside a sealed container using the applewood for 30 min. I skipped this step as I could not find applewood. Roast the duck by the following steps: (1) Roast for 30 min at 350F and hang for 5 min to remove fat; (2) Roast again for 30 min until the core temperature reaches 130F. Bath the duck with hot oil at 390F until it is golden. Notes In the video guide, a pump was used to blow the duck, which was very efficient. However, it is possible to manually separate the skin and the flesh - just be careful. Make sure the wings and legs do not touch the body during the drying process. In my experiment, the drying process was only one day. As a result, the skin of the final product was not so crispy. The roast process depends on how fat the duck is. In the experiment, the duck was quite fat. As a result, the duck was hung at a higher frequency to remove the extra fat and oil. To disassemble the duck, consider first remove the drum stick, then peel the skin off on the back, then cut through the legs, and finally cut out the breast. The purpose of the maltose syrup is to provide a thick sauce base that can be applied onto the duck without dripping down too quickly. Moreover, the sugar in the syrup contributes significantly to the smell in the final product. When maltose syrup is not available, one can try to concentrate off-the-shelf pancake syrup: Boil the syrup for a few seconds and let it cool down slowly. Do not boil for too long time, otherwise the syrup would solidify."},{"title":"Karaage","permalink":"http://smanist.github.io/2018/10/14/Karaage/","text":"An (on-going?) experiment of Japanese-style fried chicken. The recipe Ingredients Chiken thigh (boneless): 2 lb Ginger: half of palm Garlic clove: 6 Salt: Dependents on mood Pepper: Dependents on mood Shichimi togarashi (optional): 1 bottle/18 g Soy sauce: Dependents on mood Cooking rice wine: Dependents on mood Egg: 4 Starch: depends on working condition Flour: depends on working condition Oil: depends on working condition Steps Cut the chiken thigh to bite size. Make the marinade sauce: Grind the garlic clove and ginger, and mix with salt, pepper, soy sauce, cooking rice wine. I also added shichimi togarashi (s.t.). Marinate chicken in the sauce for 5 min. Meanwhile, whisk the eggs. Meanwhile, prepare the mixture of starch and flour with a ratio of 1:1. Remove the marinade sauce on the chicken dice. Roll the chicken dice in the powder mixture after dipping in the whisked egg. Fry by repeating the following for 2-3 times: (1) Fry for 90 sec in 160-180C oil; (2) Stand for 60 sec while draining oil; (3) Break the crispy surface and fry again. At the last time, fry for 30 sec in 200C oil. Notes: Do not fry too many chicken dices in one batch, so as to avoid the sudden drop in oil temperature. The time for frying depends on the size of chicken. In practice, what I did was to (1) fry one batch until the surface of the chicken dice just turns light yellow over a time period of 60-90 sec; (2) let the batch stand for some time until another batch is finished; (3) fry the first batch again until the color is deeper or becomes golden. The key is to control the oil temperature. Do not let the surface color change too quickly - that means the temperature is too high. Remove solid wastes in the oil between batches. References: Recipe 1 Recipe 2 Recipe 3"},{"title":"Multi-Objective Optimization","permalink":"http://smanist.github.io/2018/08/30/Multi-objective-optimization/","text":"An incomplete review. Introduction In a previous article, we discussed Bayesian optimization for single objective problems. This article will discuss the multi-objective optimization (MO) and provide a partial review of the classical and the Bayesian MO algorithms. Defining a multi-objective optimization Some of the mathematical contents follow this lecture note. Formally, an MO is written as, argminxf(x)=[f1(x),&#x22EF;,fn(x)]s.t.cE(x)=0cI(x)&#x2265;0xlb&#x2264;x&#x2264;xub\\displaystyle \\begin{aligned} {\\mathop{\\mathrm{arg\\,min}}\\limits_{\\mathbf{x}}} &amp;\\quad {\\mathbf{f}}({\\mathbf{x}})=[f_1({\\mathbf{x}}),\\cdots,f_n({\\mathbf{x}})] \\\\ {\\mathrm{s.t.}}&amp;\\quad {\\mathbf{c}}_E({\\mathbf{x}}) = 0 \\\\ &amp;\\quad {\\mathbf{c}}_I({\\mathbf{x}}) \\ge 0 \\\\ &amp;\\quad {\\mathbf{x}}_{lb} \\le {\\mathbf{x}}\\le {\\mathbf{x}}_{ub} \\end{aligned} &#x200B;&#x200B;x&#x200B;argmin&#x200B;&#x200B;&#x200B;s.t.&#x200B;&#x200B;&#x200B;&#x200B;&#x200B;f(x)=[f&#x200B;1&#x200B;&#x200B;(x),&#x22EF;,f&#x200B;n&#x200B;&#x200B;(x)]&#x200B;c&#x200B;E&#x200B;&#x200B;(x)=0&#x200B;c&#x200B;I&#x200B;&#x200B;(x)&#x2265;0&#x200B;x&#x200B;lb&#x200B;&#x200B;&#x2264;x&#x2264;x&#x200B;ub&#x200B;&#x200B;&#x200B;&#x200B; or simply writing the constraints as x&#x2208;X{\\mathbf{x}}\\in{\\mathcal{X}}x&#x2208;X, where X{\\mathcal{X}}X is the feasible design space. Assume that fi&#x2217;f_i^*f&#x200B;i&#x200B;&#x2217;&#x200B;&#x200B; is the minimum attainable value of the iiith objective in the feasible design space, i.e. fi&#x2217;f_i^*f&#x200B;i&#x200B;&#x2217;&#x200B;&#x200B; is the solution to the single-objective optimization (SO) consisting of the iiith objective and all the constraints of the MO. The collection of all these solutions f&#x2217;=[f1&#x2217;,&#x22EF;,fn&#x2217;]{\\mathbf{f}}^*=[f_1^*,\\cdots,f_n^*]f&#x200B;&#x2217;&#x200B;&#x200B;=[f&#x200B;1&#x200B;&#x2217;&#x200B;&#x200B;,&#x22EF;,f&#x200B;n&#x200B;&#x2217;&#x200B;&#x200B;] is defined as the ideal objective vector. In a typical MO problem, such a point is not attainable. That means no single solution exists that simultaneously optimizes each objective &#x2013; this is the fundamental problem in MO. When f&#x2217;{\\mathbf{f}}^*f&#x200B;&#x2217;&#x200B;&#x200B; is unattainable, the objective functions are said to be conflicting and there exists a (possibly infinite) number of Pareto optimal solutions. A solution is called Pareto optimal if none of the objectives can be decreased without increasing some of the other objectives. Two Pareto optimal solutions are mutually nondominated. That means there exists some objectives in one solution that are smaller than those in the other solution. The dominance is more precisely defined via the partial ordering, or the dominance relation between the design vectors x{\\mathbf{x}}x. x1{\\mathbf{x}}_1x&#x200B;1&#x200B;&#x200B; dominates x2{\\mathbf{x}}_2x&#x200B;2&#x200B;&#x200B;, denoted x1&#x2AAF;x2{\\mathbf{x}}_1\\preceq{\\mathbf{x}}_2x&#x200B;1&#x200B;&#x200B;&#x2AAF;x&#x200B;2&#x200B;&#x200B;, if (1) fi(x1)&#x2264;fi(x2)f_i({\\mathbf{x}}_1)\\leq f_i({\\mathbf{x}}_2)f&#x200B;i&#x200B;&#x200B;(x&#x200B;1&#x200B;&#x200B;)&#x2264;f&#x200B;i&#x200B;&#x200B;(x&#x200B;2&#x200B;&#x200B;) for i=1,&#x22EF;,ni=1,\\cdots,ni=1,&#x22EF;,n and (2) &#x2203;j&#x2208;{1,&#x22EF;,n}\\exists j\\in \\{ 1,\\cdots,n\\}&#x2203;j&#x2208;{1,&#x22EF;,n}, fj(x1)&lt;fj(x2)f_j({\\mathbf{x}}_1)&lt; f_j({\\mathbf{x}}_2)f&#x200B;j&#x200B;&#x200B;(x&#x200B;1&#x200B;&#x200B;)&lt;f&#x200B;j&#x200B;&#x200B;(x&#x200B;2&#x200B;&#x200B;). The corresponding objective vectors are denoted f1&#x2AAF;f2{\\mathbf{f}}_1\\preceq{\\mathbf{f}}_2f&#x200B;1&#x200B;&#x200B;&#x2AAF;f&#x200B;2&#x200B;&#x200B;. The dominance is strict, denoted x1&#x227A;x2{\\mathbf{x}}_1\\prec{\\mathbf{x}}_2x&#x200B;1&#x200B;&#x200B;&#x227A;x&#x200B;2&#x200B;&#x200B; and f1&#x227A;f2{\\mathbf{f}}_1\\prec{\\mathbf{f}}_2f&#x200B;1&#x200B;&#x200B;&#x227A;f&#x200B;2&#x200B;&#x200B;, if (2) is true for all jjj&#x2019;s. Using the dominance relation, a solution x{\\mathbf{x}}x is (1) globally Pareto optimal if x&#x2AAF;x&#x2032;{\\mathbf{x}}\\preceq{\\mathbf{x}}&apos;x&#x2AAF;x&#x200B;&#x2032;&#x200B;&#x200B;, &#x2200;x&#x2032;&#x2208;X\\forall{\\mathbf{x}}&apos;\\in{\\mathcal{X}}&#x2200;x&#x200B;&#x2032;&#x200B;&#x200B;&#x2208;X, (2) locally Pareto optimal if &#x2203;&#x3F5;\\exists\\epsilon&#x2203;&#x3F5;, x&#x2AAF;x&#x2032;{\\mathbf{x}}\\preceq{\\mathbf{x}}&apos;x&#x2AAF;x&#x200B;&#x2032;&#x200B;&#x200B;, &#x2200;x&#x2032;,&#x2225;x&#x2212;x&#x2032;&#x2225;&lt;&#x3F5;\\forall{\\mathbf{x}}&apos;,\\lVert{\\mathbf{x}}-{\\mathbf{x}}&apos;\\rVert&lt;\\epsilon&#x2200;x&#x200B;&#x2032;&#x200B;&#x200B;,&#x2225;x&#x2212;x&#x200B;&#x2032;&#x200B;&#x200B;&#x2225;&lt;&#x3F5;. All globally (locally) Pareto optimal solutions form the global (local) Pareto set Xp{\\mathcal{X}}^pX&#x200B;p&#x200B;&#x200B; and its image in the objective space is the global (local) Pareto front F{\\mathcal{F}}F. The ideal objective vector f&#x2217;{\\mathbf{f}}^*f&#x200B;&#x2217;&#x200B;&#x200B; is more formally defined by setting its iiith entry to be [f&#x2217;]i=infx&#x2208;Xpfi(x),i=1,&#x22EF;,n\\displaystyle [{\\mathbf{f}}^*]_i = \\inf_{ {\\mathbf{x}}\\in{\\mathcal{X}}^p } f_i({\\mathbf{x}}),\\quad i=1,\\cdots,n [f&#x200B;&#x2217;&#x200B;&#x200B;]&#x200B;i&#x200B;&#x200B;=&#x200B;x&#x2208;X&#x200B;p&#x200B;&#x200B;&#x200B;inf&#x200B;&#x200B;f&#x200B;i&#x200B;&#x200B;(x),i=1,&#x22EF;,n Similarly, the nadir objective vector fn{\\mathbf{f}}^nf&#x200B;n&#x200B;&#x200B; is defined by setting its iiith entry to be [fn]i=supx&#x2208;Xpfi(x),i=1,&#x22EF;,n\\displaystyle [{\\mathbf{f}}^n]_i = \\sup_{ {\\mathbf{x}}\\in{\\mathcal{X}}^p } f_i({\\mathbf{x}}),\\quad i=1,\\cdots,n [f&#x200B;n&#x200B;&#x200B;]&#x200B;i&#x200B;&#x200B;=&#x200B;x&#x2208;X&#x200B;p&#x200B;&#x200B;&#x200B;sup&#x200B;&#x200B;f&#x200B;i&#x200B;&#x200B;(x),i=1,&#x22EF;,n The ideal and nadir objective vectors define the lower and upper bounds of the Pareto front and thus can be used for normalization. The iiith entry of the normalized objective vector is [f&#xAF;p]i=[fp]i&#x2212;[f&#x2217;]i[fn]i&#x2212;[f&#x2217;]i\\displaystyle [\\bar{ {\\mathbf{f}}}^p]_i = \\frac{ [{\\mathbf{f}}^p]_i-[{\\mathbf{f}}^*]_i }{ [{\\mathbf{f}}^n]_i-[{\\mathbf{f}}^*]_i } [&#x200B;f&#x200B;&#xAF;&#x200B;&#x200B;&#x200B;p&#x200B;&#x200B;]&#x200B;i&#x200B;&#x200B;=&#x200B;[f&#x200B;n&#x200B;&#x200B;]&#x200B;i&#x200B;&#x200B;&#x2212;[f&#x200B;&#x2217;&#x200B;&#x200B;]&#x200B;i&#x200B;&#x200B;&#x200B;&#x200B;[f&#x200B;p&#x200B;&#x200B;]&#x200B;i&#x200B;&#x200B;&#x2212;[f&#x200B;&#x2217;&#x200B;&#x200B;]&#x200B;i&#x200B;&#x200B;&#x200B;&#x200B; The utopian objective vector is defined as fu=f&#x2217;&#x2212;e{\\mathbf{f}}^u={\\mathbf{f}}^*-{\\mathbf{e}}f&#x200B;u&#x200B;&#x200B;=f&#x200B;&#x2217;&#x200B;&#x200B;&#x2212;e where [e]i&gt;0[{\\mathbf{e}}]_i&gt;0[e]&#x200B;i&#x200B;&#x200B;&gt;0 for i=1,&#x22EF;,ni=1,\\cdots,ni=1,&#x22EF;,n, which is useful in some MO algorithms. This vector is too good to attain and hence utopian. Finally, the individual minimum (IM) objective vectors {fkim}k=1n\\{ {\\mathbf{f}}_k^{im} \\}_{k=1}^n{f&#x200B;k&#x200B;im&#x200B;&#x200B;}&#x200B;k=1&#x200B;n&#x200B;&#x200B; are introduced to further characterize the Pareto front. Geometrically, they are the &#x201C;corners&#x201D; of a Pareto front, which attains the minimum value of at least one of the objectives. The kkkth fim{\\mathbf{f}}^{im}f&#x200B;im&#x200B;&#x200B; is defined as, fkim&#x2208;F,[fkim]k=[f&#x2217;]k\\displaystyle {\\mathbf{f}}_k^{im}\\in{\\mathcal{F}},\\quad [{\\mathbf{f}}_k^{im}]_k = [{\\mathbf{f}}^*]_k f&#x200B;k&#x200B;im&#x200B;&#x200B;&#x2208;F,[f&#x200B;k&#x200B;im&#x200B;&#x200B;]&#x200B;k&#x200B;&#x200B;=[f&#x200B;&#x2217;&#x200B;&#x200B;]&#x200B;k&#x200B;&#x200B; The IM objective vectors form the convex hull of individual minima (CHIM), which are used in some of the MO algorithms. In the 2-objective case, CHIM is a segment connecting the two IM objective vectors. Classical MO algorithms Some of the discussion follows this lecture note. Generating a point on the Pareto front typically requires solving an optimization problem and generating a set of Pareto points can be computationally expensive. Therefore, a common question to ask before solving an MO is: Is it necessary to solve the problem as an MO? If sufficient preference information on the objectives about the problem is available, the MO could be taken care of using one single-objective optimization (SO). This is the so-called a priori approach. The advantage is that the optimization only needs to be carried out once, but the disadvantages is that one needs to specify proper preferences over the objectives. The other type of method is the a posteriori approach, which works in a reversed manner. A representative set of Pareto front is generated first, typically via multiple runs of optimization, and the final design is identified within the solution sets. This approach is useful for problems having objectives with limited user knownledge. Besides the a priori and a posteriori approaches, there are also non-preference and interactive methods. However, these will not be discussed in this article. A priori approach The a priori approach is closely related to the idea of scalarization, i.e.&#xA0;the aggregation of multiple objectives. Essentially, a utility function is required to quantify the preference over different solutions. A utility function satisfies (1) u(x1)&lt;u(x2)u({\\mathbf{x}}_1)&lt;u({\\mathbf{x}}_2)u(x&#x200B;1&#x200B;&#x200B;)&lt;u(x&#x200B;2&#x200B;&#x200B;) if x1&#x227A;x2{\\mathbf{x}}_1\\prec{\\mathbf{x}}_2x&#x200B;1&#x200B;&#x200B;&#x227A;x&#x200B;2&#x200B;&#x200B; and (2) u(x1)=u(x2)u({\\mathbf{x}}_1)=u({\\mathbf{x}}_2)u(x&#x200B;1&#x200B;&#x200B;)=u(x&#x200B;2&#x200B;&#x200B;) if x1&#x2280;x2{\\mathbf{x}}_1\\nprec{\\mathbf{x}}_2x&#x200B;1&#x200B;&#x200B;&#x2280;x&#x200B;2&#x200B;&#x200B; and x2&#x2280;x1{\\mathbf{x}}_2\\nprec{\\mathbf{x}}_1x&#x200B;2&#x200B;&#x200B;&#x2280;x&#x200B;1&#x200B;&#x200B;. Two typical scalarization approaches are the &#x3F5;\\epsilon&#x3F5;-constraint method and the weighted metric method. &#x3B5;-constraint The &#x3F5;\\epsilon&#x3F5;-constraint method is an effective approach for converting an MO into only one SO, if sufficient information is known about the optimization problem. Specifically, the idea is to optimize only one objective while making sure other objectives are not too large, i.e.&#xA0;below certain user-specified upper bounds. The utility function is simply u(x)=fj(x)u({\\mathbf{x}})=f_j({\\mathbf{x}})u(x)=f&#x200B;j&#x200B;&#x200B;(x), where j&#x2208;{1,&#x22EF;,n}j\\in\\{ 1,\\cdots,n \\}j&#x2208;{1,&#x22EF;,n}. The method works by adding extra constraints to the SO, argminxu(x)s.t.x&#x2208;Xfi(x)&#x2264;&#x3F5;i,i&#x2260;j,i&#x2208;{1,&#x22EF;,n}\\displaystyle \\begin{aligned} {\\mathop{\\mathrm{arg\\,min}}\\limits_{\\mathbf{x}}} &amp;\\quad u({\\mathbf{x}}) \\\\ {\\mathrm{s.t.}}&amp;\\quad {\\mathbf{x}}\\in{\\mathcal{X}}\\\\ &amp;\\quad f_i({\\mathbf{x}})\\leq \\epsilon_i,\\quad i\\neq j,i\\in\\{ 1,\\cdots,n \\} \\end{aligned} &#x200B;&#x200B;x&#x200B;argmin&#x200B;&#x200B;&#x200B;s.t.&#x200B;&#x200B;&#x200B;&#x200B;u(x)&#x200B;x&#x2208;X&#x200B;f&#x200B;i&#x200B;&#x200B;(x)&#x2264;&#x3F5;&#x200B;i&#x200B;&#x200B;,i&#x2260;j,i&#x2208;{1,&#x22EF;,n}&#x200B;&#x200B; If the ranges of the objectives are known a priori, it is possible to obtain the complete Pareto front by excuting above procedure repeatedly with each run using a different set of &#x3F5;\\epsilon&#x3F5;&#x2019;s. Weighted metric The weighted metric (WM) of f{\\mathbf{f}}f is defined as, up(f)=(&#x2211;i=1nwi&#x2223;fi&#x2212;firef&#x2223;p)1/p\\displaystyle u_p({\\mathbf{f}}) = \\left(\\sum_{i=1}^n w_i|f_i-f_i^{ref}|^p\\right)^{1/p} u&#x200B;p&#x200B;&#x200B;(f)=(&#x200B;i=1&#x200B;&#x2211;&#x200B;n&#x200B;&#x200B;w&#x200B;i&#x200B;&#x200B;&#x2223;f&#x200B;i&#x200B;&#x200B;&#x2212;f&#x200B;i&#x200B;ref&#x200B;&#x200B;&#x2223;&#x200B;p&#x200B;&#x200B;)&#x200B;1/p&#x200B;&#x200B; where p&#x2208;[1,&#x221E;]p\\in [1,\\infty]p&#x2208;[1,&#x221E;], wi&gt;0w_i&gt;0w&#x200B;i&#x200B;&#x200B;&gt;0 and typically &#x2211;i=1nwi=1\\sum_{i=1}^n w_i=1&#x2211;&#x200B;i=1&#x200B;n&#x200B;&#x200B;w&#x200B;i&#x200B;&#x200B;=1, and fref{\\mathbf{f}}^{ref}f&#x200B;ref&#x200B;&#x200B; is a reference point. The figure illustrates two special cases. The first one is p=1p=1p=1 (WM1WM_1WM&#x200B;1&#x200B;&#x200B; in the figure), in which case the method is equivalent to the weighted sum method. This approach guarantees to find the complete Pareto front if it is convex. However, such is not guaranteed for non-convex case. Moreover, a uniform distribtuion of weights typically does not result in a uniformly distributed Pareto set. The second case is p=&#x221E;p=\\inftyp=&#x221E; (WM&#x221E;WM_\\inftyWM&#x200B;&#x221E;&#x200B;&#x200B; in the figure), where the method becomes the Tchebycheff metric. This approach guarantees to find the complete Pareto front no matter whether it is convex or not. However, the reference point has to satisfy fref&#x2AAF;f&#x2217;{\\mathbf{f}}^{ref}\\preceq{\\mathbf{f}}^*f&#x200B;ref&#x200B;&#x200B;&#x2AAF;f&#x200B;&#x2217;&#x200B;&#x200B;. An extension of WM is the rotated WM, which will not be discussed in detail here. Illustration of the concepts associated with Pareto front and several MO algorithms. A posteriori approach The a posteriori approach is usually iterative and roughly fall into two categories. One is based on special formulations of mathematical programming, and can be considered an iterative a priori method that generates a Pareto point per iteration. The other, which is typically based on evolutionary algorithms (EAs), improves a set of (potential) Pareto points simultaneously per iteration. Using mathematical programming Two objectives The two-objective problem has been studied extensively and is simpler than problems of more objectives. Two classical approaches are Normal Boundary Intersection (NBI) Das1998 and (Normalized) Normal Constraint (NC) Messac2003, as illustrated in the above figure. The NBI and NC can be considered the generalization of EC: Essentially, these methods convert the MO into an SO by introducing extra constraints and redefining the objective, so that the solution to the SO produces a point on the Pareto front. The extra constraints depends on a base point (or an anchor point) b{\\mathbf{b}}b on the CHIM, or the utopia line in two-objective case. A discrete approximation of the Pareto front is constructed by choosing various b{\\mathbf{b}}b along the utopia line and solving the resulting SO&#x2019;s. As the reader might have noted, these approaches require the knowledge of the IM&#x2019;s, which has to be solved before the application of the MO algorithms. In the NBI formulation, the objective vector is constrained to be on a line defined by b{\\mathbf{b}}b and a direction vector n{\\mathbf{n}}n that is normal to the utopia line. The MO is converted to an SO for finding the intersection between the Pareto front and the line constraint, and hence the name NBI. argminxt(x)s.t.x&#x2208;Xf=b+tn\\displaystyle \\begin{aligned} {\\mathop{\\mathrm{arg\\,min}}\\limits_{\\mathbf{x}}} &amp;\\quad t({\\mathbf{x}}) \\\\ {\\mathrm{s.t.}}&amp;\\quad {\\mathbf{x}}\\in{\\mathcal{X}}\\\\ &amp;\\quad {\\mathbf{f}}={\\mathbf{b}}+t{\\mathbf{n}}\\end{aligned} &#x200B;&#x200B;x&#x200B;argmin&#x200B;&#x200B;&#x200B;s.t.&#x200B;&#x200B;&#x200B;&#x200B;t(x)&#x200B;x&#x2208;X&#x200B;f=b+tn&#x200B;&#x200B; In the NC formulation, the objective is constrained to be on a half-plane defined by b{\\mathbf{b}}b and a direction vector t{\\mathbf{t}}t aligned with the utopia line. The MO is converted to an SO for finding the minimum of one of the objectives (the second objective in the illustrated case) given the extra constraint. argminxf1(x)s.t.x&#x2208;X(f&#x2212;b)&#x22C5;t&#x2265;0\\displaystyle \\begin{aligned} {\\mathop{\\mathrm{arg\\,min}}\\limits_{\\mathbf{x}}} &amp;\\quad f_1({\\mathbf{x}}) \\\\ {\\mathrm{s.t.}}&amp;\\quad {\\mathbf{x}}\\in{\\mathcal{X}}\\\\ &amp;\\quad ({\\mathbf{f}}-{\\mathbf{b}})\\cdot{\\mathbf{t}}\\geq 0 \\end{aligned} &#x200B;&#x200B;x&#x200B;argmin&#x200B;&#x200B;&#x200B;s.t.&#x200B;&#x200B;&#x200B;&#x200B;f&#x200B;1&#x200B;&#x200B;(x)&#x200B;x&#x2208;X&#x200B;(f&#x2212;b)&#x22C5;t&#x2265;0&#x200B;&#x200B; In [Messac2003], a normalization step is applied before solving the SO, which slightly simplifies the normal constraint. Three or more objectives The ideas of NBI and NC are easily extended to the cases of more objectives, as have been done in [Das1998] and [Messac2003]. However, both methods may not be able to explore the complete Pareto front, resulting in some unobtainable regions. This is illustrated in the figure below: Assuming the objective space is a sphere centered at the origin, the Pareto front F{\\mathcal{F}}F is an octant of the sphere (Green) and the CHIM is an equilateral triangle (Blue). However, the projection of the Pareto front on the CHIM plane, which is defined as CHIM+, is a region encompassed by three arcs (Red). That means, using a base point on the CHIM, one can only obtain solutions encompassed by the black dashed lines on the Pareto front. As a remedy, Messac2004 proposed an improved NBI algorithm to explore the complete Pareto front by adding more base points outside the CHIM, i.e.&#xA0;on the CHIM+. Another approach, Directed Search Domain (DSD), is proposed in Erfani2011. In DSD, the NBI constraint is replaced by cone constraints that is able to explore the complete Pareto front by expanding or rotating the cone. The Messac2004 and Erfani2011 algorithms are more like patches to the classical NBI and NC algorithms. These &#x201C;patched&#x201D; algorithms contain empirical parameters that have to be tuned and there is no guarantee of finding the complete Pareto front. More systematic algorithms are proposed in MG2009 as Successive Pareto Optimization (SPO) and in Motta2012 as Modified NBI and NC [Motta2012]. The two methods share a similar idea as recursive construction of the Pareto front. To solve an MO of nnn objectives, i.e.&#xA0;find the nnn-dimensional Pareto front F{\\mathcal{F}}F, nnn problems of n&#x2212;1n-1n&#x2212;1 objectives are solved to generate the nnn Pareto fronts &#x2202;F\\partial{\\mathcal{F}}&#x2202;F of (n&#x2212;1)(n-1)(n&#x2212;1) dimensions, which are the boundaries of F{\\mathcal{F}}F. Subsequently, a set of base points are distributed uniformly between these boundaries, so as to cover the CHIM+ (almost) evenly and capture the complete Pareto front F{\\mathcal{F}}F. Finally, at the recursion boundary, the SO&#x2019;s associated with the objectives are solved to determine the IM&#x2019;s. Take a 3-objective problem for example, as shown in the figure below. First, the IM&#x2019;s are found. Next, the NBI procedure is applied to find &#x2202;F13\\partial{\\mathcal{F}}_{13}&#x2202;F&#x200B;13&#x200B;&#x200B; for the MO associated with objectives 1 and 3. Same procedures are done for &#x2202;F12\\partial{\\mathcal{F}}_{12}&#x2202;F&#x200B;12&#x200B;&#x200B; and &#x2202;F23\\partial{\\mathcal{F}}_{23}&#x2202;F&#x200B;23&#x200B;&#x200B;. Finally, base points will be distributed over CHIM+, which is emcompassed by &#x2202;F12\\partial{\\mathcal{F}}_{12}&#x2202;F&#x200B;12&#x200B;&#x200B;, &#x2202;F13\\partial{\\mathcal{F}}_{13}&#x2202;F&#x200B;13&#x200B;&#x200B; and &#x2202;F23\\partial{\\mathcal{F}}_{23}&#x2202;F&#x200B;23&#x200B;&#x200B; 1, to identify the complete Pareto front by applying the NBI procedure again. Illustration of Pareto front of three objectives. Using evolutionary algorithm There are two out-standing EAs in this category, which are Non-dominated Sorting Genetic Algorithm-II (NSGA-II) in Deb2002 and Strength Pareto Evolutionary Algorithm 2 (SPEA-2) in Zitzler2001. It appears they have become standard evolutionary algorithms for MO, against which new algorithms will be compared. However, I am not going to talk too much about EAs, which are not my favorite. Some introductory materials are found here. A comparison of evolutional algorithms for MO is found in, for example, Zitzler2000 and Bader2011. Nevertheless, one important thing to learn from the EAs is the construction of the fitness function of a Pareto solution - How much it is dominating others, or how much it is improving the Pareto front? This requires the proper definition of indicators describing the quality of the Pareto front. These indicators have a broader range of application in, for example, the assessment of convergence and the construction of acquisition functions in Bayesian MO algorithms. In Zitzler2003, a number of criteria for the quality of the Pareto solution are gathered and compared. Three commonly used criteria include: The &#x3F5;\\epsilon&#x3F5;, R2R_2R&#x200B;2&#x200B;&#x200B; and hypervolume indicators. The &#x3F5;\\epsilon&#x3F5;-indicator characterizes the minimum separation between two Pareto solutions F{\\mathcal{F}}F and G{\\mathcal{G}}G. The additive form is, I&#x3F5;(F,G)=inf&#x3F5;{&#x2200;g&#x2208;G&#x2203;f&#x2208;F:f+&#x3F5;&#x2AAF;g}\\displaystyle I_\\epsilon({\\mathcal{F}}, {\\mathcal{G}}) = \\inf_{\\epsilon}\\{\\forall{\\mathbf{g}}\\in{\\mathcal{G}}\\exists{\\mathbf{f}}\\in{\\mathcal{F}}: {\\mathbf{f}}+\\epsilon\\preceq {\\mathbf{g}}\\} I&#x200B;&#x3F5;&#x200B;&#x200B;(F,G)=&#x200B;&#x3F5;&#x200B;inf&#x200B;&#x200B;{&#x2200;g&#x2208;G&#x2203;f&#x2208;F:f+&#x3F5;&#x2AAF;g} The multiplicative form is defined in a similar manner. The R2R_2R&#x200B;2&#x200B;&#x200B; indicator was initially developed in Hansen1998 for the case that the Pareto solutions are measured using a set of utility functions U{\\mathcal{U}}U, e.g.&#xA0;the WM functions parameterized by the weight vectors w{\\mathbf{w}}w. The utility fuctions are assigned some weights, or &#x201C;probablities&#x201D; p(u)p(u)p(u), representing the preference information. The indicator is defined as the weighted or expected improvement of the best value of utility functions, IR2(F,G;U)=&#x222B;u&#x2208;U[u&#x2217;(F)&#x2212;u&#x2217;(G)]p(u)du\\displaystyle I_{R_2}({\\mathcal{F}}, {\\mathcal{G}}; {\\mathcal{U}}) = \\int_{u\\in{\\mathcal{U}}}[u^*({\\mathcal{F}})-u^*({\\mathcal{G}})]p(u)du I&#x200B;R&#x200B;2&#x200B;&#x200B;&#x200B;&#x200B;(F,G;U)=&#x222B;&#x200B;u&#x2208;U&#x200B;&#x200B;[u&#x200B;&#x2217;&#x200B;&#x200B;(F)&#x2212;u&#x200B;&#x2217;&#x200B;&#x200B;(G)]p(u)du where u&#x2217;(&#x25A1;)=inf{u(f),f&#x2208;&#x25A1;}u^*(\\Box)=\\inf\\{ u({\\mathbf{f}}),{\\mathbf{f}}\\in\\Box \\}u&#x200B;&#x2217;&#x200B;&#x200B;(&#x25A1;)=inf{u(f),f&#x2208;&#x25A1;}. When there is only one utility function, IR2(F,G)=u&#x2217;(F)&#x2212;u&#x2217;(G)I_{R_2}({\\mathcal{F}},{\\mathcal{G}})=u^*({\\mathcal{F}})-u^*({\\mathcal{G}})I&#x200B;R&#x200B;2&#x200B;&#x200B;&#x200B;&#x200B;(F,G)=u&#x200B;&#x2217;&#x200B;&#x200B;(F)&#x2212;u&#x200B;&#x2217;&#x200B;&#x200B;(G). The (binary) hypervolume indicator is defined as the &#x201C;size&#x201D; of the margin between two Pareto solutions F{\\mathcal{F}}F and G{\\mathcal{G}}G, if one dominates the other. More formally, it is the measure &#x39B;\\Lambda&#x39B; of the set containing points that are dominated by F{\\mathcal{F}}F but not by G{\\mathcal{G}}G, IH(F,G)=&#x39B;{h&#x2223;h&#x2AB0;F&#x2227;h&#x2AAF;G}\\displaystyle I_H({\\mathcal{F}}, {\\mathcal{G}}) = \\Lambda\\{ {\\mathbf{h}}|{\\mathbf{h}}\\succeq{\\mathcal{F}}\\wedge {\\mathbf{h}}\\preceq{\\mathcal{G}}\\} I&#x200B;H&#x200B;&#x200B;(F,G)=&#x39B;{h&#x2223;h&#x2AB0;F&#x2227;h&#x2AAF;G} As mentioned above, there are two typical applications of these binary indicators. The first one is for convergence check. One can set one input to be the true Pareto solution (for benchmark problems), or a set consisting of the Utopian point (for real problems). The second application is to construct a unary indicator as the utility function of a potential solution f{\\mathbf{f}}f by setting F=G&#x222A;{f}{\\mathcal{F}}={\\mathcal{G}}\\cup\\{ {\\mathbf{f}}\\}F=G&#x222A;{f}, where G{\\mathcal{G}}G is a reference Pareto solution. Bayesian MO algorithms The algorithms to be discussed in this section are considered Bayesian because the optimization process generates the solution based on the observed samples of the objective functions, instead of the objective functions themselves as in classical methods. This bares the same idea as in the Bayesian SO algorithms. A surrogate has to be constructed using the observed samples as a replacement of the objective functions, or their utility function. During the optimization, the exploitation and exploration strategy has to be incorporated so as to account for the uncertainty of the surrogate model, as was done in Bayesian SO algorithms. The Bayesian MO algorithms have deep roots in the classical methods. Depending on how classical methods are utilized, the algorithms are classified into the indirect and the direct methods. Indirect methods In the indirect methods, no special acquisition functions are developed for MO. Instead, the MO is converted to an SO as was done in the classical methods, such as WS and SPO. In a sense, the utility function in a classical method is directly used as an acqusition function. The resulting SO is solved using a BO algorithm, which is usually referred to as inner optimization. One such example is the ParEGO algorithm in Knowles2006. This is probably the first important Bayesian MO algorithm. The utility function is developed using the augmented Tchebycheff function, which is a combination of the u&#x221E;u_\\inftyu&#x200B;&#x221E;&#x200B;&#x200B; and u1u_1u&#x200B;1&#x200B;&#x200B; functions, u(f)=maxiwifi+&#x3C1;&#x2211;i=1nwifi\\displaystyle u({\\mathbf{f}}) = \\max_i w_i f_i + \\rho \\sum_{i=1}^n w_i f_i u(f)=&#x200B;i&#x200B;max&#x200B;&#x200B;w&#x200B;i&#x200B;&#x200B;f&#x200B;i&#x200B;&#x200B;+&#x3C1;&#x200B;i=1&#x200B;&#x2211;&#x200B;n&#x200B;&#x200B;w&#x200B;i&#x200B;&#x200B;f&#x200B;i&#x200B;&#x200B; where &#x3C1;\\rho&#x3C1; is a small positive value typically set to 0.05. In each run, a random weight vector is generated and a point on the Pareto front is found. A noteworthy disadvantage of ParEGO is that the uniformity of the Pareto solution is not guaranteed. Using a similar idea, the algorithms of EC, NBI, NC are easily combined with Bayesian SO algorithms. A major disadvantage of the indirect method is that, in the inner optimization, the BO algorithm would cost multiple evaluations of the black-box objective functions only to find one point on the Pareto front. A more efficient approach would be the direct method, which produces one point on the Pareto front per evaluation. Direct methods In the direct methods, the BO algorithm is executed with special MO acquisition functions. Two historical methods One precursor in this category is Jeong2005. The MO is carried out using an evolutionary algorithm, where the fitness is defined as the expected improvements (EI) of the single objectives. Another MO acquisition function is developed in Keane2006. It is the first paper extending EI and probablity of improvement (PoI) of SO to MO. The EI was defined as the product of the PoI and an Euclidean distance-based improvement function. However, the formulation is limited to the 2-objective case. Two modern methods Later, the concept of hypervolume is introduced into the development of MO acquisition functions. It is mainly developed into two families. One family is the SMS-EGO method proposed in Ponweiser2008. It is an extension of the classical acqusition function of lower confidence bound (LCB), i.e.&#xA0;the improvement of HV due to LCB. In addition, a penalty is added to points that do not improve the Pareto front and an additive epsilon-dominance term is added to points close to Pareto front to smooth the distribution of the acquisition function. It was shown to outperform ParEGO and standard EAs like NSGA-II and SPEA-2. This method is easy to implement and has been widely used. The other family is based on the S-metric expected improvement (SExI). It is the hypervolume version of EI for MO, originally proposed in Emmerich2005, as an extension of the classical EI for SO. The formulation is straight-forward by replacing the improvement function with the unary hypervolume indocator, EI(x)=&#x222B;I(f)p(f;x)df\\displaystyle EI({\\mathbf{x}}) = \\int I({\\mathbf{f}})p({\\mathbf{f}};{\\mathbf{x}})d{\\mathbf{f}}EI(x)=&#x222B;I(f)p(f;x)df where I(f)=IH(F&#x222A;{f},F)I({\\mathbf{f}}) = I_H({\\mathcal{F}}\\cup\\{ {\\mathbf{f}}\\}, {\\mathcal{F}})I(f)=I&#x200B;H&#x200B;&#x200B;(F&#x222A;{f},F) and F{\\mathcal{F}}F is the Pareto front of the current iteration. In [Emmerich2005], the algorithm was called SMS-EMOA (i.e.&#xA0;solved using an evolutionary algorithm) and the integration of hypervolume was carried out using Monte Carlo method. In a later paper, Emmerich2008, an exact integration method is proposed for SExI. However, the computational complexity of the exact ingration method grows exponentially with the problem dimension and number of Pareto points. The algorithm complexity of SExI definitely limits the spread of its application. There are even survey papers that skipped this algorithm in the numerical comparison section due to complexity in the implementation. Nevertheless, the SExI algorithm is improved in Hupkens2015, which claimed to be the fastest algorithm for the 2D and 3D cases. For the general case, however, the fastest algorithm is proposed in Couckuyt2014, which is based on the WFG algorithm. In [Couckuyt2014], the new algorithm is also applied to the MO version of PoI, which is easier to implement than SExI and appears to be equally effective. Comparison The aforementioned algorithms have been systematically compared in the literature. In Wagner2010, the algorithms from [Jeong2005], [Knowles2006], [Keane2006], [Ponweiser2008], and [Emmerich2008] are compared. Three necessary conditions are proposed to detect conceptual problems in the formulations while four desirable properties are identified. It is concluded that [Keane2006] is problematic. [Ponweiser2008] satisfies the essential conditions for acquisition function, but has disadvantages like non-smooth distribution of acquisition function. [Emmerich2008] has the most desirable properties, but is hard to implement. In Zaefferer2013, four algorithms are compared: [Keane2006], [Emmerich2008], [Ponweiser2008], and an evolutional algorithm MSPOT (which I do not care), with SMS-EMOA as the baseline. [Keane2006] was found to be worse than the baseline, which agrees with the discussion in [Wagner2010]. The rest outperformed the baseline, but there was no decisive difference. Further development More algorithms and enhancements are developed in the literature since the proposal of SMS-EGO. Multi-point proposal With the advent of parallel computing, the idea of multi-point proposal was proposed, e.g.&#xA0;in Zhang2009. The idea is to find multiple candidate design vectors that improves the Pareto front and evaluate the black-box function at these new points simultaneously, exploiting the parallelism of the modern computers. In Horn2015, algorithms like [Jeong2005], [Knowles2006] and [Ponweiser2008] are compared and extended with multi-point proposal. The major finding was that, for some algorithms, the multi-point variants did not significantly deteriorate the results. They even improved the approximation quality in some cases. Moreover, the change from the EI to the LCB could improve the results of the internal optimization within ParEGO. Informatics-based approaches This family of approaches are more recent and more &#x201C;Bayesian&#x201D; in the sense that a stronger statistical flavor is involved. Typical examples are stepwise uncertainty reduction (SUR) Picheny2015 and Predictive Entropy Search (PES) Hern&#xE1;ndez-Lobato2016. The idea is to pick a new point at each iteration to maximize the &#x201C;information gain&#x201D; to the current Pareto front. The information gain is typically measured using the Shannon entropy. These methods claim themselves to be &#x201C;intuitive, statistically consistent and efficient&#x201D;, as an alternative to the classical &#x201C;sensible heuristic&#x201D; approaches, such as the hypervolume EI. For academic problems, these methods do seem to be comparable to methods like SMS-EGO. However, the computational cost appears to be higher and the implementation seems to be more complex than all the methods discussed above. Computer implementations I have not found many implementations for Bayesian MO algorithms. Two working libraries I found are GPflowOpt and SUMO. There are some libraries for evolutionary MO algorithms, such as PyGMO and Platypus, but without surrogate capabilities. Probably these libraries can be incorporated into some BO framework for MO purposes. Finally, for the evaluation of these libraries, there are a few standard test cases to play with: MOP: VanVeldhuizen1999 ZDT: Zitzler2000 DTLZ: Deb2005 A precise description is that the base points are distributed on a surface encompassed by the boundaries. The specific definition of this surface is algorithm-dependent. The projection of this surface on the CHIM plane is identical to the CHIM+. Therefore, the projection of the base points are also expected to cover the CHIM+ (almost) evenly.&#x21A9;"},{"title":"Lewis Overthrust","permalink":"http://smanist.github.io/2018/07/29/Lewis-Overthrust/","text":"Where to play with huge snowpatches in summer? -In mountains of high altitude and/or high latitude. Maybe high enough that even glaciers exist. The Glacier National Park (GNP) is one such place to go. Introduction The glaciers are indeed an essential ingredient of the spectacular scenes in GNP. Yet, the scenes could be given an extra layer of &#x201C;awesomeness&#x201D; if the long geological history were taken into account. In a sense, the GNP is the result of the interactions between the terrain, the glacier, the climate, the fauna and flora, etc. over billions of years. And the most fascinating part is probably how the stage was &#x201C;prepared&#x201D; for these interactions by tectonic processes. This stage is the Lewis Overthrust. And its formation is vividly explained in a booklet &#x201C;Rocks, Ice, and Water - The Geology of Waterton-Glacier Park&#x201D;, by David D. Alt and Donald W. Hyndman, 1973. I think it would be better to directly present the excerpt of this book (pp.&#xA0;21-24), instead of myself, a layman, trying to explain the geological mechanisms. The Lewis Overthrust Fault - The Beginning of Mountains Geologists normally expect to find sedimentary rocks stacked in the order they were deposited with the oldest layers at the bottom of the pile and the youngest on top. In Waterton-Glacier Park this expectable order of rock layers is dramatically reversed; Precambrian sedimentary rocks deposited more than one billion years ago are now on top of Cretaceous sedimentary rocks laid down only 70 million years ago! Apparently a slab of Precambrian sedimentary rock several thousand feet thick slid eastward some tens of miles over the much younger Cretaceous sedimentary rocks. The surface on which the sliding movement occurred is called the Lewis Overthrust Fault. Geologists have marvelled at this situation, and attempted to understand it, ever since they first recognized it in the years near the beginning of the twentieth century. For many years geologists argued that a strong force from the west must have pushed the slab of Precambrian sedimentary rock eastward onto the plains. But this vision poses problems: pushing such a long, thin slab of rock from behind without crumpling it is an undertaking similar to pushing a large carpet across a floor without wrinkling it. The rocks, like the carpet, are not strong enough to withstand the necessary force without folding, and the friction in the sliding surface makes it difficult for movement to occur. The Precambrian slab in Waterton-Glacier Park is not crumpled, neither is there evidence in the area west of the Park of any geologic event that could have exerted a strong eastward push. So it is difficult to imagine how this enormous slab of rock was pushed into its present position. Now most geologists are convinced that overthrust faults do not move in response to a push from behind but instead slide downhill under the pull of gravity. This eliminates the problem of understanding how the overthrust slab could withstand a force without crumpling because every particle of rock feels the tug of gravity individually. The problem of overcoming friction in the sliding surface of the fault still remains. If water in the pores of the rock is under sufficient pressure, it will support the rocks above enabling them to move with very little friction. This might have happened in the Cretaceous rocks but would have been most unlikely in the much older Precambrian formations because they were probably much too dry by the time movement occurred on the Lewis Overthrust fault. Some geologists contend that the Precambrian rocks moved because certain layers were weak enough to flow like a viscous fluid carrying the rocks above. They imagine the rocks behaving somewhat like a layer cake filled with soft frosting. Thousands of feet of sedimentary rocks had accumulated in the region of Waterton-Glacier Park by the end of Cretaceous time. Layer after layer of sandstone, mudstone and limestone deposited over a period of many hundreds of millions of years while the region was a level plain flooded at times by shallow seas. The quiet years ended about 70-90 million years ago, during Cretaceous time while giant dinosaurs still roamed the earth. Processes operating deep within the earth slowly raised the continental crust of western North America, with its burden of sedimentary rocks, several thousand feet vertically upward forming a broad crustal arch that had its crest about 100 miles west of Waterton-Glacier Park. Thousands of feet of interlayered limestone, sandstone, and mudstone slowly slanted eastward as uplift proceeded. Tilting such a thick pile of sedimentary rocks, some layers strong and others weak, is somewhat like tilting a thick stack of heavily-buttered pancakes. In both cases the entire stack will eventually begin to slide downward on one or more of the weak layers. That is probably what happened about 50-60 million years ago all along the eastern front of the northern Rockies. Somewhere deep within the pile of sedimentary rocks a weak layer yielded under the strain and the rocks above began to glide slowly eastward down the flank of the broad regional arch still rising in the earth&#x2019;s crust. The huge slab of Precambrian sedimentary rock that is now Waterton-Glacier Park slid an unknown distance eastward, probably more than 30 miles. It moved at least ten miles across the soft sands and muds deposited in the shallow Cretaceous sea that had receded only a few million years previously. As the mass of Precambrian sedimentary rock slowly slid eastward, large gaps opened behind it. The same sort of thing happens when slabs of snow slide down a roof leaving gaps where the moving snow detached itself from the stationary mass that remained behind &#x2013; or the upper end of a glacier pulls away from the mountain at its head. The North Fork Valley, along the western margin of Waterton-Glacier Park, appears to be such a gap pulled open behind the Precambrian slab as it moved eastward on the Lewis Overthrust. It is approximately ten miles wide, probably not enough to account for all the displacement on the Lewis Overthrust fault. In order to find another gap to account for more displacement we must go farther west to the broad Flathead Valley and suggest that the Whitefish Range, west of the North Fork Valley, may also have slid eastward. Early geologists interpreted the North Fork Valley quite differently, arguing that it is a downdropped block of the earth&#x2019;s crust. Rocks in the southern end of the valley, where the bedrock valley floor is exposed, do suggest that the valley floor has dropped vertically downward. But there are reasons to believe that the floor of a pull-apart valley might drop so the two explanations are not incompatible. Mountain ranges north and south of Waterton-Glacier Park also consist of large slabs of rock that slid eastward as the earth&#x2019;s crust arched up to the west. But these ranges do not consist of a single large slab. Instead, they are made of many smaller slabs stacked on each other like a row of fallen dominoes. This kind of structure is also found in part of the eastern portion of Waterton Park. More references: Wikipedia, where a few illustrative figures are provided. Glacier National Park and the Lewis Overthrust"},{"title":"Solving a Multibody Short-Range Interaction Problem","permalink":"http://smanist.github.io/2018/06/23/Multibody-short-range-interaction/","text":"When multiple bodies interact with their neighbours according to a graph. Introduction Recently I wrote a code for solving a certain type of multibody problems - just for fun. One instance of such problem is the truss structure, which can be viewed as a set of points connected by bars that can only deform axially. A graph specifies the connectivity of the points - only the points that are connected interact with each other. Another instance of the problem is certain particle system that appear in material science. The particles only interact with their neighbours. Now the problem is essentially determining the equilibrium geometrical configuration of the multi-body system when it is subject to an external excitation. Such equilibrium can be determined via a certain energy principle, if there is any. Mathematically, the problem is stated as follows. Suppose a multibody system is composed of NNN points {xi}\\{ {\\mathbf{x}}_i\\}{x&#x200B;i&#x200B;&#x200B;} with MMM point pairs {ei=(xi1,xi2)}\\{ {\\mathbf{e}}_i=({\\mathbf{x}}_{i1},{\\mathbf{x}}_{i2})\\}{e&#x200B;i&#x200B;&#x200B;=(x&#x200B;i1&#x200B;&#x200B;,x&#x200B;i2&#x200B;&#x200B;)}. The energy U{\\mathcal{U}}U of the multibody system is defined as, U(u)=&#x2211;i=1MU(xi1,xi2)&#x2261;&#x2211;i=1MUi\\displaystyle {\\mathcal{U}}({\\mathbf{u}}) = \\sum_{i=1}^M U({\\mathbf{x}}_{i1},{\\mathbf{x}}_{i2}) \\equiv \\sum_{i=1}^M U_i U(u)=&#x200B;i=1&#x200B;&#x2211;&#x200B;M&#x200B;&#x200B;U(x&#x200B;i1&#x200B;&#x200B;,x&#x200B;i2&#x200B;&#x200B;)&#x2261;&#x200B;i=1&#x200B;&#x2211;&#x200B;M&#x200B;&#x200B;U&#x200B;i&#x200B;&#x200B; where UiU_iU&#x200B;i&#x200B;&#x200B; is the energy of the iiith point pair and u{\\mathbf{u}}u is a vector containing all the states of the points. Next, assume the external excitation is conservative, i.e.&#xA0;there exists a scalar function V(u){\\mathcal{V}}({\\mathbf{u}})V(u) such that &#x2212;&#x2202;V&#x2202;u-{\\frac{\\partial {\\mathcal{V}}}{\\partial {\\mathbf{u}}}}&#x2212;&#x200B;&#x2202;u&#x200B;&#x200B;&#x2202;V&#x200B;&#x200B; is the external force acting on the points. The system achieves equilibrium at its stationary point, i.e.&#xA0;when the gradient of total energy &#x3A0;=U+V\\Pi={\\mathcal{U}}+{\\mathcal{V}}&#x3A0;=U+V becomes zero, g(u&#x2217;)=&#x2202;&#x3A0;&#x2202;u=0\\displaystyle {\\mathbf{g}}({\\mathbf{u}}^*) = {\\frac{\\partial \\Pi}{\\partial {\\mathbf{u}}}} = 0 g(u&#x200B;&#x2217;&#x200B;&#x200B;)=&#x200B;&#x2202;u&#x200B;&#x200B;&#x2202;&#x3A0;&#x200B;&#x200B;=0 Solution schemes Naive Newton scheme In simple cases, u&#x2217;{\\mathbf{u}}^*u&#x200B;&#x2217;&#x200B;&#x200B; is a minimum point near the initial state. One can employ any standard optimization algorithms to solve the problem, i.e.&#xA0;to minimize &#x3A0;\\Pi&#x3A0; w.r.t. u{\\mathbf{u}}u. Particularly, given the gradient g{\\mathbf{g}}g and the Jacobian J{\\mathbf{J}}J of the energy, J(u&#x2217;)=&#x2202;2&#x3A0;&#x2202;u2\\displaystyle {\\mathbf{J}}({\\mathbf{u}}^*) = \\frac{\\partial^2 \\Pi}{\\partial {\\mathbf{u}}^2} J(u&#x200B;&#x2217;&#x200B;&#x200B;)=&#x200B;&#x2202;u&#x200B;2&#x200B;&#x200B;&#x200B;&#x200B;&#x2202;&#x200B;2&#x200B;&#x200B;&#x3A0;&#x200B;&#x200B; the minimum is found via the Newton-Raphson (NR) procedure, Ji&#x394;ui=&#x2212;giui+1=ui+&#x394;ui\\displaystyle \\begin{aligned} {\\mathbf{J}}_i{\\Delta\\mathbf{u}}_i &amp;= -{\\mathbf{g}}_i \\\\ {\\mathbf{u}}_{i+1} &amp;= {\\mathbf{u}}_i + {\\Delta\\mathbf{u}}_i \\end{aligned} &#x200B;J&#x200B;i&#x200B;&#x200B;&#x394;u&#x200B;i&#x200B;&#x200B;&#x200B;u&#x200B;i+1&#x200B;&#x200B;&#x200B;&#x200B;&#x200B;=&#x2212;g&#x200B;i&#x200B;&#x200B;&#x200B;=u&#x200B;i&#x200B;&#x200B;+&#x394;u&#x200B;i&#x200B;&#x200B;&#x200B;&#x200B; where u0{\\mathbf{u}}_0u&#x200B;0&#x200B;&#x200B; is the initial guess of the solution. By applying the NR procedure to a series of external forces, one obtains the equilibrium path of the system, or the displacement-load curve in structural analysis. Nonlinear schemes There are exceptions that cannot be solved using the naive Newton scheme. Such exceptions occur typically when (1) the initial state is far from the solution, or/and (2) the equilibrium path contains limit points. There are two types of limit points. At a load limit point, a nonzero displacement increment results in a zero load increment. Or put in a different way, increasing (or decreasing) the load would result in the increase/decrease of the displacement on the two sides of the limit point. The case of displacement limit point is the reverse. People have developed various solution schemes to tackle these issues. A review of these schemes is provided in Leon2011. (Also check its Figure 1 for an illustration of the displacement and load limit points.) To introduce these schemes, in the following we consider only the case where the external excitation is linear, &#x2212;&#x2202;V&#x2202;u=&#x3BB;f\\displaystyle -{\\frac{\\partial {\\mathcal{V}}}{\\partial {\\mathbf{u}}}} = \\lambda{\\mathbf{f}}&#x2212;&#x200B;&#x2202;u&#x200B;&#x200B;&#x2202;V&#x200B;&#x200B;=&#x3BB;f where f{\\mathbf{f}}f is a constant vector and the value of &#x3BB;\\lambda&#x3BB; determines the magnitude of the external force. In such case, the total energy of the system is written as, &#x3A0;(u,&#x3BB;)=U(u)&#x2212;&#x3BB;uTf\\displaystyle \\Pi({\\mathbf{u}},\\lambda) = {\\mathcal{U}}({\\mathbf{u}}) - \\lambda {\\mathbf{u}}^T{\\mathbf{f}}&#x3A0;(u,&#x3BB;)=U(u)&#x2212;&#x3BB;u&#x200B;T&#x200B;&#x200B;f N+1 dimensional space formulation Assume that the NR iteration starts at the previous equilibrium point. Treating &#x3BB;\\lambda&#x3BB; as an unknown, in the iiith NR iteration, the linear system is augmented as, [Ji&#x2212;fciTbi][&#x394;ui&#x394;&#x3BB;i]=[&#x2212;giHi]\\displaystyle \\begin{bmatrix} {\\mathbf{J}}_i &amp; -{\\mathbf{f}}\\\\ {\\mathbf{c}}_i^T &amp; b_i \\end{bmatrix} \\begin{bmatrix} {\\Delta\\mathbf{u}}_i \\\\ {\\Delta\\lambda}_i \\end{bmatrix} = \\begin{bmatrix} -{\\mathbf{g}}_i \\\\ H_i \\end{bmatrix} [&#x200B;J&#x200B;i&#x200B;&#x200B;&#x200B;c&#x200B;i&#x200B;T&#x200B;&#x200B;&#x200B;&#x200B;&#x200B;&#x2212;f&#x200B;b&#x200B;i&#x200B;&#x200B;&#x200B;&#x200B;][&#x200B;&#x394;u&#x200B;i&#x200B;&#x200B;&#x200B;&#x394;&#x3BB;&#x200B;i&#x200B;&#x200B;&#x200B;&#x200B;]=[&#x200B;&#x2212;g&#x200B;i&#x200B;&#x200B;&#x200B;H&#x200B;i&#x200B;&#x200B;&#x200B;&#x200B;] where the last row and the coefficients ci{\\mathbf{c}}_ic&#x200B;i&#x200B;&#x200B;, bib_ib&#x200B;i&#x200B;&#x200B; and HiH_iH&#x200B;i&#x200B;&#x200B; are introduced to constrain &#x3BB;\\lambda&#x3BB; and close the linear system. Different choices of these coefficients give rise to different solution schemes. The solution of the augmented system is expressed as, due to Batoz1979, &#x394;&#x3BB;i=Hi&#x2212;ciT&#x394;ugib+ciT&#x394;ufi&#x394;ui=&#x394;&#x3BB;i&#x394;ufi+&#x394;ugi\\displaystyle \\begin{aligned} {\\Delta\\lambda}_i &amp;= \\frac{H_i - {\\mathbf{c}}_i^T{\\Delta\\mathbf{u}}_{gi}}{b + {\\mathbf{c}}_i^T{\\Delta\\mathbf{u}}_{fi}} \\\\ {\\Delta\\mathbf{u}}_i &amp;= {\\Delta\\lambda}_i{\\Delta\\mathbf{u}}_{fi} + {\\Delta\\mathbf{u}}_{gi} \\end{aligned} &#x200B;&#x394;&#x3BB;&#x200B;i&#x200B;&#x200B;&#x200B;&#x394;u&#x200B;i&#x200B;&#x200B;&#x200B;&#x200B;&#x200B;=&#x200B;b+c&#x200B;i&#x200B;T&#x200B;&#x200B;&#x394;u&#x200B;fi&#x200B;&#x200B;&#x200B;&#x200B;H&#x200B;i&#x200B;&#x200B;&#x2212;c&#x200B;i&#x200B;T&#x200B;&#x200B;&#x394;u&#x200B;gi&#x200B;&#x200B;&#x200B;&#x200B;&#x200B;=&#x394;&#x3BB;&#x200B;i&#x200B;&#x200B;&#x394;u&#x200B;fi&#x200B;&#x200B;+&#x394;u&#x200B;gi&#x200B;&#x200B;&#x200B;&#x200B; where Ji&#x394;ugi=&#x2212;gi{\\mathbf{J}}_i{\\Delta\\mathbf{u}}_{gi}=-{\\mathbf{g}}_iJ&#x200B;i&#x200B;&#x200B;&#x394;u&#x200B;gi&#x200B;&#x200B;=&#x2212;g&#x200B;i&#x200B;&#x200B; and Ji&#x394;ufi=f{\\mathbf{J}}_i{\\Delta\\mathbf{u}}_{fi}={\\mathbf{f}}J&#x200B;i&#x200B;&#x200B;&#x394;u&#x200B;fi&#x200B;&#x200B;=f. Simple incremental schemes A naive choice of the constraint for &#x3BB;\\lambda&#x3BB; is that ci=0,bi=1,H1=&#x3BB;&#xAF;Hi=0,i&#x2265;2\\displaystyle \\begin{aligned} {\\mathbf{c}}_i=0,\\quad b_i=1,\\quad H_1={\\bar\\lambda}\\\\ H_i=0,\\quad i\\geq 2 \\end{aligned} &#x200B;c&#x200B;i&#x200B;&#x200B;=0,b&#x200B;i&#x200B;&#x200B;=1,H&#x200B;1&#x200B;&#x200B;=&#x200B;&#x3BB;&#x200B;&#xAF;&#x200B;&#x200B;&#x200B;H&#x200B;i&#x200B;&#x200B;=0,i&#x2265;2&#x200B;&#x200B; This corresponds to the incremental loading (IL) scheme, which prescribes the load increment &#x3BB;&#xAF;{\\bar\\lambda}&#x200B;&#x3BB;&#x200B;&#xAF;&#x200B;&#x200B; at the first iteration. As a result, the load parameter is fixed for the rest of iterations. Near the load limit point, the IL scheme would either fail or result in the snap-through behavior - the solution &#x201C;jumps&#x201D; to an equilibrium point far away from the previous solution and results in a non-smooth equilibrium path. Such behavior cannot be avoided unless the direction of the load increment is reversed at the load limit point. Similarly there is incremental displacement scheme which prescribes the displacement increment and suffers from the displacement limit point. Arc length schemes The family of arc length (AL) schemes are developed to overcome the limitations of the incremental schemes at limit points. These schemes have been widely used in engineering applications, esp. commercial computater-aided engineering software. The key idea is to introduce an arc length constraint that simultaneously controls the increments in the displacement and load, &#x394;uT&#x394;u+&#x3BC;&#x394;&#x3BB;2=&#x394;s2\\displaystyle {\\Delta\\mathbf{u}}^T{\\Delta\\mathbf{u}}+ \\mu{\\Delta\\lambda}^2 = {\\Delta s}^2 &#x394;u&#x200B;T&#x200B;&#x200B;&#x394;u+&#x3BC;&#x394;&#x3BB;&#x200B;2&#x200B;&#x200B;=&#x394;s&#x200B;2&#x200B;&#x200B; Different values of &#x3BC;\\mu&#x3BC; result in the variants of the schemes: &#x3BC;=1\\mu=1&#x3BC;=1 for spherical AL method, &#x3BC;=0\\mu=0&#x3BC;=0 for cylindrical AL method, and the most general, &#x3BC;&gt;0,&#x3BC;&#x2260;1\\mu&gt;0,\\mu\\neq 1&#x3BC;&gt;0,&#x3BC;&#x2260;1 for elliptical AL method. For the N+1N+1N+1 formulation, the AL constraint is rewritten as, &#x394;u1T&#x394;ui+&#x3BC;&#x394;&#x3BB;1&#x394;&#x3BB;i=&#x394;si2\\displaystyle {\\Delta\\mathbf{u}}_1^T{\\Delta\\mathbf{u}}_i + \\mu{\\Delta\\lambda}_1{\\Delta\\lambda}_i = {\\Delta s}_i^2 &#x394;u&#x200B;1&#x200B;T&#x200B;&#x200B;&#x394;u&#x200B;i&#x200B;&#x200B;+&#x3BC;&#x394;&#x3BB;&#x200B;1&#x200B;&#x200B;&#x394;&#x3BB;&#x200B;i&#x200B;&#x200B;=&#x394;s&#x200B;i&#x200B;2&#x200B;&#x200B; where &#x394;s1=&#x394;s{\\Delta s}_1={\\Delta s}&#x394;s&#x200B;1&#x200B;&#x200B;=&#x394;s the prescribed AL and &#x394;si=0,i&#x2265;2{\\Delta s}_i=0,i\\geq 2&#x394;s&#x200B;i&#x200B;&#x200B;=0,i&#x2265;2. The coefficients ci{\\mathbf{c}}_ic&#x200B;i&#x200B;&#x200B;, bib_ib&#x200B;i&#x200B;&#x200B; and HiH_iH&#x200B;i&#x200B;&#x200B; are then determined accordingly. The final expression for load increments is the following, &#x394;&#x3BB;i={&#xB1;&#x394;s&#x394;uf1T&#x394;uf1+&#x3BC;,i=1&#x2212;&#x394;uf1T&#x394;ugi&#x394;uf1T&#x394;ufi+&#x3BC;&#x394;&#x3BB;1,i&#x2265;2\\displaystyle {\\Delta\\lambda}_i = \\left\\{ \\begin{array}{ll} \\pm\\frac{ {\\Delta s}}{ \\sqrt{ {\\Delta\\mathbf{u}}_{f1}^T{\\Delta\\mathbf{u}}_{f1}+\\mu}}, &amp;\\quad i=1 \\\\ -\\frac{ {\\Delta\\mathbf{u}}_{f1}^T{\\Delta\\mathbf{u}}_{gi}}{ {\\Delta\\mathbf{u}}_{f1}^T{\\Delta\\mathbf{u}}_{fi}+\\mu{\\Delta\\lambda}_1}, &amp;\\quad i\\geq 2 \\end{array} \\right. &#x394;&#x3BB;&#x200B;i&#x200B;&#x200B;=&#x200B;&#x23A9;&#x200B;&#x23AA;&#x200B;&#x23AA;&#x200B;&#x23AA;&#x200B;&#x23A8;&#x200B;&#x23AA;&#x200B;&#x23AA;&#x200B;&#x23AA;&#x200B;&#x23A7;&#x200B;&#x200B;&#x200B;&#xB1;&#x200B;&#x221A;&#x200B;&#x394;u&#x200B;f1&#x200B;T&#x200B;&#x200B;&#x394;u&#x200B;f1&#x200B;&#x200B;+&#x3BC;&#x200B;&#x200B;&#x200B;&#x200B;&#x200B;&#x394;s&#x200B;&#x200B;,&#x200B;&#x2212;&#x200B;&#x394;u&#x200B;f1&#x200B;T&#x200B;&#x200B;&#x394;u&#x200B;fi&#x200B;&#x200B;+&#x3BC;&#x394;&#x3BB;&#x200B;1&#x200B;&#x200B;&#x200B;&#x200B;&#x394;u&#x200B;f1&#x200B;T&#x200B;&#x200B;&#x394;u&#x200B;gi&#x200B;&#x200B;&#x200B;&#x200B;,&#x200B;&#x200B;&#x200B;i=1&#x200B;i&#x2265;2&#x200B;&#x200B; A noteworthy issue of the above scheme is that the sign of &#x394;&#x3BB;1{\\Delta\\lambda}_1&#x394;&#x3BB;&#x200B;1&#x200B;&#x200B; is unspecified. One way to determine the sign is to pick the new increment that is &#x201C;closest to&#x201D; the previous solution, as discussed in this document. Another way to overcome the issue of direction determination is the linearization of the AL scheme, which replaces the AL constraint with a normal plane constraint. Generalized displacement control scheme The Yang1990 scheme is another scheme that bears a similar geometrical interpretation like the linearized AL scheme. Yet, initially, its derivation was to ensure the numerical stability of the N+1N+1N+1 dimensional space solution. A generalized stiffness parameter GSP is proposed, GSP=(&#x394;uf0)T&#x394;uf0(&#x394;uf10)T&#x394;uf1\\displaystyle GSP = \\frac{ ({\\Delta\\mathbf{u}}_f^0)^T{\\Delta\\mathbf{u}}_f^0}{ ({\\Delta\\mathbf{u}}_{f1}^0)^T{\\Delta\\mathbf{u}}_{f1}} GSP=&#x200B;(&#x394;u&#x200B;f1&#x200B;0&#x200B;&#x200B;)&#x200B;T&#x200B;&#x200B;&#x394;u&#x200B;f1&#x200B;&#x200B;&#x200B;&#x200B;(&#x394;u&#x200B;f&#x200B;0&#x200B;&#x200B;)&#x200B;T&#x200B;&#x200B;&#x394;u&#x200B;f&#x200B;0&#x200B;&#x200B;&#x200B;&#x200B; where &#x394;uf0{\\Delta\\mathbf{u}}_f^0&#x394;u&#x200B;f&#x200B;0&#x200B;&#x200B; is the first iteration from the first increment and &#x394;uf10{\\Delta\\mathbf{u}}_{f1}^0&#x394;u&#x200B;f1&#x200B;0&#x200B;&#x200B; is the first iteration from the previous increment. At the first increment, &#x394;uf0=&#x394;uf10{\\Delta\\mathbf{u}}_f^0={\\Delta\\mathbf{u}}_{f1}^0&#x394;u&#x200B;f&#x200B;0&#x200B;&#x200B;=&#x394;u&#x200B;f1&#x200B;0&#x200B;&#x200B;. Initially GSP=1GSP=1GSP=1 and GSP increases/decreases as the structure stiffens/softens. A negative value of GSP means that the equilibrium path passed the load limit point and the load direction should be reversed. Refer to Figure 2 in [Yang1990] for a geometrical illustration of the effect of GSP. The introduction of GSP leads to the following definition of the load increment, &#x394;&#x3BB;i={sgn&#x394;s&#x2223;GSP&#x2223;,i=1&#x2212;(&#x394;uf10)T&#x394;ugi(&#x394;uf10)T&#x394;ufi,i&#x2265;2\\displaystyle {\\Delta\\lambda}_i = \\left\\{ \\begin{array}{ll} sgn{\\Delta s}\\sqrt{ |GSP|}, &amp;\\quad i=1 \\\\ -\\frac{ ({\\Delta\\mathbf{u}}_{f1}^0)^T{\\Delta\\mathbf{u}}_{gi}}{ ({\\Delta\\mathbf{u}}_{f1}^0)^T{\\Delta\\mathbf{u}}_{fi}}, &amp;\\quad i\\geq 2 \\end{array} \\right. &#x394;&#x3BB;&#x200B;i&#x200B;&#x200B;=&#x200B;&#x23A9;&#x200B;&#x23AA;&#x200B;&#x23A8;&#x200B;&#x23AA;&#x200B;&#x23A7;&#x200B;&#x200B;&#x200B;sgn&#x394;s&#x221A;&#x200B;&#x2223;GSP&#x2223;&#x200B;&#x200B;&#x200B;,&#x200B;&#x2212;&#x200B;(&#x394;u&#x200B;f1&#x200B;0&#x200B;&#x200B;)&#x200B;T&#x200B;&#x200B;&#x394;u&#x200B;fi&#x200B;&#x200B;&#x200B;&#x200B;(&#x394;u&#x200B;f1&#x200B;0&#x200B;&#x200B;)&#x200B;T&#x200B;&#x200B;&#x394;u&#x200B;gi&#x200B;&#x200B;&#x200B;&#x200B;,&#x200B;&#x200B;&#x200B;i=1&#x200B;i&#x2265;2&#x200B;&#x200B; where sgn=1.0sgn=1.0sgn=1.0 and its sign changes whenever GSP becomes negative - and thus the load direction is automatically reversed at load limit point. Application to geometrically nonlinear truss Formulation For the geometrically nonlinear truss, the energy between one pair of points is, Ei=12k&#x2223;&#x2223;l&#x2223;&#x2223;(&#x2223;&#x2223;l&#x2032;&#x2223;&#x2223;&#x2212;&#x2223;&#x2223;l&#x2223;&#x2223;)2\\displaystyle E_i = \\frac{1}{2} \\frac{k}{||{\\mathbf{l}}||} (||{\\mathbf{l}}&apos;|| - ||{\\mathbf{l}}||)^2 E&#x200B;i&#x200B;&#x200B;=&#x200B;2&#x200B;&#x200B;1&#x200B;&#x200B;&#x200B;&#x2223;&#x2223;l&#x2223;&#x2223;&#x200B;&#x200B;k&#x200B;&#x200B;(&#x2223;&#x2223;l&#x200B;&#x2032;&#x200B;&#x200B;&#x2223;&#x2223;&#x2212;&#x2223;&#x2223;l&#x2223;&#x2223;)&#x200B;2&#x200B;&#x200B; where l=xi2&#x2212;xi1{\\mathbf{l}}={\\mathbf{x}}_{i2}-{\\mathbf{x}}_{i1}l=x&#x200B;i2&#x200B;&#x200B;&#x2212;x&#x200B;i1&#x200B;&#x200B;, l&#x2032;=xi2&#x2032;&#x2212;xi1&#x2032;{\\mathbf{l}}&apos;={\\mathbf{x}}_{i2}&apos;-{\\mathbf{x}}_{i1}&apos;l&#x200B;&#x2032;&#x200B;&#x200B;=x&#x200B;i2&#x200B;&#x2032;&#x200B;&#x200B;&#x2212;x&#x200B;i1&#x200B;&#x2032;&#x200B;&#x200B;, and superscript &#x2019; means new states of the points. The gradient and the Jacobian of EiE_iE&#x200B;i&#x200B;&#x200B; only depend on uiT=[xi1T,xi2T]{\\mathbf{u}}_i^T=[{\\mathbf{x}}_{i1}^T,{\\mathbf{x}}_{i2}^T]u&#x200B;i&#x200B;T&#x200B;&#x200B;=[x&#x200B;i1&#x200B;T&#x200B;&#x200B;,x&#x200B;i2&#x200B;T&#x200B;&#x200B;], &#x2202;Ei&#x2202;ui=k1L&#x2202;2Ei&#x2202;ui2=k1[I&#x2212;I&#x2212;II]+k2LLT\\displaystyle \\begin{aligned} {\\frac{\\partial E_i}{\\partial {\\mathbf{u}}_i}} &amp;= k_1 {\\mathbf{L}}\\\\ \\frac{ \\partial^2 E_i}{ \\partial {\\mathbf{u}}_i^2} &amp;= k_1 \\begin{bmatrix} I &amp; -I \\\\ -I &amp; I \\end{bmatrix} + k_2 {\\mathbf{L}}{\\mathbf{L}}^T \\end{aligned} &#x200B;&#x200B;&#x2202;u&#x200B;i&#x200B;&#x200B;&#x200B;&#x200B;&#x2202;E&#x200B;i&#x200B;&#x200B;&#x200B;&#x200B;&#x200B;&#x200B;&#x2202;u&#x200B;i&#x200B;2&#x200B;&#x200B;&#x200B;&#x200B;&#x2202;&#x200B;2&#x200B;&#x200B;E&#x200B;i&#x200B;&#x200B;&#x200B;&#x200B;&#x200B;&#x200B;&#x200B;=k&#x200B;1&#x200B;&#x200B;L&#x200B;=k&#x200B;1&#x200B;&#x200B;[&#x200B;I&#x200B;&#x2212;I&#x200B;&#x200B;&#x200B;&#x2212;I&#x200B;I&#x200B;&#x200B;]+k&#x200B;2&#x200B;&#x200B;LL&#x200B;T&#x200B;&#x200B;&#x200B;&#x200B; where, LT=[&#x2212;(l&#x2032;)T,(l&#x2032;)T]k1=k&#x2223;&#x2223;l&#x2223;&#x2223;(1&#x2212;&#x2223;&#x2223;l&#x2223;&#x2223;&#x2223;&#x2223;l&#x2032;&#x2223;&#x2223;)k2=k&#x2223;&#x2223;l&#x2032;&#x2223;&#x2223;3\\displaystyle \\begin{aligned} {\\mathbf{L}}^T &amp;= [-({\\mathbf{l}}&apos;)^T, ({\\mathbf{l}}&apos;)^T] \\\\ k_1 &amp;= \\frac{k}{||{\\mathbf{l}}||} \\left(1 - \\frac{||{\\mathbf{l}}||}{||{\\mathbf{l}}&apos;||}\\right) \\\\ k_2 &amp;= \\frac{k}{||{\\mathbf{l}}&apos;||^3} \\end{aligned} &#x200B;L&#x200B;T&#x200B;&#x200B;&#x200B;k&#x200B;1&#x200B;&#x200B;&#x200B;k&#x200B;2&#x200B;&#x200B;&#x200B;&#x200B;&#x200B;=[&#x2212;(l&#x200B;&#x2032;&#x200B;&#x200B;)&#x200B;T&#x200B;&#x200B;,(l&#x200B;&#x2032;&#x200B;&#x200B;)&#x200B;T&#x200B;&#x200B;]&#x200B;=&#x200B;&#x2223;&#x2223;l&#x2223;&#x2223;&#x200B;&#x200B;k&#x200B;&#x200B;(1&#x2212;&#x200B;&#x2223;&#x2223;l&#x200B;&#x2032;&#x200B;&#x200B;&#x2223;&#x2223;&#x200B;&#x200B;&#x2223;&#x2223;l&#x2223;&#x2223;&#x200B;&#x200B;)&#x200B;=&#x200B;&#x2223;&#x2223;l&#x200B;&#x2032;&#x200B;&#x200B;&#x2223;&#x2223;&#x200B;3&#x200B;&#x200B;&#x200B;&#x200B;k&#x200B;&#x200B;&#x200B;&#x200B; The gradient and Jacobian of the whole system are assembled from those of the point pairs. Case study The star dome 24-bar truss is a typical problem that contains various nonlinear behaviors. The description of the problem can be found here. The star dome is loaded at the center and experiences several load and displacement limit points during the loading process. The initial configuration (red dot-dashed line) and several typical deformation are shown in Figure 1. The displacement-load curve of the center node is presented in Figure 2. Figure 1. Figure 2. y-axis is the vertical force."},{"title":"Bayesian Optimization","permalink":"http://smanist.github.io/2018/06/12/Bayesian-optimization/","text":"How to solve an optimization problem when the objective function and/or the constraints are expensive/impossible to compute? Introduction The problem The objective function is expensive to compute when it is, for example, the lift-to-drag ratio of an aircraft wing using a computational fluid dynamics (CFD) solver, or nonlinear deformation of composite structure using a finite element (FE) solver. The objective function is impossible to compute when it is, for example, data obtained from experiments. The optimization problem is written formally as, argmindJ(d;U)s.t.cE(d;U)=0cI(d;U)&#x2265;0\\displaystyle \\begin{aligned} {\\mathrm{arg\\,min}}_{\\mathbf{d}}&amp;\\quad J({\\mathbf{d}};{\\mathbf{U}}) \\\\ {\\mathrm{s.t.}}&amp;\\quad {\\mathbf{c}}_E({\\mathbf{d}};{\\mathbf{U}}) = 0 \\\\ &amp;\\quad {\\mathbf{c}}_I({\\mathbf{d}};{\\mathbf{U}}) \\ge 0 \\end{aligned} &#x200B;argmin&#x200B;d&#x200B;&#x200B;&#x200B;s.t.&#x200B;&#x200B;&#x200B;&#x200B;J(d;U)&#x200B;c&#x200B;E&#x200B;&#x200B;(d;U)=0&#x200B;c&#x200B;I&#x200B;&#x200B;(d;U)&#x2265;0&#x200B;&#x200B; where d{\\mathbf{d}}d is the vector of design variables, cE{\\mathbf{c}}_Ec&#x200B;E&#x200B;&#x200B; and cI{\\mathbf{c}}_Ic&#x200B;I&#x200B;&#x200B; are the aggregated equality and inequality constraint functions, respectively. The state variables U{\\mathbf{U}}U are those implicitly involved in the evaluation of the objective and constraint functions. Examples of U{\\mathbf{U}}U are the flow variables in a CFD solver or the displacement field in the structural FE solver. In above cases, in order to solve the optimization problem during a practical time period, the number of evaluation of the objective function has to be limited in the optimization algorithm. There are two limitations on the optimization algorithm: (1) The design space cannot be explored by carrying out numerous direct evaluation of the objective function; (2) The derivative of the objective function w.r.t. design variables cannot be computed using the finite difference approach. These limitations prevent the direct application of any gradient-free or gradient-based algorithms to the optimization problem. Surrogate-based optimization To overcome the limitations, one approach is to use surrogate-based optimization (SBO). The SBO algorithms typically contain two key ingredients, a surrogate model and an acquisition function. The surrogate model is employed to approximate the expensive objective function. Since the surrogate is computationally efficient, it allows for fast evaluation of approximated objective function as well as its derivative w.r.t. the design variables. The acquisition function is a criterion for selecting the points in the design space that is potentially a solution to the optimization problem. The acquisition function is designed to take into account of both exploration, i.e.&#xA0;sampling from areas of high uncertainty, and exploitation, i.e.&#xA0;sampling from areas likely to contain the minimizer of the objective function. The general procedure of SBO is as follows, Step 1: Generate a sample data set D={(di,Ji,cEi,cIi)}i=1Ns{\\mathcal{D}}=\\{({\\mathbf{d}}_i, J_i, {\\mathbf{c}}_{Ei}, {\\mathbf{c}}_{Ii})\\}_{i=1}^{N_s}D={(d&#x200B;i&#x200B;&#x200B;,J&#x200B;i&#x200B;&#x200B;,c&#x200B;Ei&#x200B;&#x200B;,c&#x200B;Ii&#x200B;&#x200B;)}&#x200B;i=1&#x200B;N&#x200B;s&#x200B;&#x200B;&#x200B;&#x200B; by evaluating the objective and constraint functions Ji,cEi,cIiJ_i, {\\mathbf{c}}_{Ei}, {\\mathbf{c}}_{Ii}J&#x200B;i&#x200B;&#x200B;,c&#x200B;Ei&#x200B;&#x200B;,c&#x200B;Ii&#x200B;&#x200B; at a few sample points di{\\mathbf{d}}_id&#x200B;i&#x200B;&#x200B; in the design space. Step 2: Generate surrogates Jsur(d)J^{sur}({\\mathbf{d}})J&#x200B;sur&#x200B;&#x200B;(d), cEsur(d){\\mathbf{c}}_E^{sur}({\\mathbf{d}})c&#x200B;E&#x200B;sur&#x200B;&#x200B;(d), cIsur(d){\\mathbf{c}}_I^{sur}({\\mathbf{d}})c&#x200B;I&#x200B;sur&#x200B;&#x200B;(d) using the sample data set D{\\mathcal{D}}D. Step 3: Find the design point d&#x2217;{\\mathbf{d}}^*d&#x200B;&#x2217;&#x200B;&#x200B; by solving an optimization problem that consists of the surrogates and acquisition function. Step 4: Evaluate the objective and constraint functions J&#x2217;,cE&#x2217;,cI&#x2217;J^*, {\\mathbf{c}}_E^*, {\\mathbf{c}}_I^*J&#x200B;&#x2217;&#x200B;&#x200B;,c&#x200B;E&#x200B;&#x2217;&#x200B;&#x200B;,c&#x200B;I&#x200B;&#x2217;&#x200B;&#x200B; at the new design point d&#x2217;{\\mathbf{d}}^*d&#x200B;&#x2217;&#x200B;&#x200B;. Step 5: Update the surrogate using the sample data set augmented with the new design point D&#x2217;=D&#x222A;{(d&#x2217;,J&#x2217;,cE&#x2217;,cI&#x2217;)}{\\mathcal{D}}^*={\\mathcal{D}}\\cup \\{({\\mathbf{d}}^*,J^*,{\\mathbf{c}}_E^*,{\\mathbf{c}}_I^*)\\}D&#x200B;&#x2217;&#x200B;&#x200B;=D&#x222A;{(d&#x200B;&#x2217;&#x200B;&#x200B;,J&#x200B;&#x2217;&#x200B;&#x200B;,c&#x200B;E&#x200B;&#x2217;&#x200B;&#x200B;,c&#x200B;I&#x200B;&#x2217;&#x200B;&#x200B;)}. Step 6: Repeat steps 3-5 until the convergence or stopping conditions are reached. One category of SBO is the one-shot approach, which only contains steps 1-4. In the one-shot approach, the acquisition function is the surrogate itself. The issue is that the initial sample set does not necessarily represent well the distribution of the objective function over the whole design space. As a result, the optimal solution found by the algorithm may be far off from the true value of objective function. The other category of SBO is the updating approach that, of course, contains all the six steps. This is the category where the Bayesian optimization lies. Bayesian optimization Concepts Bayesian optimization (BO) is essentially the six-step SBO procedure with a statistical interpretation. Adapted from wikipedia: The expensive function is treated as a random function with a prior distribution, which captures the beliefs about the behavior of the function. The prior distribution is updated using the data set to form the the posterior distribution over the objective function. The posterior distribution is used to construct an acquisition function that determines the next design point. The two precursors of BO are Kushner1964 and Mockus1975. A good review of BO is provided in Brochu2010. The Gaussian process regression (GPR) model is a popular choice for the surrogate model in BO. Some outstanding the GPR-based BO algorithms include, but not limited to, BayesOpt: code, doc, paper. HIPS/spearmint: code. GPyOpt: code, doc GPflowOpt: code, doc, paper Besides GPR, there are BO algorithms using other surrogate models, such as those in SMAC (code, paper). A list of implementations of BO is provided here. Finally, note that in the engineering community, the BO algorithm tends to appear by the name efficient global optimization (EGO) algorithm Jones1998, Sasena2002. Next, the key components of BO, the surrogate model and the acquisition function, as well as the treatment of constraints will be discussed. Surrogate model In this and the following sections, the discussion will be based on the GPR model. The prediction of the GPR model at a new design point d&#x2217;{\\mathbf{d}}^*d&#x200B;&#x2217;&#x200B;&#x200B; follows a Gaussian probability distribution, J&#x2217;=Jsur(d&#x2217;)&#x223C;N(&#x3BC;(d&#x2217;),&#x3C3;2(d&#x2217;)),orP(Jsur=J&#x2217;)=12&#x3C0;&#x3C3;2exp(&#x2212;(J&#x2217;&#x2212;&#x3BC;)22&#x3C3;2)\\displaystyle J^* = J^{sur}({\\mathbf{d}}^*) \\sim {\\mathcal{N}}(\\mu({\\mathbf{d}}^*), {\\sigma^2}({\\mathbf{d}}^*)),\\quad\\mathrm{or}\\quad P(J^{sur}=J^*)=\\frac{1}{\\sqrt{2\\pi{\\sigma^2}}}\\exp\\left(-\\frac{(J^*-\\mu)^2}{2{\\sigma^2}}\\right) J&#x200B;&#x2217;&#x200B;&#x200B;=J&#x200B;sur&#x200B;&#x200B;(d&#x200B;&#x2217;&#x200B;&#x200B;)&#x223C;N(&#x3BC;(d&#x200B;&#x2217;&#x200B;&#x200B;),&#x3C3;&#x200B;2&#x200B;&#x200B;(d&#x200B;&#x2217;&#x200B;&#x200B;)),orP(J&#x200B;sur&#x200B;&#x200B;=J&#x200B;&#x2217;&#x200B;&#x200B;)=&#x200B;&#x221A;&#x200B;2&#x3C0;&#x3C3;&#x200B;2&#x200B;&#x200B;&#x200B;&#x200B;&#x200B;&#x200B;&#x200B;1&#x200B;&#x200B;exp(&#x2212;&#x200B;2&#x3C3;&#x200B;2&#x200B;&#x200B;&#x200B;&#x200B;(J&#x200B;&#x2217;&#x200B;&#x200B;&#x2212;&#x3BC;)&#x200B;2&#x200B;&#x200B;&#x200B;&#x200B;) where &#x3BC;\\mu&#x3BC; is the predicted value of objective function and &#x3C3;2{\\sigma^2}&#x3C3;&#x200B;2&#x200B;&#x200B; is the variance, i.e.&#xA0;the uncertainty of the prediction. The details of GPR models have been discussed in the previous articles and will be skipped. Acquisition function for unconstrained optimization The BO is initially developed for unconstrained problems. Surveys of acquisition functions for such problems can be found in, for example, [Sasena2002] and Gelbart2015. There are three basic acquisition functions: (1) Probability Improvement (PI) [Kushner1964], (2) Expected Improvement (EI) Mockus1994, Lizotte2008, (3) Lower Confidence Bound (LCB) Cox1992. Besides the basic ones, there are acquisition functions based on Thompson Sampling and the information theory (entropy). In general, it appears that the acquisition functions are evolving towards (1) finding multiple candidate points in one iteration, (2) taking advantage of parallel computing via techniques like asynchronization. Nonetheless, this article will focus only on the three basic acquisition functions. PI Defined as the probability of the new design point d&#x2217;{\\mathbf{d}}^*d&#x200B;&#x2217;&#x200B;&#x200B; to offer a better value of the objective function J&#x2217;J^*J&#x200B;&#x2217;&#x200B;&#x200B; than the minimum objective function in the sample data set Jmin=min{Ji}J_{\\min}=\\min\\{J_i\\}J&#x200B;min&#x200B;&#x200B;=min{J&#x200B;i&#x200B;&#x200B;}. CPI(d&#x2217;)=P(J&#x2217;&#x2264;Jmin)\\displaystyle C_{PI}({\\mathbf{d}}^*) = P(J^*\\le J_{\\min}) C&#x200B;PI&#x200B;&#x200B;(d&#x200B;&#x2217;&#x200B;&#x200B;)=P(J&#x200B;&#x2217;&#x200B;&#x200B;&#x2264;J&#x200B;min&#x200B;&#x200B;) EI Defined as the expectation of the improvement in the objective function at the new design point. In the literature, EI has been generalized to include user-specified parameters that control the exploitation-exploration trade-off. The generalized EI is written as, CEI(d&#x2217;)=E[I(d&#x2217;)],I(d)=max(0,(Jmin&#x2212;Jsur(d)&#x2212;&#x3B6;&#x3C3;(d))g)\\displaystyle C_{EI}({\\mathbf{d}}^*) = {\\mathbb{E}}[I({\\mathbf{d}}^*)],\\quad I({\\mathbf{d}}) = \\max(0,(J_{\\min}-J^{sur}({\\mathbf{d}})-\\zeta\\sigma({\\mathbf{d}}))^g) C&#x200B;EI&#x200B;&#x200B;(d&#x200B;&#x2217;&#x200B;&#x200B;)=E[I(d&#x200B;&#x2217;&#x200B;&#x200B;)],I(d)=max(0,(J&#x200B;min&#x200B;&#x200B;&#x2212;J&#x200B;sur&#x200B;&#x200B;(d)&#x2212;&#x3B6;&#x3C3;(d))&#x200B;g&#x200B;&#x200B;) where &#x3B6;&#x2265;0\\zeta\\ge 0&#x3B6;&#x2265;0 and g&#x2265;1g\\ge 1g&#x2265;1 are the user-specified parameters. The classical form of EI is obtained with &#x3B6;=0\\zeta=0&#x3B6;=0 and g=1g=1g=1. A larger ggg or &#x3B6;\\zeta&#x3B6; will put more weight on the exploration. Note that when &#x3B6;=0\\zeta=0&#x3B6;=0 and g=0g=0g=0, EI reduces to PI. For a GPR model, the closed-form expression is available for CEIC_{EI}C&#x200B;EI&#x200B;&#x200B;. For the case g=1g=1g=1, CEI(d&#x2217;)=&#x222B;0&#x221E;IP(Jsur=Jmin&#x2212;&#x3B6;&#x3C3;&#x2212;I)dI={&#x3C3;[z&#x3A6;(z)+&#x3D5;(z)],&#x3C3;&gt;00,&#x3C3;=0\\displaystyle \\begin{aligned} C_{EI}({\\mathbf{d}}^*) &amp;= \\int_0^\\infty I P(J^{sur}=J_{\\min}-\\zeta\\sigma-I) dI \\\\ &amp;= \\left\\{ \\begin{array}{ll} \\sigma [z\\Phi(z) + \\phi(z)],&amp;\\quad \\sigma &gt; 0 \\\\ 0,&amp;\\quad \\sigma = 0 \\end{array} \\right. \\end{aligned} &#x200B;C&#x200B;EI&#x200B;&#x200B;(d&#x200B;&#x2217;&#x200B;&#x200B;)&#x200B;&#x200B;&#x200B;&#x200B;=&#x222B;&#x200B;0&#x200B;&#x221E;&#x200B;&#x200B;IP(J&#x200B;sur&#x200B;&#x200B;=J&#x200B;min&#x200B;&#x200B;&#x2212;&#x3B6;&#x3C3;&#x2212;I)dI&#x200B;={&#x200B;&#x3C3;[z&#x3A6;(z)+&#x3D5;(z)],&#x200B;0,&#x200B;&#x200B;&#x200B;&#x3C3;&gt;0&#x200B;&#x3C3;=0&#x200B;&#x200B;&#x200B;&#x200B; where z=Jmin&#x2212;&#x3B6;&#x3C3;&#x2212;&#x3BC;&#x3C3;z=\\frac{J_{\\min}-\\zeta\\sigma-\\mu}{\\sigma}z=&#x200B;&#x3C3;&#x200B;&#x200B;J&#x200B;min&#x200B;&#x200B;&#x2212;&#x3B6;&#x3C3;&#x2212;&#x3BC;&#x200B;&#x200B;, and &#x3A6;\\Phi&#x3A6; and &#x3D5;\\phi&#x3D5; are the cummulative distribution and probability density functions, respectively. The gradient of CEIC_{EI}C&#x200B;EI&#x200B;&#x200B; w.r.t. d{\\mathbf{d}}d for &#x3C3;&gt;0\\sigma&gt;0&#x3C3;&gt;0 is, &#x2202;CEI&#x2202;d=&#x2212;&#x2202;&#x3BC;&#x2202;d&#x3A6;(z)+&#x2202;&#x3C3;&#x2202;d[&#x3D5;(z)&#x2212;&#x3B6;&#x3A6;(z)]\\displaystyle {\\frac{\\partial C_{EI}}{\\partial {\\mathbf{d}}}} = - {\\frac{\\partial \\mu}{\\partial {\\mathbf{d}}}}\\Phi(z) + {\\frac{\\partial \\sigma}{\\partial {\\mathbf{d}}}}[\\phi(z)-\\zeta\\Phi(z)] &#x200B;&#x2202;d&#x200B;&#x200B;&#x2202;C&#x200B;EI&#x200B;&#x200B;&#x200B;&#x200B;=&#x2212;&#x200B;&#x2202;d&#x200B;&#x200B;&#x2202;&#x3BC;&#x200B;&#x200B;&#x3A6;(z)+&#x200B;&#x2202;d&#x200B;&#x200B;&#x2202;&#x3C3;&#x200B;&#x200B;[&#x3D5;(z)&#x2212;&#x3B6;&#x3A6;(z)] where the computation of &#x2202;&#x3BC;&#x2202;d{\\frac{\\partial \\mu}{\\partial {\\mathbf{d}}}}&#x200B;&#x2202;d&#x200B;&#x200B;&#x2202;&#x3BC;&#x200B;&#x200B; and &#x2202;&#x3C3;&#x2202;d{\\frac{\\partial \\sigma}{\\partial {\\mathbf{d}}}}&#x200B;&#x2202;d&#x200B;&#x200B;&#x2202;&#x3C3;&#x200B;&#x200B; has been discussed in a previous article. For the case &#x3B6;=0\\zeta=0&#x3B6;=0, refer to P. 64 of [Sasena2002]. LCB Defined using the LCB concept, CLCB(d&#x2217;)=&#x3BC;(d&#x2217;)&#x2212;&#x3B6;&#x3C3;(d&#x2217;)\\displaystyle C_{LCB}({\\mathbf{d}}^*) = \\mu({\\mathbf{d}}^*) - \\zeta\\sigma({\\mathbf{d}}^*) C&#x200B;LCB&#x200B;&#x200B;(d&#x200B;&#x2217;&#x200B;&#x200B;)=&#x3BC;(d&#x200B;&#x2217;&#x200B;&#x200B;)&#x2212;&#x3B6;&#x3C3;(d&#x200B;&#x2217;&#x200B;&#x200B;) where the probability of Jsur&lt;CLCBJ^{sur}&lt;C_{LCB}J&#x200B;sur&#x200B;&#x200B;&lt;C&#x200B;LCB&#x200B;&#x200B; is a constant controlled by the user-specified parameter &#x3B6;&gt;0\\zeta&gt;0&#x3B6;&gt;0. A larger &#x3B6;\\zeta&#x3B6; will put more weight on the exploration. The gradient of CLCBC_{LCB}C&#x200B;LCB&#x200B;&#x200B; w.r.t. d{\\mathbf{d}}d is straight-forward. Discussion The PI acquisition function is purely exploitation, which is undesirable for global optimization. The EI and LCB acquisition functions are high when J&#x2217;J^*J&#x200B;&#x2217;&#x200B;&#x200B; approaches the optimum point, or the uncertainty of J&#x2217;J^*J&#x200B;&#x2217;&#x200B;&#x200B; is high. Therefore, both CEIC_{EI}C&#x200B;EI&#x200B;&#x200B; and CLCBC_{LCB}C&#x200B;LCB&#x200B;&#x200B; achieve a balance between exploitation and exploration. The exploitation-exploration trade-off of EI and LCB functions can be further tuned by the cooling scheme. In the cooling scheme, the optimization starts with a large user-specified parameter for more exploration and gradually decreases the parameter to focus on exploitation. However, the effect of this scheme is controversial [Sasena2002] and [Brochu2010]. Treatment of constraints The acquisition functions discussed in the previous section work well with optimization problems without constraints or with box constraints only. For more complex constraints, there are two types of treatments. The first type is the direct approach. As suggested in [Sasena2002], the objective and constraint functions are replaced with the surrogates, and the following problem is solved, argmindC(Jsur,d)s.t.cEsur(d)=0cIsur(d)&#x2265;0\\displaystyle \\begin{aligned} {\\mathrm{arg\\,min}}_{\\mathbf{d}}&amp;\\quad C(J^{sur}, {\\mathbf{d}}) \\\\ {\\mathrm{s.t.}}&amp;\\quad {\\mathbf{c}}_E^{sur}({\\mathbf{d}}) = 0 \\\\ &amp;\\quad {\\mathbf{c}}_I^{sur}({\\mathbf{d}}) \\ge 0 \\end{aligned} &#x200B;argmin&#x200B;d&#x200B;&#x200B;&#x200B;s.t.&#x200B;&#x200B;&#x200B;&#x200B;C(J&#x200B;sur&#x200B;&#x200B;,d)&#x200B;c&#x200B;E&#x200B;sur&#x200B;&#x200B;(d)=0&#x200B;c&#x200B;I&#x200B;sur&#x200B;&#x200B;(d)&#x2265;0&#x200B;&#x200B; Similar to [Sasena2002] is the expected violation (EV) method Audet2000: The optimization is carried out by filling the design space using latin hypercube sampling and filtering out infeasible candidate points using the so-called EV function, which takes the same form of EI. Essentially, the constraint surrogates csur{\\mathbf{c}}^{sur}c&#x200B;sur&#x200B;&#x200B; are replaced by CEV(csur,d)C_{EV}({\\mathbf{c}}^{sur}, {\\mathbf{d}})C&#x200B;EV&#x200B;&#x200B;(c&#x200B;sur&#x200B;&#x200B;,d). The other type is the indirect approach, which is further divided into two categories, as discussed in [Gelbart2015]. In the first category, the constrained problem is converted to an unconstrained one using classical (non-BO) methods. Three representative approaches are, Barrier methods: The iterates are prevented from leaving the feasible region by augmenting the objective function with a barrier function, which causes the objective to grow to infinity at the boundary of the feasible region. Penalty methods: The objective function is augmented with a penalty term, which still allows the iterates to leave the feasible region but the iterates become feasible as the penalty increases to infinity in the process of optimization. Augmented Lagrangian methods: The problem is solved via the Lagrangian form augmented with the extra term in penalty methods, while the Lagrangian multipliers are controlled by the penalty parameters. In the second category of indirect approach, the acquisition function is modified to incorporate the constraint surrogates. two representative approaches are, Modified EI methods: An example is the EI with constraints (EIC) Schonlau1998. The EI for the objective function is augmented to take account of the constraints. In EIC, the EI is multiplied by the probability that the constraints are satisfied, so that the improvement (almost) only occurs at feasible candidate points. Marginalization integral (MI) methods: Examples are integrated expected conditional improvement Gramacy2011 and expected volume minimization Picheny2014. The acqusition function at d{\\mathbf{d}}d is defined using an integral over the whole design space, CMI(d)=&#x222B;F(d,d&#x2032;)h(d&#x2032;)dd&#x2032;\\displaystyle C_{MI}({\\mathbf{d}}) = \\int F({\\mathbf{d}},{\\mathbf{d}}&apos;)h({\\mathbf{d}}&apos;)d{\\mathbf{d}}&apos; C&#x200B;MI&#x200B;&#x200B;(d)=&#x222B;F(d,d&#x200B;&#x2032;&#x200B;&#x200B;)h(d&#x200B;&#x2032;&#x200B;&#x200B;)dd&#x200B;&#x2032;&#x200B;&#x200B; where F(d,d&#x2032;)F({\\mathbf{d}},{\\mathbf{d}}&apos;)F(d,d&#x200B;&#x2032;&#x200B;&#x200B;) is a measure of improvement at d&#x2032;{\\mathbf{d}}&apos;d&#x200B;&#x2032;&#x200B;&#x200B; given observation at d{\\mathbf{d}}d and h(d&#x2032;)h({\\mathbf{d}}&apos;)h(d&#x200B;&#x2032;&#x200B;&#x200B;) is the probability that the constraints are satisfied at d&#x2032;{\\mathbf{d}}&apos;d&#x200B;&#x2032;&#x200B;&#x200B;. The maximizer of CMIC_{MI}C&#x200B;MI&#x200B;&#x200B; provides the best overall improvement in the design space. The inclusion of h(d)h({\\mathbf{d}})h(d) encourages picking candidate points likely to be feasible, while still permits the picking of points in infeasible region that may provide improvement over the whole design space. In terms of programming, the direct approach is probably the easiest one to implement. Particularly, the non-BO indirect approaches may be applied to solve the subproblems derived from the the direct approach, if standard packages for numerical optimization are employed. The challenge in the MI methods is the integration over the design space, which could be intractable in higher dimensions. Miscellaneous topics Choice of optimization algorithms No matter which algorithm is used, eventually the BO process boils down to a series of non-convex optimization subproblems. It is hard to find the global optimum of a non-convex function. One choice is to use the evolutionary algorithms, or some so-called global algorithms like the DIRECT, which are claimed to be able to find the global optimum given sufficiently many iterations. Another choice is to apply the algorithms for convex optimization, especially the gradient-based ones, with multiple restarts. I personally prefer the latter. Both choices do not guarantee the convergence to global optimum. The convergence rate of the former is much slower than the latter, especially in high-dimensional space. In practice, multiple restarts usually result in a good global sub-optimal point that is sufficient for the engineering purposes. A merit of the former, though, is that some algorithms can handle disjoint feasible regions. Relearn rate of the surrogate The training of the surrogates could become expensive as the number of samples increases. Also, contrary to intuition, updating the hyperparameters of the surrogate at every iteration may be unnecessary or even counterproductive Bull2011. A better strategy is to introduce a relearn rate: Update the sample data set in the surrogate every iteration, but update the hyperparameters every few iterations. In practice, the effectiveness of this strategy depends on the quality of the surrogate implementation. If the current hyperparameters are far off from the converged values, keeping the current hyperparameters would reduce the convergence rate of the whole BO algorithm. As for the GPR model, the update of sample data set has been discussed in a previous article. Final note To be fair, it is worth mentioning the existence of adjoint-based optimization. This methodology applies to optimization problems constrained by partial differential equations (PDEs). One can incorporate the adjoint capability in their PDE solver and enable the direct gradient calculation of the expensive objective and constraint functions. This approach applies to optimization problems involving CFD and FE solvers. The adjoint method would be a different (but interesting) story that I will discuss in future."},{"title":"Gaussian Process Regressor - Addendum","permalink":"http://smanist.github.io/2018/06/08/Gaussian-process-regressor-addendum/","text":"A collection of extra topics as a sequel to the GPR series. Updating scheme Consider a scenario where a GP model is trained using a large sample data set (NNN points). Recall from the first and the second articles, the training process determines the hyperparameters and generates a number of coefficient matrices for the efficient computation of the predictive mean and variance. Now suppose a few new samples (MMM points, M&#x226A;NM\\ll NM&#x226A;N) are to be appended to the data set. The question is, does one simply retrain the GP model? Not necessarily. The new samples can reduce the prediction error and the overall uncertainty but may have limited effect on the hyperparameters. Therefore, with a few new samples, one can update the GP model by keeping the old hyperparameters and recomputing the coefficient matrices, including L{\\mathbf{L}}L, F{\\mathbf{F}}F, Q{\\mathbf{Q}}Q and R{\\mathbf{R}}R. Strictly speaking, the addition of new samples will result in the recomputation of everything, even though the hyperparameters remain the same: The std and mean of the samples are modified, so is the correlation matrix K{\\mathbf{K}}K, and so are the follow-up matrix decompositions. However, now that M&#x226A;NM\\ll NM&#x226A;N, one can assume that the std and mean of the new sample data set are the same as those of the old one. As a result, the portion of K{\\mathbf{K}}K associated with the old sample data set remains the same, and the new coefficient matrices can be computed via partial matrix decompositions, which could save considerable amount of time - dropping from O(N3)O(N^3)O(N&#x200B;3&#x200B;&#x200B;) to O(N2)O(N^2)O(N&#x200B;2&#x200B;&#x200B;). The new covariance matrix is K=[KssKsnKnsKnn]\\displaystyle {\\mathbf{K}}= \\begin{bmatrix} {\\mathbf{K}}_{ss} &amp; {\\mathbf{K}}_{sn} \\\\ {\\mathbf{K}}_{ns} &amp; {\\mathbf{K}}_{nn} \\end{bmatrix} K=[&#x200B;K&#x200B;ss&#x200B;&#x200B;&#x200B;K&#x200B;ns&#x200B;&#x200B;&#x200B;&#x200B;&#x200B;K&#x200B;sn&#x200B;&#x200B;&#x200B;K&#x200B;nn&#x200B;&#x200B;&#x200B;&#x200B;] where Kss{\\mathbf{K}}_{ss}K&#x200B;ss&#x200B;&#x200B; is the matrix associated with the old data set, whose Cholesky factor Ls{\\mathbf{L}}_sL&#x200B;s&#x200B;&#x200B; is known. Matrices Kns=KsnT{\\mathbf{K}}_{ns}={\\mathbf{K}}_{sn}^TK&#x200B;ns&#x200B;&#x200B;=K&#x200B;sn&#x200B;T&#x200B;&#x200B; and Knn{\\mathbf{K}}_{nn}K&#x200B;nn&#x200B;&#x200B; are due to the new samples. The Cholesky factor L{\\mathbf{L}}L of K{\\mathbf{K}}K is obtained via the following procedure of partial Cholesky decomposition, Cholesky decomposition: Knn=LnLnT{\\mathbf{K}}_{nn}={\\mathbf{L}}_n{\\mathbf{L}}_n^TK&#x200B;nn&#x200B;&#x200B;=L&#x200B;n&#x200B;&#x200B;L&#x200B;n&#x200B;T&#x200B;&#x200B;. Linear solve: Lsn=Ls&#x2212;1Ksn{\\mathbf{L}}_{sn} = {\\mathbf{L}}_s^{-1}{\\mathbf{K}}_{sn}L&#x200B;sn&#x200B;&#x200B;=L&#x200B;s&#x200B;&#x2212;1&#x200B;&#x200B;K&#x200B;sn&#x200B;&#x200B; Assemble the Cholesky factor, L=[LsOLsnTLn]\\displaystyle {\\mathbf{L}}= \\begin{bmatrix} {\\mathbf{L}}_s &amp; {\\mathbf{O}}\\\\ {\\mathbf{L}}_{sn}^T &amp; {\\mathbf{L}}_n \\end{bmatrix} L=[&#x200B;L&#x200B;s&#x200B;&#x200B;&#x200B;L&#x200B;sn&#x200B;T&#x200B;&#x200B;&#x200B;&#x200B;&#x200B;O&#x200B;L&#x200B;n&#x200B;&#x200B;&#x200B;&#x200B;] Next, the new F{\\mathbf{F}}F matrix is F=L&#x2212;1H=[LsOLsnTLn]&#x2212;1[HsHn]=[FsLn&#x2212;1(Hn&#x2212;LsnTFs)]\\displaystyle {\\mathbf{F}}= {\\mathbf{L}}^{-1}{\\mathbf{H}}= \\begin{bmatrix} {\\mathbf{L}}_s &amp; {\\mathbf{O}}\\\\ {\\mathbf{L}}_{sn}^T &amp; {\\mathbf{L}}_n \\end{bmatrix}^{-1} \\begin{bmatrix} {\\mathbf{H}}_s \\\\ {\\mathbf{H}}_n \\end{bmatrix} = \\begin{bmatrix} {\\mathbf{F}}_s \\\\ {\\mathbf{L}}_n^{-1} ({\\mathbf{H}}_n - {\\mathbf{L}}_{sn}^T{\\mathbf{F}}_s) \\end{bmatrix} F=L&#x200B;&#x2212;1&#x200B;&#x200B;H=[&#x200B;L&#x200B;s&#x200B;&#x200B;&#x200B;L&#x200B;sn&#x200B;T&#x200B;&#x200B;&#x200B;&#x200B;&#x200B;O&#x200B;L&#x200B;n&#x200B;&#x200B;&#x200B;&#x200B;]&#x200B;&#x2212;1&#x200B;&#x200B;[&#x200B;H&#x200B;s&#x200B;&#x200B;&#x200B;H&#x200B;n&#x200B;&#x200B;&#x200B;&#x200B;]=[&#x200B;F&#x200B;s&#x200B;&#x200B;&#x200B;L&#x200B;n&#x200B;&#x2212;1&#x200B;&#x200B;(H&#x200B;n&#x200B;&#x200B;&#x2212;L&#x200B;sn&#x200B;T&#x200B;&#x200B;F&#x200B;s&#x200B;&#x200B;)&#x200B;&#x200B;] where block matrix inversion is used and Fs=Ls&#x2212;1Hs{\\mathbf{F}}_s={\\mathbf{L}}_s^{-1}{\\mathbf{H}}_sF&#x200B;s&#x200B;&#x200B;=L&#x200B;s&#x200B;&#x2212;1&#x200B;&#x200B;H&#x200B;s&#x200B;&#x200B; is known from the old model. Finally, since Fs=QsRs{\\mathbf{F}}_s={\\mathbf{Q}}_s{\\mathbf{R}}_sF&#x200B;s&#x200B;&#x200B;=Q&#x200B;s&#x200B;&#x200B;R&#x200B;s&#x200B;&#x200B; is known, one can utilize the QR update algorithm to obtain the QR decomposition of F{\\mathbf{F}}F. Such algorithm has been implemented in standard packages for scientific computation, such as scipy.linalg.qr_insert. With the new coefficient matices L{\\mathbf{L}}L, F{\\mathbf{F}}F, Q{\\mathbf{Q}}Q and R{\\mathbf{R}}R, the GP model is updated with the new sample data set. Gradients In some scenarios where a GP model is involved, the gradients of the mean and the variance w.r.t. the input are required. One example is the surrogate-based optimization, where the GP model is used as the surrogate and the gradient-based algorithm is chosen to find the optima. It is necessary to compute the gradient analytically (or using automatic differentiation), instead of using finite difference. The latter could destabilize the iterations of gradient descent near some &#x201C;singularity&#x201D; points at which the GP model is ill-defined. Note that, in the trivial treatment of the multiple output case, the process variances &#x3C3;f2{\\sigma_f^2}&#x3C3;&#x200B;f&#x200B;2&#x200B;&#x200B; of the output are determined independently. Therefore, it is sufficient to consider the single output case. From the first article of the GPR series, the mean and variance at a single point are, respectively, m(x)=g&#xAF;Tku(x)+b&#xAF;Thu(x)&#x3C3;2(x)=&#x3C3;f2&#x2212;[L&#x2212;1ku(x)]2+[R&#x2212;T[hu(x)&#x2212;FT[L&#x2212;1ku(x)]]]2&#x2261;&#x3C3;f2&#x2212;e1Te1+e2Te2\\displaystyle \\begin{aligned} m({\\mathbf{x}}) &amp;= {\\bar\\mathbf{g}}^T{\\mathbf{k}_u}({\\mathbf{x}}) + {\\bar\\mathbf{b}}^T{\\mathbf{h}_u}({\\mathbf{x}}) \\\\ {\\sigma^2}({\\mathbf{x}}) &amp;= {\\sigma_f^2}- [{\\mathbf{L}}^{-1}{\\mathbf{k}_u}({\\mathbf{x}})]^2 + [{\\mathbf{R}}^{-T} [{\\mathbf{h}_u}({\\mathbf{x}}) - {\\mathbf{F}}^T[{\\mathbf{L}}^{-1}{\\mathbf{k}_u}({\\mathbf{x}})]]]^2 \\\\ &amp;\\equiv {\\sigma_f^2}- {\\mathbf{e}}_1^T{\\mathbf{e}}_1 + {\\mathbf{e}}_2^T{\\mathbf{e}}_2 \\end{aligned} &#x200B;m(x)&#x200B;&#x3C3;&#x200B;2&#x200B;&#x200B;(x)&#x200B;&#x200B;&#x200B;&#x200B;=&#x200B;g&#x200B;&#xAF;&#x200B;&#x200B;&#x200B;T&#x200B;&#x200B;k&#x200B;u&#x200B;&#x200B;(x)+&#x200B;b&#x200B;&#xAF;&#x200B;&#x200B;&#x200B;T&#x200B;&#x200B;h&#x200B;u&#x200B;&#x200B;(x)&#x200B;=&#x3C3;&#x200B;f&#x200B;2&#x200B;&#x200B;&#x2212;[L&#x200B;&#x2212;1&#x200B;&#x200B;k&#x200B;u&#x200B;&#x200B;(x)]&#x200B;2&#x200B;&#x200B;+[R&#x200B;&#x2212;T&#x200B;&#x200B;[h&#x200B;u&#x200B;&#x200B;(x)&#x2212;F&#x200B;T&#x200B;&#x200B;[L&#x200B;&#x2212;1&#x200B;&#x200B;k&#x200B;u&#x200B;&#x200B;(x)]]]&#x200B;2&#x200B;&#x200B;&#x200B;&#x2261;&#x3C3;&#x200B;f&#x200B;2&#x200B;&#x200B;&#x2212;e&#x200B;1&#x200B;T&#x200B;&#x200B;e&#x200B;1&#x200B;&#x200B;+e&#x200B;2&#x200B;T&#x200B;&#x200B;e&#x200B;2&#x200B;&#x200B;&#x200B;&#x200B; where ku=Ksu{\\mathbf{k}_u}={\\mathbf{K}}_{su}k&#x200B;u&#x200B;&#x200B;=K&#x200B;su&#x200B;&#x200B; and hu=HuT{\\mathbf{h}_u}={\\mathbf{H}}_u^Th&#x200B;u&#x200B;&#x200B;=H&#x200B;u&#x200B;T&#x200B;&#x200B; and b&#xAF;=R&#x2212;1[QT(L&#x2212;1ys)]g&#xAF;=L&#x2212;T[L&#x2212;1(ys&#x2212;Hb&#xAF;)]\\displaystyle \\begin{aligned} {\\bar\\mathbf{b}}&amp;= {\\mathbf{R}}^{-1} [{\\mathbf{Q}}^T({\\mathbf{L}}^{-1}{\\mathbf{y}}_s)] \\\\ {\\bar\\mathbf{g}}&amp;= {\\mathbf{L}}^{-T} [{\\mathbf{L}}^{-1} ({\\mathbf{y}}_s-{\\mathbf{H}}{\\bar\\mathbf{b}})] \\end{aligned} &#x200B;&#x200B;b&#x200B;&#xAF;&#x200B;&#x200B;&#x200B;&#x200B;g&#x200B;&#xAF;&#x200B;&#x200B;&#x200B;&#x200B;&#x200B;=R&#x200B;&#x2212;1&#x200B;&#x200B;[Q&#x200B;T&#x200B;&#x200B;(L&#x200B;&#x2212;1&#x200B;&#x200B;y&#x200B;s&#x200B;&#x200B;)]&#x200B;=L&#x200B;&#x2212;T&#x200B;&#x200B;[L&#x200B;&#x2212;1&#x200B;&#x200B;(y&#x200B;s&#x200B;&#x200B;&#x2212;H&#x200B;b&#x200B;&#xAF;&#x200B;&#x200B;)]&#x200B;&#x200B; The gradient of the mean is computed in a straight-forward manner, &#x2202;m&#x2202;x=g&#xAF;T&#x2202;ku&#x2202;x+b&#xAF;T&#x2202;hu&#x2202;x\\displaystyle {\\frac{\\partial m}{\\partial {\\mathbf{x}}}} = {\\bar\\mathbf{g}}^T{\\frac{\\partial {\\mathbf{k}_u}}{\\partial {\\mathbf{x}}}} + {\\bar\\mathbf{b}}^T{\\frac{\\partial {\\mathbf{h}_u}}{\\partial {\\mathbf{x}}}} &#x200B;&#x2202;x&#x200B;&#x200B;&#x2202;m&#x200B;&#x200B;=&#x200B;g&#x200B;&#xAF;&#x200B;&#x200B;&#x200B;T&#x200B;&#x200B;&#x200B;&#x2202;x&#x200B;&#x200B;&#x2202;k&#x200B;u&#x200B;&#x200B;&#x200B;&#x200B;+&#x200B;b&#x200B;&#xAF;&#x200B;&#x200B;&#x200B;T&#x200B;&#x200B;&#x200B;&#x2202;x&#x200B;&#x200B;&#x2202;h&#x200B;u&#x200B;&#x200B;&#x200B;&#x200B; where &#x2202;ku&#x2202;x{\\frac{\\partial {\\mathbf{k}_u}}{\\partial {\\mathbf{x}}}}&#x200B;&#x2202;x&#x200B;&#x200B;&#x2202;k&#x200B;u&#x200B;&#x200B;&#x200B;&#x200B; and &#x2202;hu&#x2202;x{\\frac{\\partial {\\mathbf{h}_u}}{\\partial {\\mathbf{x}}}}&#x200B;&#x2202;x&#x200B;&#x200B;&#x2202;h&#x200B;u&#x200B;&#x200B;&#x200B;&#x200B; are obtained from the regression and mean functions, respectively. The computation of the gradient of the variance is a little bit more involved, &#x2202;&#x3C3;2&#x2202;x=&#x2212;2e1TL&#x2212;1&#x2202;ku&#x2202;x+2e2TR&#x2212;T(&#x2202;hu&#x2202;x&#x2212;FTL&#x2212;1&#x2202;ku&#x2202;x)=&#x2212;2[L&#x2212;T(Fr+e1)]T&#x2202;ku&#x2202;x+2rT&#x2202;hu&#x2202;x\\displaystyle \\begin{aligned} {\\frac{\\partial {\\sigma^2}}{\\partial {\\mathbf{x}}}} &amp;= - 2{\\mathbf{e}}_1^T{\\mathbf{L}}^{-1}{\\frac{\\partial {\\mathbf{k}_u}}{\\partial {\\mathbf{x}}}} + 2{\\mathbf{e}}_2^T{\\mathbf{R}}^{-T}\\left({\\frac{\\partial {\\mathbf{h}_u}}{\\partial {\\mathbf{x}}}} - {\\mathbf{F}}^T{\\mathbf{L}}^{-1}{\\frac{\\partial {\\mathbf{k}_u}}{\\partial {\\mathbf{x}}}}\\right) \\\\ &amp;= - 2[{\\mathbf{L}}^{-T}({\\mathbf{F}}{\\mathbf{r}}+ {\\mathbf{e}}_1)]^T {\\frac{\\partial {\\mathbf{k}_u}}{\\partial {\\mathbf{x}}}} + 2{\\mathbf{r}}^T{\\frac{\\partial {\\mathbf{h}_u}}{\\partial {\\mathbf{x}}}} \\end{aligned} &#x200B;&#x200B;&#x2202;x&#x200B;&#x200B;&#x2202;&#x3C3;&#x200B;2&#x200B;&#x200B;&#x200B;&#x200B;&#x200B;&#x200B;&#x200B;&#x200B;=&#x2212;2e&#x200B;1&#x200B;T&#x200B;&#x200B;L&#x200B;&#x2212;1&#x200B;&#x200B;&#x200B;&#x2202;x&#x200B;&#x200B;&#x2202;k&#x200B;u&#x200B;&#x200B;&#x200B;&#x200B;+2e&#x200B;2&#x200B;T&#x200B;&#x200B;R&#x200B;&#x2212;T&#x200B;&#x200B;(&#x200B;&#x2202;x&#x200B;&#x200B;&#x2202;h&#x200B;u&#x200B;&#x200B;&#x200B;&#x200B;&#x2212;F&#x200B;T&#x200B;&#x200B;L&#x200B;&#x2212;1&#x200B;&#x200B;&#x200B;&#x2202;x&#x200B;&#x200B;&#x2202;k&#x200B;u&#x200B;&#x200B;&#x200B;&#x200B;)&#x200B;=&#x2212;2[L&#x200B;&#x2212;T&#x200B;&#x200B;(Fr+e&#x200B;1&#x200B;&#x200B;)]&#x200B;T&#x200B;&#x200B;&#x200B;&#x2202;x&#x200B;&#x200B;&#x2202;k&#x200B;u&#x200B;&#x200B;&#x200B;&#x200B;+2r&#x200B;T&#x200B;&#x200B;&#x200B;&#x2202;x&#x200B;&#x200B;&#x2202;h&#x200B;u&#x200B;&#x200B;&#x200B;&#x200B;&#x200B;&#x200B; where r=R&#x2212;1e2{\\mathbf{r}}={\\mathbf{R}}^{-1}{\\mathbf{e}}_2r=R&#x200B;&#x2212;1&#x200B;&#x200B;e&#x200B;2&#x200B;&#x200B;. The computation is organized so as to minimize the number of linear solves of the triangular matrices."},{"title":"Professor Ni Naru II","permalink":"http://smanist.github.io/2018/05/27/Professor-Ni-Naru-II/","text":"How to become a professor (in Engineering)? Cases and examples. In short, there are more than one road to Rome. Yet, the general principles agree with those in the previous article. The panelists Prof.&#xA0;M (Tenured, female) Did undergrad in UIUC and worked in industry for 10 years before going to grad school. In the stage of PhD/PostDoc, she was thinking about back to industry afterwards. Yet, the Dean offered a chance in a newly-developed program in engineering education. That is how she ended up to be a faculty member. Prof.&#xA0;J (Tenured, female) Directly became a tenure-track AP after PhD. What surprised her was that (1) she had to be hands off the direct research (such as coding) and focus on writing proposals, and (2) high level of interdisciplinary research (univ. dependent). Two mistakes she wished to have avoided in the AP period are that (1) continuing dissertation research (only) and (2) not knowing the field - resulting in, e.g.&#xA0;journal rejection. Her major tip is that an AP should identify the field of impact and research vision, so that he/she can focus on one core area due to the limited timeframe of the tenure process. She was able to gave birth to a baby while striving for tenure. Having a baby is beneficial in the sense that it makes the life becomes more focused. Work has to be done when the baby is still in daycare. Prof.&#xA0;C (Fresh AP, female) Worked as Postdoc in a NL before becoming an AP. That is probably how she developed a strong publication record. Prof.&#xA0;K (Senior AP, female) She applied for a faculty position to over 30 institutions when she graduated and received around 10 interviews. Now what she thinks is that she should have applied to less places so that the time and energy are more focused. During the negotiation, she was able to convince the dept. to create two courses based on her research work, which are potentially beneficial for her later-on research. Two more tips she offered: Do not be afraid to ask for resources. It is natural and okay to have no experience in the beginning. Prof.&#xA0;L (Just tenured, male) He was hired through an interdisciplinary program between several depts. Now he is running a lab with around 10 grad students and some undergrads. Two things he found challenging: (1) dealing with a few superviors, (2) motivating the students. Concerning work-life balance, he suggested using the conferences as a means for family vacations. Prof.&#xA0;S (Senior AP, male) He and his spouse were hired utilizing the dual-career program offered by the univ. He pointed out that the lab should be treated as a small business. The AP needs to be hands-off the &#x201C;field work&#x201D; and let the students do the labor. Also, one cannot always do what one wants. Q &amp; A Writing research statement The key is to balance the old and new projects. The RS works as research proposals, presenting the new ideas and the start-up budget. This also indicates how one becomes independent from the advisor. The RS also shows the existing technical asset of one person, represented by the old projects. Anyways, make sure the RS receives feedback from the peers and mentors before application. Start-up package It is basically university dependent. Keep in mind that, during the negotiation, the dept. on the AP&#x2019;s side against the univ. in some aspects. A few suggestions: (1) Have a flexible requirement of the necessities. (2) Confirm what courses to teach. (3) Make sure any communication be recorded and all the requirements be written. Getting tenure First of all, check the memos on tenure requirements and talk to senior faculty members for mentoring. Typically, a tier 1 research university focuses on research, but bad teaching would annihilate the tenure. As a mentor The role of a mentor is about not just academics, but also the overall well-being, such as the student&#x2019;s career development. Taking undergrads is usually the starting point of a new AP. Two suggestions: (1) utilize existing univ. program support, (2) avoid people aiming for recommendation letters - maybe give a one-year observation period. Always note that the team chemistry is vital for the lab and the tenure. Time management The key is to prioritize the schedule and do not become deadline-driven. A typical work load of 50 hrs a week is decomposed as 60-70% for R, 20-30% for T, and the rest for S. 60% of time would be spent in course preparation. Work-life balance First, &#x201C;balance&#x201D; itself should be well defined. It could mean a fixed time frame for life and work. Apparently, the understanding of the family and the partner is paramount. Especially the kids would force the AP to optimize the time management. There are univ. guidelines for faculty with family, which could be exploited. Reasons to transit from NL to univ. Family factor Desire to interact with students and have more impact on people."},{"title":"Professor Ni Naru I","permalink":"http://smanist.github.io/2018/05/26/Professor-Ni-Naru-I/","text":"How to become a professor (in Engineering)? General talk. This is the digest of several seminars I attended recently. These are the info. provided by several professors from university, and filtered by my notes. I am not responsible for any biases. Before any discussion in the details, one thing that I think should be kept in mind throughout the academic career is to form the research identity verbally 1&quot;I, Professor X, would like to be known for ...&quot; How does faculty search happen? Before diving into the applicants&#x2019; perspective, let&#x2019;s examine the perspective of the department. Bascially, the dept. would look for a candidate that fits into the departmental culture. The following are the typical steps: Apply to the univ. for slots of new faculty positions. The slots may be prescribed special purposes, e.g.&#xA0;an AP in computer science specializing in machine learning. Set up the search committee (which is common place for the AP to do service). Solicit applications via advertisement, faculty network, and direct scouting. Review applications. Remote interview and evaluate (with rubrics). On-site interview for finalists. Discuss and decide on the final choice(s) and submit to college or univ. for approval. Send out the offer and negotiate with the candidate. Next, from the applicants&#x2019; perspective, the faculty search happens as follows, Step zero is to develop a good research record and reputation. Prepare for application: CV, reference letters (RL), teaching and research statements (TS &amp; RS), cover letter (CL), set up the personal website for showcase. For TS and RS, it is important to have outsider review and emphasis on the mutual institutional fit. Wait: from application deadline to interview. Develop job talk and/or chalk talk. Two things to cover: &#x201C;What is done&#x201D; and &#x201C;What to be done&#x201D;. Make sure to balance the depth and breadth and maintain accessibility for people outside the field. When there is &#x201C;chalk talk&#x201D;, it may be also used to check the teaching capability of the candidate and how one would run a lab. Interview: Several things to keep in mind: Explain to the diverse audience about the accomplishment and goals. Study the background of the people in department. Enjoy and learn - the interview is not necessarily the last one. Wait: from interview to decision notification. Negotiate if given an offer. Like the dept., it is advisable that the applicant check if departmental culture fits himself/herself. Or put in this way, the job of faculty is a long-term endeavor that involves the person and the dept. As a result, the faculty search is essentially a process of mutual fitting. Before faculty A rough time line Before getting a faculty position: Explore - 2 years prior: Search job listing and conduct informal interviews. Prepare - 1 year prior: Prepare the documents CV, RL, TS/RS, CL and have them reviewed, esp. if the univ. provides such resources. Execute - 6 months prior: Prepare for the interview and review the offer with faculty and specialists from the univ. As for the background in PostDoc, the institutional reputation does matter. However, getting experience in mentoring and proposal writing (in a maybe lower level of univ.) is more important than joining in famous labs. National labs Chances are that one goes for national labs (NL) before becoming a faculty member. There are pros and cons. Pros: NL provides funded postdocs and intership with generous benefits. World-class equipments for experimentalist and computational scientists. Work with reputed scientists, which forms the network beneficial for future research, funding, collaboration, and recognition. Chances for publication. Cons: Limitations in immigration status. Publication could be delayed due to bureacratic process or clearance issues. Lesser feeling of contribution as the research project is usually done collectively. Limited freedom to select the research topic. Limited chance for teaching, although possible if there are nearby univs. To initialize the connection with NL, networking is important. Less than 50% of NL positions are publicly advertised and more are filled by recommendation of univ. faculties, or through networking during conferences. During tenure-track A rough time line Year 1: R and T are the focus. S should be minimum. Especially extra time is needed to develop a course. Year 2-3: R goes up and T goes down. Esp. R weighs in due to the mid-term review. S slightly increases and the AP becomes more experienced. Year 4-6: R continues to increase for the final tenure review. S stays more or less the same level. Proposals Writing proposals will be the major task of the new faculty. Practically, he/she needs to pay for students, lab expenses, faculty salary, and travel/logistic costs. Before application, one needs to understand the mission of the funding agency. One basic way is to watch out for the solicitation of the agency, e.g.&#xA0;request for information (RFI), request for proposal (RFP), and broad agency anouncement (BAA). However, more importantly, talk to the manager directly. The manager is indeed the key person associated with the proposal. He/she creates the program, picks the proposal winners, and reports the progress to his/her boss. The general procedure/loop would be (1) present the idea to the manager, (2) let manager criticize or express his/her needs, (3) correct the proposal. One tip is to expect rejections but learn about the feedback. Check out the Heilmeier Catechism when working on the proposal. What are you trying to do? Articulate your objectives using absolutely no jargon. How is it done today, and what are the limits of current practice? What&#x2019;s new in your approach and why do you think it will be successful? Who cares? If you&#x2019;re successful, what difference will it make? What are the risks and the payoffs? How much will it cost? How long will it take? What are the midterm and final &#x201C;exams&#x201D; to check for success? The proposal requires some initial input data obtained based on the start-up funding. A suggested writing order is as follows: Summary of the ideas, deliverables and timeline, budget, background, introduction &amp; conlusion, abstract (most important and thus the last). Make sure to write about the broader impact. A rule is suggested: Seek advice from people who are busy. They are busy because their advices are so valuable that people keep him/her occupied. Service responsibilities Service occurs in two aspects. First, within the campus, there are opportunities in the college/univ., dept., and outreach levels. Second, externally, the service includes professional committees, editorial work, proposal review, and journal review. A few things to think about for the choice of service: High-visibility, networking opportunities, potential impact on R &amp; T. Some good examples are graduate student search committee and proposal review committee. The caveats in service include non-measurable time cost and distraction from R &amp; T, e.g.&#xA0;travelling for external services. Finally, it is better to actively seek and choose the service, instead of passively getting assigned the job. Miscellaneous About growing research team: Be careful about the structure and size, hire the excellent ones and double-think about postdocs and undergrads. Be aware of the common practices in the dept. About whether to continue work of PhD/postdoc: A first question to ask is that whether the area is saturated? Continuted work provides potential early wins, but one eventually needs to branch to new areas. About time management: A few things to consider - (1) When and how to collaborate. (2) Whether to outsource. (3) Respect other&#x2019;s time. (4) Identify the deadline and the key time nodes. (5) Try not to reinvent the wheels. About branding of research: Note the Pygmalion effect, i.e.&#xA0;expectation enhances performance. Sustaining the brand gives positive feedback on publication, citation and impact, students, and sustainable funding."},{"title":"Images in Hexo","permalink":"http://smanist.github.io/2018/04/22/Images-in-Hexo/","text":"Displaying images in Hexo with Markdown. File locations of the images This is straightforward and is discussed in the official documentation. There are two ways. One is to put all images in the so-called global asset folder, source/images, and all posts will need to refer to the images using the path /images/[FILENAME]. The other way is to enable the post asset folder by setting the following flag in _config.yml, 1post_asset_folder: true In this case, the images will be stored separately in a folder of the same name as the post file name. In the post, the image is inserted using the path [FILENAME]. A similar discussion can be found here. Displaying the images Using Markdown The image capabilities of Markdown depends on its implementation. The basic approach can be found here 1![](FILENAME [TEXT]) Some implementations of Markdown support the sizing of the image as discussed here. 1![](FILENAME [TEXT] WIDTHx[HEIGHT]) Unfortunately, it seems the current Markdown engine pandoc does not support the sizing. An example is shown as follows, Using HTML The HTML can be embedded into Markdown. So fancier image displaying can be achieved using HTML snippets. Note that there is also another approach that is based on CSS (an example). However, CSS more or less makes the file structure more complicated. The basic format is, but not limited to, 1&lt;img src=FILENAME [width=WIDTH] [height=HEIGHT] [hspace=HSPACE] [align=&lt;&quot;right&quot;|&quot;left&quot;&gt;] [title=TITLETEXT] [style=STYLESTR]&gt; Note that one can use the style keyword to define the size and alignment, etc. For example, 1style=&quot;width:WIDTH; height:HEIGHT; float:&lt;right|left&gt;&quot; Finally, &lt;img&gt; can be combined with &lt;p&gt;&lt;/p&gt;, &lt;figure&gt;&lt;/figure&gt;, etc to achieve other formatting purposes. The following are some examples. Hover the cursor on the image to see the title. 1&lt;img src=&quot;avatar.jpeg&quot; title=&quot;A regular image&quot; width=&quot;20px&quot; height=&quot;20px&quot;&gt; 1&lt;img src=&quot;avatar.jpeg&quot; title=&quot;Image with right alignment&quot; width=&quot;20px&quot; align=&quot;right&quot;&gt; 1&lt;img src=&quot;avatar.jpeg&quot; title=&quot;Right alignment using style&quot; style=&quot;float:right; width:20px;&quot;&gt; 12&lt;img src=&quot;avatar.jpeg&quot; title=&quot;Multiple images on one line&quot; width=&quot;20px&quot; hspace=&quot;20px&quot;&gt;&lt;img src=&quot;avatar.jpeg&quot; width=&quot;20px&quot;&gt; 1234&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;avatar.jpeg&quot; title=&quot;Multiple images using p with center alignment&quot; width=&quot;20px&quot;&gt; &lt;img src=&quot;avatar.jpeg&quot; width=&quot;20px&quot;&gt;&lt;/p&gt; 12345&lt;figure float=&quot;left&quot;&gt; &lt;img src=&quot;avatar.jpeg&quot; title=&quot;Image 1 with a caption&quot; width=&quot;20px&quot;&gt; &lt;img src=&quot;avatar.jpeg&quot; title=&quot;Image 2 with a caption&quot; width=&quot;20px&quot;&gt; &lt;figcaption&gt;An image with a caption.&lt;/figcaption&gt;&lt;/figure&gt; Images with a caption. More references: HTML alignment HTML multiple images on the same line HTML image with a caption"},{"title":"Adding Fonts in WSL","permalink":"http://smanist.github.io/2018/04/20/Adding-Fonts-in-WSL/","text":"Not using Cygwin. Problem The default fonts that come with WSL/Ubuntu do not work well with emacs - not suitable for long-time editing (at least for me). There are several particular issues. The first one is with the defects with the default font DejaVu Sans Mono (This is probably personal). The second is the scale of the fonts. Finally, the anti-aliasing of the fonts is missing. It seems that anti-aliasing is not supported with Xming. So this article will focus on solving the first two issues. Solving the scaling issue This problem is relatively easy. One way is to set the fontsize particularly in emacs. Another way, which I went with, is to set directly through Xming. This is simple: just add one more argument to the shortcut to the Xming executable. 1Xming.exe [Other options] -dpi 120 Solving font issue The list of fonts that are available to emacs can be found by, 1(print (font-family-list)) The fonts can be tried out by, 1(set-frame-font [FONTNAME]) However, none of them works for me. The font that worked well for me is ubuntu mono, which can be downloaded from here. Next, installing fonts in Xming is pretty straightforward, as shown here. It would require the mkfontscale tool, which is available in the xfonts-utils from apt. Note that mkfontscale is also available in Cygwin, but I do not think it is necessary to install a heavy system like Cygwin just for installing the font. Finally, the new font in emacs is set by 12(set-face-attribute &apos;default nil :height [HEIGHT])(set-face-attribute &apos;default nil :font [FONTNAME])"},{"title":"Python Linting","permalink":"http://smanist.github.io/2018/04/19/Python-Linting/","text":"Make Python clean again. Pylint is a nice tool for code analysis and it is well documented here. The setup of pylint in Emacs has been discussed in a previous article. Pylint is highly-configurable via the .pylintrc file. This article will focus on the tuning of the pylintrc file. The tuning is based on my actual needs. Disabled messages The messages are categorized into four groups: The &#x201C;too-many/few&#x201D; family: too-many-arguments, too-many-branches, too-many-instance-attributes, too-many-locals, too-many-public-methods, too-many-statements, too-few-public-methods. Having something &#x201C;too many&#x201D; typically indicates the code is not well designed. Yet, how many is &#x201C;too many&#x201D;? It really depends and a maximum number given in PEP or pylint may not be practical. Same thing for &#x201C;too few&#x201D;. False-positive: no-member, unbalanced-tuple-unpacking. After all, pylint is not able to actually run the code and identify the variables that are created dynamically or in a context-dependent manner. In these cases, pylint raise distracting false-positive messages. Code style: bad-whitespace, invalid-name. The PEP does have a long style guide. But it is hard and unnecessary to modify the code style of a large project with another set of self-consistent styles. Code design: broad-except, protected-access. These, probably, should not be disabled. However, better solutions might just require large scale refactorization, which is undesirable. Messages not to be disabled Up until now, one item is found to be important and should not be disabled: cell-var-from-loop. Consider this case, where i turns out to be the same in all three lambda functions. 1234funcList = []for i in range(3): funcList.append(lambda x: i*x)funcList[0](3) # = 6, supposed to be 0 This is where the cell-var-from-loop message will be raised. The correct way is to define the lambda function with a default argument, 1lambda x, arg=i: arg*x More to be updated in the future. References: List of pylint messages Explanation of pylint messages"},{"title":"Exploring CAS","permalink":"http://smanist.github.io/2018/04/15/Exploring-CAS/","text":"CAS for Computer Algebra System. Problem Recently I ran into a situation that I needed to do some symbolic math but did not have access to a decent CAS software. I have been a Mathematica user for quite long time, but it is apparently not available everywhere. After struggling with my problem, this question is raised: What is a good substitue for Mathematica? What I like about Mathematica include: Strong symbolic capabilities in simplification, polynomials, calculus, etc. Support for multiple paradigms, including functional programming - and everything is a list. Notebook-like GUI with various export options. For the substitute, I hope it is light-weight and easy to pick up. Exploration A long of list of major CAS software can be found here. Removing the specialized ones and picking the ones with as many capabilities as possible, some candidates are selected. These include: Maxima, SymPy, SageMath, Axiom, and FriCAS. For completeness of discussion, there is also Rubi based on Mathematica, which focuses solely on integration. Axiom and FriCAS Axiom and FriCAS, as a fork of Axiom, used HyperDoc as its GUI, which is - sorry to use this word - ugly. FriCAS is said to be particularly good at integrations. However, its capability in simplification is very limited, as documented by itself. Candidates eliminated. SageMath SageMath is somewhat more than a CAS software, as it tries to include many other capabilities like those in MATLAB. However, that is exactly my issue with SageMath. The capabilities depend on different other packages, include Maxima and SymPy as mentioned above. That makes the ecosystem way too heavy for the CAS purpose. Candidate eliminated. SymPy SymPy is nice in the sense that it is in the Python ecosystem and is expected to work well with the NumPy toolchain. So it is very easy to pick up (at least for a heavy Python user). Moreover, the Jupyter notebook provides a good solution for the GUI. Yet, its symbolic capability is limited. Maxima Maxima appears to be another CAS language that is easy to pick up. A GUI option is provided by wxMaxima, which looks like Mathematica and Jupyter. Its symbolic capability is fair. There is also an App MaximaOnAndroid on the smart phone. Assessment Two sets of tests are found for assessing the symbolic capabilities of CAS. The first one is the Charlwood&apos;s Integration Problems, which are documented here and here. The integral problem, or the antiderivative problem, is considered difficult for a CAS system. The aforementioned integration problems are specially developed for testing CAS. In the so-called ten &#x201C;hardest&#x201D; integrals, the performance of Maxima is fair (8 out of 10), while SymPy only got 2 correct. The second one is from the blog Maxima v.s. Mathematica. A set of problems, including limit operation, integrals, simplification, algebraic equation solver, are discussed. In all problems, Maxima either provides a wrong answer, or fails to provide an answer. The blog is old (2015), but as of writing, I have tried all the problems except the simplification ones on (1) Maxima 5.40 using MaximaOnAndroid and (2) SymPy 1.1. For Maxima, no improvement is identified. SymPy fails in the integrals (again), but it did much better than Maxima in the algebraic solver. The test is unnecessarily fair, as there is always an aspect of a CAS software that is weaker than that of another. Subsequently, wxMaxima is tried out on WSL. There is a Windows version for wxMaxima, but I prefer to have it in Linux-like environment. The installation is standard. However, the Maxima kernel somehow does not work. The kernel terminates upon start with an error message personality failure 38. This appears to be an issue with WSL support for Common LISP, as identified here and here. So, finally, SymPy with the Jupyter environment is down-selected for the open-source substitute for Mathematica. Nevertheless, there is probably no real open-source substitute for Mathematica after all."},{"title":"Fun With WSL","permalink":"http://smanist.github.io/2018/03/23/Fun-with-WSL/","text":"Now I hate Windows less. Windows subsystem for Linux (WSL) has come out for a while. It started from the insider preview version, migrated to Windows Store, and recently expanded its support to multiple Linux distributions, which caught my eyeball. As a user who ditched Windows for Linux, WSL is intriguing to me and I decided to try it out. Installation and configuration I selected the Ubuntu distribution to install. The installation through Windows Store is straightforward. The only thing to note is that, for a first-time installation, the WSL feature has to be enabled through PowerShell with Administrator privilege, 1Enable-WindowsOptionalFeature -Online -FeatureName Microsoft-Windows-Subsystem-Linux I had a problem during the installation though, that the process appeared to be frozen. However, when I restarted the computer (hallmark of Windows), it turns out the Ubuntu distribution is already installed in WSL. Due to this detour, I had to set up the user accounts manually in WSL, 123456# Create user with home folderuseradd -m &lt;username&gt;# Set passwordpasswd &lt;username&gt;# Add user to sudo groupusermod -aG sudo &lt;username&gt; Afterwards, one also needs to set the default user for WSL, otherwise the start-up account would still be the root. In PowerShell do 1ubuntu config --default-user &lt;username&gt; Finally, upgrade the Ubuntu distribution, 12sudo apt-get updatesudo apt-get upgrade Unlike Windows itself, the WSL does not have a native graphical engine. So interacting with WSL would be like accessing a remote computer. Yet, it is possible to install a third-party X server, e.g.&#xA0;the Xming X server. Make sure Xming is running in Windows, a GUI program in WSL can be invoked as, 1DISPLAY=:0 &lt;program&gt; Possible application: Editor replacement In Windows, it is somehow difficult to find a good editor. Maybe that is because Windows has &#x201C;too&#x201D; good graphical support than Linux. What I looked for is something like Emacs (or Vim) - lightweight, higly-configurable, highly-extensible, support multiple languages. However, being lightweight appears to be contradict to the rest of the properties. Eventually NotePad++ is down-selected for its lightweightness. Yet, I would not use it to work on large projects. The recent rising star, VS code, is fancy and nice. I like it but it is too heavy for my machine. I did not try the Emacs for Windows, thought that it is not very meaningful to use Emacs without its ecosystem on Linux. But now, with WSL, why not consider Emacs again? The installation and the configuration could be done single-handedly in WSL. By configuration I mean copying the files from my config repo. By the way, to download auxiliary files from a code hosting website, the regular wget might not work, one has to use curl, 1curl --digest --user &lt;username&gt;:&lt;password&gt; &lt;url&gt; -o &lt;output&gt; First, the Emacs in terminal mode is tested. Working with terminal mode appears simpler as it does not require Xming. However, the problem is with the keyboard mapping. I struggled for some time and eventually gave up. The underlying issue is that the terminal interprets whatever the keyboard sends it into a sequence of characters, which are then sent to Emacs. Therefore, Emacs could not get whatever the terminal could not understand. This could result in behaviors like, mapping the arrow keys and Home/End keys to the letters ABCDHF. This particular one is easy to fix though, (with ergoemacs mode), by disabling a key binding in the configuration file, 1(global-unset-key &quot;\\M-O&quot;) However, there are worse issues. For example, the terminal could not understand the Windows key (i.e. super key) and differentiate upper and lower cases. There is no way to patch that in Emacs. Working with terminal Emacs is only possible if I gave up half of my customized key-bindings. Next, I switched to the regular GUI Emacs. The memory usage is around 30 MB (plus 6 MB for Xming), about 2% of what VS code requires. This clears my last concern about the GUI mode - &#x201C;Emulating&#x201D; X-server-based GUI does not really take much memory like virtual machine would do. The operation in GUI Emacs is smooth and pretty much the same as that in Linux - except that one need to make sure to have Xming run with the keyhook option, otherwise the super could not be picked up. This can be done by modifying the shortcut to the Xming application. Concerning the comparison between the terminal and GUI modes, there has been quite a few discussions (see references). Looks like people do favor GUI over terminal for Emacs. For the GUI Emacs, the last issue is to figure out a way to run it easily. It would be tedious to start a bash and type in emacs before working every time. The solution is surprisingly simple via the short-cut mechanism. Create a shortcut and define the command as 1C:\\Windows\\System32\\bash.exe -c &quot;DISPLAY=:0 emacs&quot; Set the Run mode to be &#x201C;Minimized&#x201D;, so that one do not need to worry about the companying bash window. A logo for the shortcut can be found here. One final thing to note, the files under Windows can be accessed in WSL by the path \\mnt\\&lt;disk&gt;\\Users\\&lt;username&gt;. To save some effort in typing, one can try the bookmark-set/bookmark-jump command in Emacs to record and jump to the location. References: Set default user Xming manual Emacs: GUI Emacs vs Terminal Emacs Don&#x2019;t Use Terminal Emacs"},{"title":"Emacs for Python and C/C++","permalink":"http://smanist.github.io/2018/01/17/Emacs-for-Python-Cpp/","text":"New configuration for the new year. This document covers the configuration of the syntax checking and code completion for Python and C/C++ in Emacs. Emacs version Emacs should be &gt;= 24.4, preferably &gt; 25.0. Mine was 24.3 before the upgrade and it does not work with some of the packages covered next. The upgrade can be done using the standard apt-get protocol following this, 123add-apt-repository ppa:kelleyk/emacsapt-get updateapt-get install emacs25 Root privilege is needed. After installation, make sure the latest version is used, not the old one. All the packages in emacs mentioned below can be installed via the package system via sources ELPA or MELPA. Details found here. Common modules Code completion Let&#x2019;s start with two common modules for code completion: packages yasnippets and auto-complete (AC for short). The two modules would work with most of the languages, theoretically. Yasnippets allows the insertion of code snippets by typing in a few letters. I configured it in the following way, 1234(require &apos;yasnippet)(yas-load-directory &quot;path-to-yasnippet/snippets&quot;) ;; User provided snippets(define-key yas-minor-mode-map [(tab)] nil)(define-key yas-minor-mode-map [(backtab)] &apos;yas-expand) The best part is that the users can create their own snippets. The function of auto-complete is self-explanatory. It tries to complete a few letters with a table of candidates. Following is a basic configuration, 123(require &apos;auto-complete)(require &apos;auto-complete-config)(ac-config-default) It could be annoying if AC tries to complete every letter one types in. I disabled the automatic completion, so that I auto-complete my input when I want to, 12(setq ac-auto-start nil)(define-key ac-mode-map (kbd &quot;your_kbd&quot;) &apos;auto-complete) The default AC table could be squeezed too much by candidates of very long names. One way to avoid that is to install and use the pos-tip package. 1(require &apos;pos-tip) Syntax checking Another necessary emacs package is flycheck as a general framework for checking the syntax. The setup is as follows, 12345(defun flycheck-kbd-map () (local-set-key (kbd &quot;your_kbd&quot;) &apos;flycheck-buffer) ;; Check the buffer for errors (local-set-key (kbd &quot;your_kbd&quot;) &apos;flycheck-clear) ;; Clear the error labels (local-set-key (kbd &quot;your_kbd&quot;) &apos;flycheck-list-errors)) ;; List the errors in a separate window(add-hook &apos;flycheck-mode-hook &apos;flycheck-kbd-map) If there were too many errors, flycheck might overflow and clear up all errors. To mitigate that, raise the threshold 1(setq flycheck-checker-error-threshold 10000) Python Mode Now getting to the Python-specific setups, which are based on this video. Two emacs packages are needed: python-mode and jedi. In the meanwhile, the packages epc, jedi and pylint have to be installed in the Python environment, as the backends to jedi and flycheck in emacs. On the Python side, the installation can be done with pip. 1pip install [--upgrade] your_packages The .emacs setup looks like this, 1234567891011121314(require &apos;python-mode)(add-hook &apos;python-mode-hook &apos;yas-minor-mode)(add-hook &apos;python-mode-hook &apos;flycheck-mode)(autoload &apos;python-mode &quot;python-mode&quot; &quot;Python Mode.&quot; t)(require &apos;jedi)(add-to-list &apos;ac-sources &apos;ac-source-jedi-direct)(setq jedi:complete-on-dot t)(setq jedi:tooltip-method &apos;pos-tip)(defun jedi-config:setup-keys () (local-set-key (kbd &quot;your_kbd&quot;) &apos;jedi:goto-definition) (local-set-key (kbd &quot;your_kbd&quot;) &apos;jedi:show-doc))(add-hook &apos;python-mode-hook &apos;jedi:setup)(add-hook &apos;python-mode-hook &apos;jedi-config:setup-keys) If Cython is needed as well, install packages cython-mode and flycheck-cython in emacs. And the setup, (require &#x2019;cython-mode) (require &#x2019;flycheck-cython) (add-hook &#x2019;cython-mode-hook &#x2019;yas-minor-mode) (add-hook &#x2019;cython-mode-hook &#x2019;flycheck-mode) (autoload &#x2019;cython-mode &#x201C;cython-mode&#x201D; &#x201C;Cython Mode.&#x201D; t) With the Cython mode present, the association of file extensions could be tricky. One needs to disable the default settings in the Python mode, so as to enable correct activation of cython-mode. 12345(setq auto-mode-alist (rassq-delete-all &apos;python-mode auto-mode-alist))(add-to-list &apos;auto-mode-alist &apos;(&quot;\\\\.py\\\\&apos;&quot; . python-mode))(setq auto-mode-alist (rassq-delete-all &apos;cython-mode auto-mode-alist))(add-to-list &apos;auto-mode-alist &apos;(&quot;\\\\.pyx\\\\&apos;&quot; . cython-mode))(add-to-list &apos;auto-mode-alist &apos;(&quot;\\\\.pxd\\\\&apos;&quot; . cython-mode)) With the above setup, the python and cython modes are activated when and only when py files and pyx/pxd files are opened, respectively. C/C++ Mode The configuration to be presented is rather simple. However, the exploration of some possibilities took quite a while. The tagging system - Trials The center issue is the parsing of the source code, i.e.&#xA0;the tagging system. C/C++ code requires compilation and linking and the parsing is not as simple as that of Python. I found three options: rtags, ctags and gtags. (Well, there is also etags, which was not tried out.) Rtags, based on LLVM/Clang, appears to be popular. Moreover, there is a cmake-ide package that integrates well with rtags and the CMake ecosystem. The best part is that it can infer all compiler flags from the cmake files. And unlike the other two tools, no extra tagging file has to be generated. The compilation of the code is also straight-forward, since everything is defined by the CMake files. The rtags-based tools in emacs can be easily found using command package-list-packages. One example setup of the cmake-ide mode can be found here. I also tried a similar setup, which requires cmake-ide and its dependencies, 1234(require &apos;rtags)(require &apos;cmake-ide)(cmake-ide-setup)(setq cmake-ide-flags-c++ (append &apos;(&quot;-std=c++11&quot;))) However, one year later, the same author switched to another set of tools that is light-weight. I ditched the rtags approach too, after trying for half an hour. The installation of rtags is OK, only took 2.5 hours. The running of rtags is painful - it uses up all allowable resources. The author used a combination of ctags and counsel-etags. This combination had certain minor problems on my machine. So I continued to look for other solutions. Then there comes the gtags-based approach. Two configurations that are more or less equivalent are discussed. One is based on helm-gtags, the other ggtags. I tried the setup with helm-gtags, 1234567(add-hook &apos;c-mode-hook &apos;helm-gtags-mode)(add-hook &apos;c++-mode-hook &apos;helm-gtags-mode)(eval-after-load &quot;helm-gtags&quot; &apos;(progn (define-key helm-gtags-mode-map (kbd &quot;your_kbd&quot;) &apos;helm-gtags-dwim) (define-key helm-gtags-mode-map (kbd &quot;your_kbd&quot;) &apos;helm-gtags-pop-stack) (define-key helm-gtags-mode-map (kbd &quot;your_kbd&quot;) &apos;helm-gtags-update-tags))) It works, but not so stable on my system. Sometimes the parse fails without a good reason. Finally ggtags is down-selected. Setting up gtags The command line tool gtags can be downloaded from here and the installation procedure is standard. In emacs, the packages company and ggtags are required. Basically company calls ggtags via company-capf for code completion. AC is replaced by company, as the latter works with gtags better than AC. The setup is as follows, 12345678(defun company-kbd-map () (local-set-key (kbd &quot;your_kbd&quot;) &apos;company-complete)) ;; Just like auto-complete(add-hook &apos;company-mode-hook &apos;company-kbd-map)(defun ggtags-kbd-map () (local-set-key (kbd &quot;your_kbd&quot;) &apos;ggtags-find-tag-dwim) ;; Jump to definition (local-set-key (kbd &quot;your_kbd&quot;) &apos;ggtags-prev-mark) ;; Return to the file before jumping (local-set-key (kbd &quot;your_kbd&quot;) &apos;ggtags-update-tags)) ;; Refresh the tagging files(add-hook &apos;ggtags-mode-hook &apos;ggtags-kbd-map) Since company is used instead of AC, AC needs to be turned off explicitly in C/C++ modes. Yasnippets and flycheck are used as well. Particularly, flycheck for c++-mode is to set for the C++11 standard. 12345678910(add-hook &apos;c-mode-common-hook (lambda () (when (derived-mode-p &apos;c-mode &apos;c++-mode) (auto-complete-mode 0) (yas-minor-mode 1) (flycheck-mode 1) (ggtags-mode 1) (company-mode 1))))(add-hook &apos;c++-mode-hook (lambda () (setq flycheck-gcc-language-standard &quot;c++11&quot;))) Others I do recommend the solarized color theme, which requires packages color-theme and color-theme-solarized. For emacs &gt;= 24, activate by 1(load-theme &apos;solarized t) Other references: auto-complete flycheck emacswiki for Python"},{"title":"Gaussian Process Regressor - Part III","permalink":"http://smanist.github.io/2017/09/28/Gaussian-process-regressor-part-3/","text":"Finally, let&#x2019;s talk about some variants of GPR. Limitations of GPR In previous articles (here and here), the classical formulation of Gaussian process regression (GPR) is presented. Relevant software implementation is also discussed and compared. GPR is non-parametric, and thus very flexible - it can handle any data set. Moreover, it provides the error estimate of the prediction. However, a non-parametric model like GPR has its inherent disadvantages. The prediction depends on the data set. That is, the model does not actually extract any information from the data, and it is essentially brute-force curve-fitting. Furthermore, the model is dense. The prediction requires accessing all the training data, resulting in expensive dense matrix operations. In fact, given NNN training data points, the trainging stage requires O(N3)O(N^3)O(N&#x200B;3&#x200B;&#x200B;) cost due to dense matrix inversion, and the prediction stage requires O(N2)O(N^2)O(N&#x200B;2&#x200B;&#x200B;) cost due to dense matrix multiplication. Towards Large Dataset In an effort to cure the weaknesses of GPR, a lot of modern variants have been developed. The basic idea is to reduce the effective NNN in the model. The classification of variants have been well discussed in Chap. 8 of GPML and Quin2005. The variants can be roughly classified into two types. In the first type, the covariance matrices are replaced by their low-rank approximations, so that the cost of matrix operations depends on the rank instead of NNN. The major criticism is that the GP becomes degenerate due to the approximation. A degenerate GP would predict low or zero variance in regions far away from the training data set, which is not desirable. In the second type, a partial set of data points is selected to represent the whole data set, thus directly reducing NNN. The challenge is, how to select the point? Greedy method might work but is probably suboptimal. There is also the variational approach that sparsifies the PGR, but I am not familiar with this aspect yet. One interesting approach is the relevance vector machine (RVM). It applies the idea of automatic relevance determination (ARD) and finds the training data point that is of the most &#x201C;relevance&#x201D; to the model. Subsequently, a kernel is constructed from these &#x201C;relevance vectors&#x201D; to form the final prediction model. Due to the construction of the kernel, RVM is a degenerate GP, which is criticized in Rasm2005. A fun fact of RVM is that its 2001 version algorithm is patented, and partially discouraged its integration into some mainstream packages. Note that its faster, 2003 version of algorithm is not patented, though. One good Python implementation of RVM can be found here. Another approach of the second type is the GPR with pseudo-inputs Snel2008, or termed fully independent training conditional (FITC). This approach determines a set of points from the training data, not necessarily the points in the data set itself, and generates the GPR over these &#x201C;pseudo inputs&#x201D;. The GP is still non-degenerate, but NNN can be significantly reduced, sometimes by two orders of magnitudes. Yet the prediction is not deteriorated by much. A Unifying View In Quin2005, a unified framework for sparse GPR (and GPR itself) is proposed, from which the variants discussed above can be derived. Outline of framework In the framework, one has to differentiate between two types of variables. One is the observed noisy output y{\\mathbf{y}}y, the other the underlying noise-free latent output f{\\mathbf{f}}f, y=f+&#x3F5;\\displaystyle {\\mathbf{y}}= {\\mathbf{f}}+ \\epsilon y=f+&#x3F5; where &#x3F5;&#x223C;N(0,&#x3C3;n2)\\epsilon\\sim{\\mathcal{N}}(0,{\\sigma_n^2})&#x3F5;&#x223C;N(0,&#x3C3;&#x200B;n&#x200B;2&#x200B;&#x200B;) is the noise, assumed to be additive and independent. The conditional satisfies y&#x2223;f&#x223C;N(vf,&#x3C3;n2){\\mathbf{y}}|{\\mathbf{f}}\\sim {\\mathcal{N}}(vf,{\\sigma_n^2})y&#x2223;f&#x223C;N(vf,&#x3C3;&#x200B;n&#x200B;2&#x200B;&#x200B;). The training data is considered noisy, i.e. ys{\\mathbf{y}}_sy&#x200B;s&#x200B;&#x200B; is provided for training. However, the prediction is expected to be noise-free, i.e. fu{\\mathbf{f}}_uf&#x200B;u&#x200B;&#x200B; is desired. Using a Bayesian approach, the prediction can be formulated as follows, p(fu&#x2223;ys)=&#x222B;p(fs,fu&#x2223;ys)dfs=&#x222B;p(ys&#x2223;fs,fu)p(fs,fu)p(ys)dfs=1p(ys)&#x222B;p(ys&#x2223;fs)p(fs,fu)dfs\\displaystyle \\begin{aligned} p({\\mathbf{f}}_u|{\\mathbf{y}}_s) &amp;= \\int p({\\mathbf{f}}_s,{\\mathbf{f}}_u|{\\mathbf{y}}_s) d{\\mathbf{f}}_s \\\\ &amp;= \\int \\frac{p({\\mathbf{y}}_s|{\\mathbf{f}}_s,{\\mathbf{f}}_u)p({\\mathbf{f}}_s,{\\mathbf{f}}_u)}{p({\\mathbf{y}}_s)} d{\\mathbf{f}}_s \\\\ &amp;= \\frac{1}{p({\\mathbf{y}}_s)} \\int p({\\mathbf{y}}_s|{\\mathbf{f}}_s)p({\\mathbf{f}}_s,{\\mathbf{f}}_u) d{\\mathbf{f}}_s \\\\ \\end{aligned} &#x200B;p(f&#x200B;u&#x200B;&#x200B;&#x2223;y&#x200B;s&#x200B;&#x200B;)&#x200B;&#x200B;&#x200B;&#x200B;&#x200B;&#x200B;=&#x222B;p(f&#x200B;s&#x200B;&#x200B;,f&#x200B;u&#x200B;&#x200B;&#x2223;y&#x200B;s&#x200B;&#x200B;)df&#x200B;s&#x200B;&#x200B;&#x200B;=&#x222B;&#x200B;p(y&#x200B;s&#x200B;&#x200B;)&#x200B;&#x200B;p(y&#x200B;s&#x200B;&#x200B;&#x2223;f&#x200B;s&#x200B;&#x200B;,f&#x200B;u&#x200B;&#x200B;)p(f&#x200B;s&#x200B;&#x200B;,f&#x200B;u&#x200B;&#x200B;)&#x200B;&#x200B;df&#x200B;s&#x200B;&#x200B;&#x200B;=&#x200B;p(y&#x200B;s&#x200B;&#x200B;)&#x200B;&#x200B;1&#x200B;&#x200B;&#x222B;p(y&#x200B;s&#x200B;&#x200B;&#x2223;f&#x200B;s&#x200B;&#x200B;)p(f&#x200B;s&#x200B;&#x200B;,f&#x200B;u&#x200B;&#x200B;)df&#x200B;s&#x200B;&#x200B;&#x200B;&#x200B; where fs{\\mathbf{f}}_sf&#x200B;s&#x200B;&#x200B; is going to be integrated out, or &#x201C;marginalized&#x201D;, as it is of no interest to the prediction. The preceeding term p(ys)p({\\mathbf{y}}_s)p(y&#x200B;s&#x200B;&#x200B;) is essentially a normalizing factor and will not be computed explicitly. The remaining term p(fs,fu)p({\\mathbf{f}}_s,{\\mathbf{f}}_u)p(f&#x200B;s&#x200B;&#x200B;,f&#x200B;u&#x200B;&#x200B;) in the integration would satisfy the joint Gaussian distribution as in previous derivations. This is where the large dense covariance matrix is introduced. This is where the simplification comes in. In the framework, a set of inducing points fi{\\mathbf{f}}_if&#x200B;i&#x200B;&#x200B; is assumed to be sampled from the GP like fs{\\mathbf{f}}_sf&#x200B;s&#x200B;&#x200B; and fu{\\mathbf{f}}_uf&#x200B;u&#x200B;&#x200B;. Therefore, the probability should satisfy, p(fs,fu)=&#x222B;p(fs,fu,fi)dfi=&#x222B;p(fs,fu&#x2223;fi)p(fi)dfi\\displaystyle p({\\mathbf{f}}_s,{\\mathbf{f}}_u) = \\int p({\\mathbf{f}}_s,{\\mathbf{f}}_u,{\\mathbf{f}}_i) d{\\mathbf{f}}_i = \\int p({\\mathbf{f}}_s,{\\mathbf{f}}_u|{\\mathbf{f}}_i)p({\\mathbf{f}}_i) d{\\mathbf{f}}_i p(f&#x200B;s&#x200B;&#x200B;,f&#x200B;u&#x200B;&#x200B;)=&#x222B;p(f&#x200B;s&#x200B;&#x200B;,f&#x200B;u&#x200B;&#x200B;,f&#x200B;i&#x200B;&#x200B;)df&#x200B;i&#x200B;&#x200B;=&#x222B;p(f&#x200B;s&#x200B;&#x200B;,f&#x200B;u&#x200B;&#x200B;&#x2223;f&#x200B;i&#x200B;&#x200B;)p(f&#x200B;i&#x200B;&#x200B;)df&#x200B;i&#x200B;&#x200B; where fi&#x223C;N(mi,Kii){\\mathbf{f}}_i\\sim{\\mathcal{N}}({\\mathbf{m}}_i,{\\mathbf{K}}_{ii})f&#x200B;i&#x200B;&#x200B;&#x223C;N(m&#x200B;i&#x200B;&#x200B;,K&#x200B;ii&#x200B;&#x200B;). The formulation up to here is still exact. The integration for p(fu&#x2223;ys)p({\\mathbf{f}}_u|{\\mathbf{y}}_s)p(f&#x200B;u&#x200B;&#x200B;&#x2223;y&#x200B;s&#x200B;&#x200B;) would result in the regular GPR model. Now here comes the key assumption in the framework, fs{\\mathbf{f}}_sf&#x200B;s&#x200B;&#x200B; and fu{\\mathbf{f}}_uf&#x200B;u&#x200B;&#x200B; are conditionally independent given fi{\\mathbf{f}}_if&#x200B;i&#x200B;&#x200B;, p(fs,fu)&#x2248;q(fs,fu)=&#x222B;q(fs&#x2223;fi)q(fu&#x2223;fi)p(fi)dfi\\displaystyle p({\\mathbf{f}}_s,{\\mathbf{f}}_u) \\approx q({\\mathbf{f}}_s,{\\mathbf{f}}_u) = \\int q({\\mathbf{f}}_s|{\\mathbf{f}}_i) q({\\mathbf{f}}_u|{\\mathbf{f}}_i) p({\\mathbf{f}}_i) d{\\mathbf{f}}_i p(f&#x200B;s&#x200B;&#x200B;,f&#x200B;u&#x200B;&#x200B;)&#x2248;q(f&#x200B;s&#x200B;&#x200B;,f&#x200B;u&#x200B;&#x200B;)=&#x222B;q(f&#x200B;s&#x200B;&#x200B;&#x2223;f&#x200B;i&#x200B;&#x200B;)q(f&#x200B;u&#x200B;&#x200B;&#x2223;f&#x200B;i&#x200B;&#x200B;)p(f&#x200B;i&#x200B;&#x200B;)df&#x200B;i&#x200B;&#x200B; This means the dependency of fu{\\mathbf{f}}_uf&#x200B;u&#x200B;&#x200B; on fs{\\mathbf{f}}_sf&#x200B;s&#x200B;&#x200B; is indirectly induced by fi{\\mathbf{f}}_if&#x200B;i&#x200B;&#x200B;. As a reference, the exact forms of the conditionals and the covariance matrix are, {fs&#x2223;fi&#x223C;N(ms&#x2212;KsiKii&#x2212;1(fi&#x2212;mi),Kss&#x2212;Qss)fu&#x2223;fi&#x223C;N(mu&#x2212;KuiKii&#x2212;1(fi&#x2212;mi),Kuu&#x2212;Quu)K=[KssKsuKusKuu]\\displaystyle \\left\\{ \\begin{aligned} {\\mathbf{f}}_s|{\\mathbf{f}}_i &amp;\\sim {\\mathcal{N}}({\\mathbf{m}}_s-{\\mathbf{K}}_{si}{\\mathbf{K}}_{ii}^{-1}({\\mathbf{f}}_i-{\\mathbf{m}}_i), {\\mathbf{K}}_{ss}-{\\mathbf{Q}}_{ss}) \\\\ {\\mathbf{f}}_u|{\\mathbf{f}}_i &amp;\\sim {\\mathcal{N}}({\\mathbf{m}}_u-{\\mathbf{K}}_{ui}{\\mathbf{K}}_{ii}^{-1}({\\mathbf{f}}_i-{\\mathbf{m}}_i), {\\mathbf{K}}_{uu}-{\\mathbf{Q}}_{uu}) \\end{aligned} \\right. \\quad{\\mathbf{K}}= \\begin{bmatrix} {\\mathbf{K}}_{ss} &amp; {\\mathbf{K}}_{su} \\\\ {\\mathbf{K}}_{us} &amp; {\\mathbf{K}}_{uu} \\end{bmatrix} {&#x200B;f&#x200B;s&#x200B;&#x200B;&#x2223;f&#x200B;i&#x200B;&#x200B;&#x200B;f&#x200B;u&#x200B;&#x200B;&#x2223;f&#x200B;i&#x200B;&#x200B;&#x200B;&#x200B;&#x200B;&#x223C;N(m&#x200B;s&#x200B;&#x200B;&#x2212;K&#x200B;si&#x200B;&#x200B;K&#x200B;ii&#x200B;&#x2212;1&#x200B;&#x200B;(f&#x200B;i&#x200B;&#x200B;&#x2212;m&#x200B;i&#x200B;&#x200B;),K&#x200B;ss&#x200B;&#x200B;&#x2212;Q&#x200B;ss&#x200B;&#x200B;)&#x200B;&#x223C;N(m&#x200B;u&#x200B;&#x200B;&#x2212;K&#x200B;ui&#x200B;&#x200B;K&#x200B;ii&#x200B;&#x2212;1&#x200B;&#x200B;(f&#x200B;i&#x200B;&#x200B;&#x2212;m&#x200B;i&#x200B;&#x200B;),K&#x200B;uu&#x200B;&#x200B;&#x2212;Q&#x200B;uu&#x200B;&#x200B;)&#x200B;&#x200B;K=[&#x200B;K&#x200B;ss&#x200B;&#x200B;&#x200B;K&#x200B;us&#x200B;&#x200B;&#x200B;&#x200B;&#x200B;K&#x200B;su&#x200B;&#x200B;&#x200B;K&#x200B;uu&#x200B;&#x200B;&#x200B;&#x200B;] where Qab=KaiKii&#x2212;1Kib{\\mathbf{Q}}_{ab}={\\mathbf{K}}_{ai}{\\mathbf{K}}_{ii}^{-1}{\\mathbf{K}}_{ib}Q&#x200B;ab&#x200B;&#x200B;=K&#x200B;ai&#x200B;&#x200B;K&#x200B;ii&#x200B;&#x2212;1&#x200B;&#x200B;K&#x200B;ib&#x200B;&#x200B;. Approximations Under the above framework, all the approximations are actually simplifying or approximating the term K&#x2217;&#x2217;&#x2212;Q&#x2217;&#x2217;{\\mathbf{K}}_{**}-{\\mathbf{Q}}_{**}K&#x200B;&#x2217;&#x2217;&#x200B;&#x200B;&#x2212;Q&#x200B;&#x2217;&#x2217;&#x200B;&#x200B;. For example, the low-rank approximation approach is effectively using, {fs&#x2223;fi&#x223C;N(ms&#x2212;KsiKii&#x2212;1(fi&#x2212;mi),O)fu&#x2223;fi&#x223C;N(mu&#x2212;KuiKii&#x2212;1(fi&#x2212;mi),O)K=[QssQsuQusQuu]\\displaystyle \\left\\{ \\begin{aligned} {\\mathbf{f}}_s|{\\mathbf{f}}_i &amp;\\sim {\\mathcal{N}}({\\mathbf{m}}_s-{\\mathbf{K}}_{si}{\\mathbf{K}}_{ii}^{-1}({\\mathbf{f}}_i-{\\mathbf{m}}_i), {\\mathbf{O}}) \\\\ {\\mathbf{f}}_u|{\\mathbf{f}}_i &amp;\\sim {\\mathcal{N}}({\\mathbf{m}}_u-{\\mathbf{K}}_{ui}{\\mathbf{K}}_{ii}^{-1}({\\mathbf{f}}_i-{\\mathbf{m}}_i), {\\mathbf{O}}) \\end{aligned} \\right. \\quad{\\mathbf{K}}= \\begin{bmatrix} {\\mathbf{Q}}_{ss} &amp; {\\mathbf{Q}}_{su} \\\\ {\\mathbf{Q}}_{us} &amp; {\\mathbf{Q}}_{uu} \\end{bmatrix} {&#x200B;f&#x200B;s&#x200B;&#x200B;&#x2223;f&#x200B;i&#x200B;&#x200B;&#x200B;f&#x200B;u&#x200B;&#x200B;&#x2223;f&#x200B;i&#x200B;&#x200B;&#x200B;&#x200B;&#x200B;&#x223C;N(m&#x200B;s&#x200B;&#x200B;&#x2212;K&#x200B;si&#x200B;&#x200B;K&#x200B;ii&#x200B;&#x2212;1&#x200B;&#x200B;(f&#x200B;i&#x200B;&#x200B;&#x2212;m&#x200B;i&#x200B;&#x200B;),O)&#x200B;&#x223C;N(m&#x200B;u&#x200B;&#x200B;&#x2212;K&#x200B;ui&#x200B;&#x200B;K&#x200B;ii&#x200B;&#x2212;1&#x200B;&#x200B;(f&#x200B;i&#x200B;&#x200B;&#x2212;m&#x200B;i&#x200B;&#x200B;),O)&#x200B;&#x200B;K=[&#x200B;Q&#x200B;ss&#x200B;&#x200B;&#x200B;Q&#x200B;us&#x200B;&#x200B;&#x200B;&#x200B;&#x200B;Q&#x200B;su&#x200B;&#x200B;&#x200B;Q&#x200B;uu&#x200B;&#x200B;&#x200B;&#x200B;] The covariance matrices are neglected and the &#x201C;distributions&#x201D; become deterministic, and hence the term Deterministic Inducing Conditional (DIC) in the framework. The zero covariance matrix is exactly the cause of the zero error estimation in this type of approach. The approximation of interest in this article, the GPRFITC model, uses the following conditionals, {fs&#x2223;fi&#x223C;N(ms&#x2212;KsiKii&#x2212;1(fi&#x2212;mi),Qss+diag(Kss&#x2212;Qss))fu&#x2223;fi&#x223C;ExactK=[Qss+diag(Kss&#x2212;Qss)QsuQusKuu]\\displaystyle \\left\\{ \\begin{aligned} {\\mathbf{f}}_s|{\\mathbf{f}}_i &amp;\\sim {\\mathcal{N}}({\\mathbf{m}}_s-{\\mathbf{K}}_{si}{\\mathbf{K}}_{ii}^{-1}({\\mathbf{f}}_i-{\\mathbf{m}}_i), {\\mathbf{Q}}_{ss} + diag({\\mathbf{K}}_{ss}-{\\mathbf{Q}}_{ss})) \\\\ {\\mathbf{f}}_u|{\\mathbf{f}}_i &amp;\\sim Exact \\end{aligned} \\right. \\quad{\\mathbf{K}}= \\begin{bmatrix} {\\mathbf{Q}}_{ss} + diag({\\mathbf{K}}_{ss}-{\\mathbf{Q}}_{ss}) &amp; {\\mathbf{Q}}_{su} \\\\ {\\mathbf{Q}}_{us} &amp; {\\mathbf{K}}_{uu} \\end{bmatrix} {&#x200B;f&#x200B;s&#x200B;&#x200B;&#x2223;f&#x200B;i&#x200B;&#x200B;&#x200B;f&#x200B;u&#x200B;&#x200B;&#x2223;f&#x200B;i&#x200B;&#x200B;&#x200B;&#x200B;&#x200B;&#x223C;N(m&#x200B;s&#x200B;&#x200B;&#x2212;K&#x200B;si&#x200B;&#x200B;K&#x200B;ii&#x200B;&#x2212;1&#x200B;&#x200B;(f&#x200B;i&#x200B;&#x200B;&#x2212;m&#x200B;i&#x200B;&#x200B;),Q&#x200B;ss&#x200B;&#x200B;+diag(K&#x200B;ss&#x200B;&#x200B;&#x2212;Q&#x200B;ss&#x200B;&#x200B;))&#x200B;&#x223C;Exact&#x200B;&#x200B;K=[&#x200B;Q&#x200B;ss&#x200B;&#x200B;+diag(K&#x200B;ss&#x200B;&#x200B;&#x2212;Q&#x200B;ss&#x200B;&#x200B;)&#x200B;Q&#x200B;us&#x200B;&#x200B;&#x200B;&#x200B;&#x200B;Q&#x200B;su&#x200B;&#x200B;&#x200B;K&#x200B;uu&#x200B;&#x200B;&#x200B;&#x200B;] Note that q(fu&#x2223;fi)q({\\mathbf{f}}_u|{\\mathbf{f}}_i)q(f&#x200B;u&#x200B;&#x200B;&#x2223;f&#x200B;i&#x200B;&#x200B;) is exact only when one output is requested. Otherwise, the covariance matrix will be treated like q(fs&#x2223;fi)q({\\mathbf{f}}_s|{\\mathbf{f}}_i)q(f&#x200B;s&#x200B;&#x200B;&#x2223;f&#x200B;i&#x200B;&#x200B;). More on GPRFITC In GPRFITC, the predictive mean becomes, mp=mu&#x2212;Qus(Qss+V)&#x2212;1(ys&#x2212;ms)=mu&#x2212;KuiM&#x2212;1KisV&#x2212;1(ys&#x2212;ms)\\displaystyle \\begin{aligned} {\\mathbf{m}}_p &amp;= {\\mathbf{m}}_u - {\\mathbf{Q}}_{us}({\\mathbf{Q}}_{ss}+{\\mathbf{V}})^{-1}({\\mathbf{y}}_s-{\\mathbf{m}}_s) \\\\ &amp;= {\\mathbf{m}}_u - {\\mathbf{K}}_{ui}{\\mathbf{M}}^{-1}{\\mathbf{K}}_{is}{\\mathbf{V}}^{-1}({\\mathbf{y}}_s-{\\mathbf{m}}_s) \\end{aligned} &#x200B;m&#x200B;p&#x200B;&#x200B;&#x200B;&#x200B;&#x200B;&#x200B;=m&#x200B;u&#x200B;&#x200B;&#x2212;Q&#x200B;us&#x200B;&#x200B;(Q&#x200B;ss&#x200B;&#x200B;+V)&#x200B;&#x2212;1&#x200B;&#x200B;(y&#x200B;s&#x200B;&#x200B;&#x2212;m&#x200B;s&#x200B;&#x200B;)&#x200B;=m&#x200B;u&#x200B;&#x200B;&#x2212;K&#x200B;ui&#x200B;&#x200B;M&#x200B;&#x2212;1&#x200B;&#x200B;K&#x200B;is&#x200B;&#x200B;V&#x200B;&#x2212;1&#x200B;&#x200B;(y&#x200B;s&#x200B;&#x200B;&#x2212;m&#x200B;s&#x200B;&#x200B;)&#x200B;&#x200B; where V=diag(Kss&#x2212;Qss)+&#x3C3;n2I{\\mathbf{V}}=diag({\\mathbf{K}}_{ss}-{\\mathbf{Q}}_{ss})+{\\sigma_n^2}{\\mathbf{I}}V=diag(K&#x200B;ss&#x200B;&#x200B;&#x2212;Q&#x200B;ss&#x200B;&#x200B;)+&#x3C3;&#x200B;n&#x200B;2&#x200B;&#x200B;I, and M=Kii+KisV&#x2212;1Ksi{\\mathbf{M}}={\\mathbf{K}}_{ii}+{\\mathbf{K}}_{is}{\\mathbf{V}}^{-1}{\\mathbf{K}}_{si}M=K&#x200B;ii&#x200B;&#x200B;+K&#x200B;is&#x200B;&#x200B;V&#x200B;&#x2212;1&#x200B;&#x200B;K&#x200B;si&#x200B;&#x200B;. The covariance is, Kp=Kuu&#x2212;Qus(Qss+V)&#x2212;1Qsu=Kuu&#x2212;Quu+KuiM&#x2212;1Kiu\\displaystyle \\begin{aligned} {\\mathbf{K}}_p &amp;= {\\mathbf{K}}_{uu} - {\\mathbf{Q}}_{us}({\\mathbf{Q}}_{ss}+{\\mathbf{V}})^{-1}{\\mathbf{Q}}_{su} \\\\ &amp;= {\\mathbf{K}}_{uu} - {\\mathbf{Q}}_{uu} + {\\mathbf{K}}_{ui}{\\mathbf{M}}^{-1}{\\mathbf{K}}_{iu} \\end{aligned} &#x200B;K&#x200B;p&#x200B;&#x200B;&#x200B;&#x200B;&#x200B;&#x200B;=K&#x200B;uu&#x200B;&#x200B;&#x2212;Q&#x200B;us&#x200B;&#x200B;(Q&#x200B;ss&#x200B;&#x200B;+V)&#x200B;&#x2212;1&#x200B;&#x200B;Q&#x200B;su&#x200B;&#x200B;&#x200B;=K&#x200B;uu&#x200B;&#x200B;&#x2212;Q&#x200B;uu&#x200B;&#x200B;+K&#x200B;ui&#x200B;&#x200B;M&#x200B;&#x2212;1&#x200B;&#x200B;K&#x200B;iu&#x200B;&#x200B;&#x200B;&#x200B; Note that for the computational cost, NNN is reduced to the number of inducing points. There are three matrix inversions involved in the prediction. V{\\mathbf{V}}V is diagonal, and its inversion is trivial. Inversion inside Qss{\\mathbf{Q}}_{ss}Q&#x200B;ss&#x200B;&#x200B; is done using Cholesky decomposition (again), Qss=KsiKii&#x2212;1Kis=Ksi(LiLiT)&#x2212;1Kis&#x2261;K&#xAF;isTK&#xAF;is\\displaystyle \\begin{aligned} {\\mathbf{Q}}_{ss} &amp;= {\\mathbf{K}}_{si}{\\mathbf{K}}_{ii}^{-1}{\\mathbf{K}}_{is} = {\\mathbf{K}}_{si}({\\mathbf{L}}_i{\\mathbf{L}}_i^T)^{-1}{\\mathbf{K}}_{is} \\\\ &amp;\\equiv \\bar{\\mathbf{K}}_{is}^T\\bar{\\mathbf{K}}_{is} \\end{aligned} &#x200B;Q&#x200B;ss&#x200B;&#x200B;&#x200B;&#x200B;&#x200B;&#x200B;=K&#x200B;si&#x200B;&#x200B;K&#x200B;ii&#x200B;&#x2212;1&#x200B;&#x200B;K&#x200B;is&#x200B;&#x200B;=K&#x200B;si&#x200B;&#x200B;(L&#x200B;i&#x200B;&#x200B;L&#x200B;i&#x200B;T&#x200B;&#x200B;)&#x200B;&#x2212;1&#x200B;&#x200B;K&#x200B;is&#x200B;&#x200B;&#x200B;&#x2261;&#x200B;K&#x200B;&#xAF;&#x200B;&#x200B;&#x200B;is&#x200B;T&#x200B;&#x200B;&#x200B;K&#x200B;&#xAF;&#x200B;&#x200B;&#x200B;is&#x200B;&#x200B;&#x200B;&#x200B; where K&#xAF;is=Li&#x2212;1Kis\\bar{\\mathbf{K}}_{is}={\\mathbf{L}}_i^{-1}{\\mathbf{K}}_{is}&#x200B;K&#x200B;&#xAF;&#x200B;&#x200B;&#x200B;is&#x200B;&#x200B;=L&#x200B;i&#x200B;&#x2212;1&#x200B;&#x200B;K&#x200B;is&#x200B;&#x200B;. Subsequently, inversion of M{\\mathbf{M}}M utilizes the decomposition of Kii{\\mathbf{K}}_{ii}K&#x200B;ii&#x200B;&#x200B;, M&#x2212;1=(Kii+KisV&#x2212;1Ksi)&#x2212;1=Li&#x2212;T(I+K&#xAF;isV&#x2212;1K&#xAF;isT)&#x2212;1Li&#x2212;1&#x2261;Li&#x2212;T(LmLmT)&#x2212;1Li&#x2212;1&#x2261;L&#x2212;TL&#x2212;1\\displaystyle \\begin{aligned} {\\mathbf{M}}^{-1} &amp;= ({\\mathbf{K}}_{ii}+{\\mathbf{K}}_{is}{\\mathbf{V}}^{-1}{\\mathbf{K}}_{si})^{-1} = {\\mathbf{L}}_i^{-T} ({\\mathbf{I}}+\\bar{\\mathbf{K}}_{is}{\\mathbf{V}}^{-1}\\bar{\\mathbf{K}}_{is}^T)^{-1} {\\mathbf{L}}_i^{-1} \\\\ &amp;\\equiv {\\mathbf{L}}_i^{-T} ({\\mathbf{L}}_m{\\mathbf{L}}_m^T)^{-1} {\\mathbf{L}}_i^{-1} \\\\ &amp;\\equiv {\\mathbf{L}}^{-T}{\\mathbf{L}}^{-1} \\end{aligned} &#x200B;M&#x200B;&#x2212;1&#x200B;&#x200B;&#x200B;&#x200B;&#x200B;&#x200B;&#x200B;=(K&#x200B;ii&#x200B;&#x200B;+K&#x200B;is&#x200B;&#x200B;V&#x200B;&#x2212;1&#x200B;&#x200B;K&#x200B;si&#x200B;&#x200B;)&#x200B;&#x2212;1&#x200B;&#x200B;=L&#x200B;i&#x200B;&#x2212;T&#x200B;&#x200B;(I+&#x200B;K&#x200B;&#xAF;&#x200B;&#x200B;&#x200B;is&#x200B;&#x200B;V&#x200B;&#x2212;1&#x200B;&#x200B;&#x200B;K&#x200B;&#xAF;&#x200B;&#x200B;&#x200B;is&#x200B;T&#x200B;&#x200B;)&#x200B;&#x2212;1&#x200B;&#x200B;L&#x200B;i&#x200B;&#x2212;1&#x200B;&#x200B;&#x200B;&#x2261;L&#x200B;i&#x200B;&#x2212;T&#x200B;&#x200B;(L&#x200B;m&#x200B;&#x200B;L&#x200B;m&#x200B;T&#x200B;&#x200B;)&#x200B;&#x2212;1&#x200B;&#x200B;L&#x200B;i&#x200B;&#x2212;1&#x200B;&#x200B;&#x200B;&#x2261;L&#x200B;&#x2212;T&#x200B;&#x200B;L&#x200B;&#x2212;1&#x200B;&#x200B;&#x200B;&#x200B; where Cholesky decomposition is applied in the middle. The last two expressions are then used in the computation of mp{\\mathbf{m}}_pm&#x200B;p&#x200B;&#x200B; and Kp{\\mathbf{K}}_pK&#x200B;p&#x200B;&#x200B;. The hyperparameters of GPRFITC can be trained by maximizing the marginal likelihood. &#x2212;2L=(ys&#x2212;ms)T(Qss+V)&#x2212;1(ys&#x2212;ms)+log&#x2223;Qss+V&#x2223;+nlog2&#x3C0;\\displaystyle -2{\\mathcal{L}}= ({\\mathbf{y}}_s-{\\mathbf{m}}_s)^T ({\\mathbf{Q}}_{ss} + {\\mathbf{V}})^{-1} ({\\mathbf{y}}_s-{\\mathbf{m}}_s) + \\log|{\\mathbf{Q}}_{ss} + {\\mathbf{V}}| + n\\log 2\\pi &#x2212;2L=(y&#x200B;s&#x200B;&#x200B;&#x2212;m&#x200B;s&#x200B;&#x200B;)&#x200B;T&#x200B;&#x200B;(Q&#x200B;ss&#x200B;&#x200B;+V)&#x200B;&#x2212;1&#x200B;&#x200B;(y&#x200B;s&#x200B;&#x200B;&#x2212;m&#x200B;s&#x200B;&#x200B;)+log&#x2223;Q&#x200B;ss&#x200B;&#x200B;+V&#x2223;+nlog2&#x3C0; where the matrix inversion is handled as before. For the determinant, log&#x2223;Qss+V&#x2223;=log&#x2223;V&#x2223;&#x2223;I+K&#xAF;isV&#x2212;1K&#xAF;isT&#x2223;=log&#x2223;V&#x2223;+2log&#x2223;Lm&#x2223;\\displaystyle \\begin{aligned} \\log|{\\mathbf{Q}}_{ss} + {\\mathbf{V}}| &amp;= \\log|{\\mathbf{V}}||{\\mathbf{I}}+\\bar{\\mathbf{K}}_{is}{\\mathbf{V}}^{-1}\\bar{\\mathbf{K}}_{is}^T| \\\\ &amp;= \\log|{\\mathbf{V}}| + 2\\log|{\\mathbf{L}}_m| \\end{aligned} &#x200B;log&#x2223;Q&#x200B;ss&#x200B;&#x200B;+V&#x2223;&#x200B;&#x200B;&#x200B;&#x200B;=log&#x2223;V&#x2223;&#x2223;I+&#x200B;K&#x200B;&#xAF;&#x200B;&#x200B;&#x200B;is&#x200B;&#x200B;V&#x200B;&#x2212;1&#x200B;&#x200B;&#x200B;K&#x200B;&#xAF;&#x200B;&#x200B;&#x200B;is&#x200B;T&#x200B;&#x200B;&#x2223;&#x200B;=log&#x2223;V&#x2223;+2log&#x2223;L&#x200B;m&#x200B;&#x200B;&#x2223;&#x200B;&#x200B; The hyperparameters in L{\\mathcal{L}}L include those in regular GPR model: the length scales, process and noise variances, as well as the extra parameters: the location of the inducing points, the number of which is proportional to the input dimension and number of points. Due the large number of hyperparameters, the only viable training approach is the gradient-based method. The gradients of L{\\mathcal{L}}L can be found in Appendix C of Snel2008. Nevertheless, as mentioned before, the gradients are automatically handled in the TensorFlow-based GPflow code. This is the end of this series of articles on GPR, which covers its derivation, computational strategy, determination of hyperparameters, and extension to other variants."},{"title":"Gaussian Process Regressor - Part II","permalink":"http://smanist.github.io/2017/09/26/Gaussian-process-regressor-part-2/","text":"This time let&#x2019;s focus on the hyperparameters. Introduction In the last article, the Gaussian process regression (GPR) model is discussed. Given the training data, it looks like all the coefficients, the predictive mean and the variances, can be determined from those formulations. Well, that is not the whole story. There are some extra coefficients in the covariance function of the Gaussian process that need to be determined, namely the hyperparameters. The determination of the hyperparameters is a little more involved than the formulations in the last article, as this problem is non-convex. Covariance function A covariance function in the Gaussian process takes the form of, k(xi,xj)=&#x3C3;f2R(xi,xj)\\displaystyle k({\\mathbf{x}}_i,{\\mathbf{x}}_j) = {\\sigma_f^2}R({\\mathbf{x}}_i,{\\mathbf{x}}_j) k(x&#x200B;i&#x200B;&#x200B;,x&#x200B;j&#x200B;&#x200B;)=&#x3C3;&#x200B;f&#x200B;2&#x200B;&#x200B;R(x&#x200B;i&#x200B;&#x200B;,x&#x200B;j&#x200B;&#x200B;) where &#x3C3;f2{\\sigma_f^2}&#x3C3;&#x200B;f&#x200B;2&#x200B;&#x200B; is the process variance, and RRR is typically stationary, i.e. R(x,x&#x2032;)=R(x&#x2212;x&#x2032;)R({\\mathbf{x}},{\\mathbf{x}}&apos;)=R({\\mathbf{x}}-{\\mathbf{x}}&apos;)R(x,x&#x200B;&#x2032;&#x200B;&#x200B;)=R(x&#x2212;x&#x200B;&#x2032;&#x200B;&#x200B;), and monotonically decreasing. It is also assumed R(0)=1R(0)=1R(0)=1, meaning that a point correlates with itself the most. When the observation is noisy, the covariance function is modified as, k(xi,xj)=&#x3C3;f2R(xi,xj)+&#x3C3;n2&#x3B4;ij&#x2261;&#x3C3;f2[R(xi,xj)+&#x3C3;~n2&#x3B4;ij]\\displaystyle k({\\mathbf{x}}_i,{\\mathbf{x}}_j) = {\\sigma_f^2}R({\\mathbf{x}}_i,{\\mathbf{x}}_j) + {\\sigma_n^2}\\delta_{ij} \\equiv {\\sigma_f^2}[R({\\mathbf{x}}_i,{\\mathbf{x}}_j) + {\\tilde{\\sigma}_n^2}\\delta_{ij}] k(x&#x200B;i&#x200B;&#x200B;,x&#x200B;j&#x200B;&#x200B;)=&#x3C3;&#x200B;f&#x200B;2&#x200B;&#x200B;R(x&#x200B;i&#x200B;&#x200B;,x&#x200B;j&#x200B;&#x200B;)+&#x3C3;&#x200B;n&#x200B;2&#x200B;&#x200B;&#x3B4;&#x200B;ij&#x200B;&#x200B;&#x2261;&#x3C3;&#x200B;f&#x200B;2&#x200B;&#x200B;[R(x&#x200B;i&#x200B;&#x200B;,x&#x200B;j&#x200B;&#x200B;)+&#x200B;&#x3C3;&#x200B;~&#x200B;&#x200B;&#x200B;n&#x200B;2&#x200B;&#x200B;&#x3B4;&#x200B;ij&#x200B;&#x200B;] A typical choice of RRR is the squared exponential function, R(xi,xj)=exp[&#x2212;(xi&#x2212;xj)TM(xi&#x2212;xj)]\\displaystyle R({\\mathbf{x}}_i,{\\mathbf{x}}_j) = \\exp[-({\\mathbf{x}}_i-{\\mathbf{x}}_j)^T{\\mathbf{M}}({\\mathbf{x}}_i-{\\mathbf{x}}_j)] R(x&#x200B;i&#x200B;&#x200B;,x&#x200B;j&#x200B;&#x200B;)=exp[&#x2212;(x&#x200B;i&#x200B;&#x200B;&#x2212;x&#x200B;j&#x200B;&#x200B;)&#x200B;T&#x200B;&#x200B;M(x&#x200B;i&#x200B;&#x200B;&#x2212;x&#x200B;j&#x200B;&#x200B;)] where in the isotropic case, M=12l2I{\\mathbf{M}}=\\frac{1}{2l^2}{\\mathbf{I}}M=&#x200B;2l&#x200B;2&#x200B;&#x200B;&#x200B;&#x200B;1&#x200B;&#x200B;I meaning that the length scales in all dimensions are the same; while in the anisotropic case, M=12diag(l)&#x2212;2{\\mathbf{M}}={\\frac{1}{2}}diag({\\mathbf{l}})^{-2}M=&#x200B;2&#x200B;&#x200B;1&#x200B;&#x200B;diag(l)&#x200B;&#x2212;2&#x200B;&#x200B; is a diagonal matrix with positive diagonal entries, representing the length scales in different dimensions. In both cases, the length scales have to be figured out from the training data. The latter case is sometimes also called automatic relevance determination (ARD), meaning that the training process automatically determines if the particular dimension has a significant influence on the output. See the DACE manual for more discussion. The length scales l{\\mathbf{l}}l and the variances &#x3C3;f2{\\sigma_f^2}&#x3C3;&#x200B;f&#x200B;2&#x200B;&#x200B; and &#x3C3;n2{\\sigma_n^2}&#x3C3;&#x200B;n&#x200B;2&#x200B;&#x200B; are the hyperparameters to be determined in the training process. In the general sense, the coefficients for the basis functions b&#xAF;\\bar{\\mathbf{b}}&#x200B;b&#x200B;&#xAF;&#x200B;&#x200B; are hyperparameters too. Non-dimensionalization Before proceeding to the training process, it is beneficial to non-dimensionalize some quantities in the GPR model. First, the covariance matrices Ky{\\mathbf{K}}_yK&#x200B;y&#x200B;&#x200B; and Ksu{\\mathbf{K}}_{su}K&#x200B;su&#x200B;&#x200B; can be &#x201C;non-dimensionalized&#x201D; by &#x3C3;f2{\\sigma_f^2}&#x3C3;&#x200B;f&#x200B;2&#x200B;&#x200B;, Ky&#x2261;&#x3C3;f2K~y&#x2261;&#x3C3;f2(K~ss+&#x3C3;~n2I)Ksu&#x2261;&#x3C3;f2K~su\\displaystyle \\begin{aligned} {\\mathbf{K}}_y &amp;\\equiv {\\sigma_f^2}{\\tilde{\\mathbf{K}}}_y \\equiv {\\sigma_f^2}({\\tilde{\\mathbf{K}}}_{ss} + {\\tilde{\\sigma}_n^2}{\\mathbf{I}}) \\\\ {\\mathbf{K}}_{su} &amp;\\equiv {\\sigma_f^2}{\\tilde{\\mathbf{K}}}_{su} \\end{aligned} &#x200B;K&#x200B;y&#x200B;&#x200B;&#x200B;K&#x200B;su&#x200B;&#x200B;&#x200B;&#x200B;&#x200B;&#x2261;&#x3C3;&#x200B;f&#x200B;2&#x200B;&#x200B;&#x200B;K&#x200B;~&#x200B;&#x200B;&#x200B;y&#x200B;&#x200B;&#x2261;&#x3C3;&#x200B;f&#x200B;2&#x200B;&#x200B;(&#x200B;K&#x200B;~&#x200B;&#x200B;&#x200B;ss&#x200B;&#x200B;+&#x200B;&#x3C3;&#x200B;~&#x200B;&#x200B;&#x200B;n&#x200B;2&#x200B;&#x200B;I)&#x200B;&#x2261;&#x3C3;&#x200B;f&#x200B;2&#x200B;&#x200B;&#x200B;K&#x200B;~&#x200B;&#x200B;&#x200B;su&#x200B;&#x200B;&#x200B;&#x200B; Subsequently, examine the effect of &#x3C3;f2{\\sigma_f^2}&#x3C3;&#x200B;f&#x200B;2&#x200B;&#x200B; on the predictive mean, mp&#x2217;=KsuTg&#xAF;+HuTb&#xAF;=K~suTg~+HuTb~\\displaystyle {\\mathbf{m}}_p^* = {\\mathbf{K}}_{su}^T\\bar{\\mathbf{g}}+ {\\mathbf{H}}_u^T\\bar{\\mathbf{b}}= {\\tilde{\\mathbf{K}}}_{su}^T{\\tilde{\\mathbf{g}}}+ {\\mathbf{H}}_u^T{\\tilde{\\mathbf{b}}}m&#x200B;p&#x200B;&#x2217;&#x200B;&#x200B;=K&#x200B;su&#x200B;T&#x200B;&#x200B;&#x200B;g&#x200B;&#xAF;&#x200B;&#x200B;+H&#x200B;u&#x200B;T&#x200B;&#x200B;&#x200B;b&#x200B;&#xAF;&#x200B;&#x200B;=&#x200B;K&#x200B;~&#x200B;&#x200B;&#x200B;su&#x200B;T&#x200B;&#x200B;&#x200B;g&#x200B;~&#x200B;&#x200B;+H&#x200B;u&#x200B;T&#x200B;&#x200B;&#x200B;b&#x200B;~&#x200B;&#x200B; where, b&#xAF;=(HTKy&#x2212;1H)&#x2212;1HTKy&#x2212;1ys=(HTK~y&#x2212;1H)&#x2212;1HTK~y&#x2212;1ys&#x2261;b~g&#xAF;=Ky&#x2212;1(ys&#x2212;Hb&#xAF;)=&#x3C3;f&#x2212;2K~y&#x2212;1(ys&#x2212;Hb~)\\displaystyle \\begin{aligned} \\bar{\\mathbf{b}}&amp;= ({\\mathbf{H}}^T{\\mathbf{K}_y^{-1}}{\\mathbf{H}})^{-1}{\\mathbf{H}}^T{\\mathbf{K}_y^{-1}}{\\mathbf{y}}_s = ({\\mathbf{H}}^T{\\tilde{\\mathbf{K}}_y^{-1}}{\\mathbf{H}})^{-1}{\\mathbf{H}}^T{\\tilde{\\mathbf{K}}_y^{-1}}{\\mathbf{y}}_s \\equiv {\\tilde{\\mathbf{b}}}\\\\ \\bar{\\mathbf{g}}&amp;= {\\mathbf{K}_y^{-1}}({\\mathbf{y}}_s-{\\mathbf{H}}\\bar{\\mathbf{b}}) = \\sigma_f^{-2} {\\tilde{\\mathbf{K}}_y^{-1}}({\\mathbf{y}}_s-{\\mathbf{H}}{\\tilde{\\mathbf{b}}}) \\end{aligned} &#x200B;&#x200B;b&#x200B;&#xAF;&#x200B;&#x200B;&#x200B;&#x200B;g&#x200B;&#xAF;&#x200B;&#x200B;&#x200B;&#x200B;&#x200B;=(H&#x200B;T&#x200B;&#x200B;K&#x200B;y&#x200B;&#x2212;1&#x200B;&#x200B;H)&#x200B;&#x2212;1&#x200B;&#x200B;H&#x200B;T&#x200B;&#x200B;K&#x200B;y&#x200B;&#x2212;1&#x200B;&#x200B;y&#x200B;s&#x200B;&#x200B;=(H&#x200B;T&#x200B;&#x200B;&#x200B;K&#x200B;~&#x200B;&#x200B;&#x200B;y&#x200B;&#x2212;1&#x200B;&#x200B;H)&#x200B;&#x2212;1&#x200B;&#x200B;H&#x200B;T&#x200B;&#x200B;&#x200B;K&#x200B;~&#x200B;&#x200B;&#x200B;y&#x200B;&#x2212;1&#x200B;&#x200B;y&#x200B;s&#x200B;&#x200B;&#x2261;&#x200B;b&#x200B;~&#x200B;&#x200B;&#x200B;=K&#x200B;y&#x200B;&#x2212;1&#x200B;&#x200B;(y&#x200B;s&#x200B;&#x200B;&#x2212;H&#x200B;b&#x200B;&#xAF;&#x200B;&#x200B;)=&#x3C3;&#x200B;f&#x200B;&#x2212;2&#x200B;&#x200B;&#x200B;K&#x200B;~&#x200B;&#x200B;&#x200B;y&#x200B;&#x2212;1&#x200B;&#x200B;(y&#x200B;s&#x200B;&#x200B;&#x2212;H&#x200B;b&#x200B;~&#x200B;&#x200B;)&#x200B;&#x200B; And the covariance, Kp&#x2217;=Kuu&#x2212;KusKy&#x2212;1Ksu+DT(HTKy&#x2212;1H)&#x2212;1D=&#x3C3;f2[K~uu&#x2212;K~usK~y&#x2212;1K~su+D~T(HTK~y&#x2212;1H)&#x2212;1D~]\\displaystyle \\begin{aligned} {\\mathbf{K}}_p^* &amp;= {\\mathbf{K}}_{uu} - {\\mathbf{K}}_{us}{\\mathbf{K}}_y^{-1}{\\mathbf{K}}_{su} + {\\mathbf{D}}^T ({\\mathbf{H}}^T{\\mathbf{K}_y^{-1}}{\\mathbf{H}})^{-1} {\\mathbf{D}}\\\\ &amp;= {\\sigma_f^2}[{\\tilde{\\mathbf{K}}}_{uu} - {\\tilde{\\mathbf{K}}}_{us}{\\tilde{\\mathbf{K}}_y^{-1}}{\\tilde{\\mathbf{K}}}_{su} + {\\tilde{\\mathbf{D}}}^T ({\\mathbf{H}}^T{\\tilde{\\mathbf{K}}_y^{-1}}{\\mathbf{H}})^{-1} {\\tilde{\\mathbf{D}}}] \\end{aligned} &#x200B;K&#x200B;p&#x200B;&#x2217;&#x200B;&#x200B;&#x200B;&#x200B;&#x200B;&#x200B;=K&#x200B;uu&#x200B;&#x200B;&#x2212;K&#x200B;us&#x200B;&#x200B;K&#x200B;y&#x200B;&#x2212;1&#x200B;&#x200B;K&#x200B;su&#x200B;&#x200B;+D&#x200B;T&#x200B;&#x200B;(H&#x200B;T&#x200B;&#x200B;K&#x200B;y&#x200B;&#x2212;1&#x200B;&#x200B;H)&#x200B;&#x2212;1&#x200B;&#x200B;D&#x200B;=&#x3C3;&#x200B;f&#x200B;2&#x200B;&#x200B;[&#x200B;K&#x200B;~&#x200B;&#x200B;&#x200B;uu&#x200B;&#x200B;&#x2212;&#x200B;K&#x200B;~&#x200B;&#x200B;&#x200B;us&#x200B;&#x200B;&#x200B;K&#x200B;~&#x200B;&#x200B;&#x200B;y&#x200B;&#x2212;1&#x200B;&#x200B;&#x200B;K&#x200B;~&#x200B;&#x200B;&#x200B;su&#x200B;&#x200B;+&#x200B;D&#x200B;~&#x200B;&#x200B;&#x200B;T&#x200B;&#x200B;(H&#x200B;T&#x200B;&#x200B;&#x200B;K&#x200B;~&#x200B;&#x200B;&#x200B;y&#x200B;&#x2212;1&#x200B;&#x200B;H)&#x200B;&#x2212;1&#x200B;&#x200B;&#x200B;D&#x200B;~&#x200B;&#x200B;]&#x200B;&#x200B; where, D=HuT&#x2212;HTKy&#x2212;1Ksu=HuT&#x2212;HTK~y&#x2212;1K~su&#x2261;D~\\displaystyle {\\mathbf{D}}= {\\mathbf{H}}_u^T-{\\mathbf{H}}^T {\\mathbf{K}_y^{-1}}{\\mathbf{K}}_{su} = {\\mathbf{H}}_u^T-{\\mathbf{H}}^T {\\tilde{\\mathbf{K}}_y^{-1}}{\\tilde{\\mathbf{K}}}_{su} \\equiv {\\tilde{\\mathbf{D}}}D=H&#x200B;u&#x200B;T&#x200B;&#x200B;&#x2212;H&#x200B;T&#x200B;&#x200B;K&#x200B;y&#x200B;&#x2212;1&#x200B;&#x200B;K&#x200B;su&#x200B;&#x200B;=H&#x200B;u&#x200B;T&#x200B;&#x200B;&#x2212;H&#x200B;T&#x200B;&#x200B;&#x200B;K&#x200B;~&#x200B;&#x200B;&#x200B;y&#x200B;&#x2212;1&#x200B;&#x200B;&#x200B;K&#x200B;~&#x200B;&#x200B;&#x200B;su&#x200B;&#x200B;&#x2261;&#x200B;D&#x200B;~&#x200B;&#x200B; In sum, &#x3C3;f2{\\sigma_f^2}&#x3C3;&#x200B;f&#x200B;2&#x200B;&#x200B; has no direct effect on the mean, but the covariance is proportional to &#x3C3;f2{\\sigma_f^2}&#x3C3;&#x200B;f&#x200B;2&#x200B;&#x200B;, once the hyperparameters are given. The question is, how to obtain the hyperparameters? Learning the hyperparameters Log-likelihood The hyperparameters are determined using the maximum likelihood estimation (MLE). With the joint Gaussian distribution, the log marginal likelihood of the training data is, L=logp(ys&#x2223;Xs,b,B)=&#x2212;12(ys&#x2212;Hb)T(Ky+HTBH)&#x2212;1(ys&#x2212;Hb)&#x2212;12log&#x2223;Ky+HTBH&#x2223;&#x2212;n2log2&#x3C0;\\displaystyle \\begin{aligned} {\\mathcal{L}}&amp;= \\log p({\\mathbf{y}}_s|{\\mathbf{X}}_s,{\\mathbf{b}},{\\mathbf{B}}) \\\\ &amp;= - {\\frac{1}{2}}({\\mathbf{y}}_s-{\\mathbf{H}}{\\mathbf{b}})^T ({\\mathbf{K}}_y+{\\mathbf{H}}^T{\\mathbf{B}}{\\mathbf{H}})^{-1} ({\\mathbf{y}}_s-{\\mathbf{H}}{\\mathbf{b}}) - {\\frac{1}{2}}\\log |{\\mathbf{K}}_y+{\\mathbf{H}}^T{\\mathbf{B}}{\\mathbf{H}}| - \\frac{n}{2}\\log 2\\pi \\end{aligned} &#x200B;L&#x200B;&#x200B;&#x200B;&#x200B;=logp(y&#x200B;s&#x200B;&#x200B;&#x2223;X&#x200B;s&#x200B;&#x200B;,b,B)&#x200B;=&#x2212;&#x200B;2&#x200B;&#x200B;1&#x200B;&#x200B;(y&#x200B;s&#x200B;&#x200B;&#x2212;Hb)&#x200B;T&#x200B;&#x200B;(K&#x200B;y&#x200B;&#x200B;+H&#x200B;T&#x200B;&#x200B;BH)&#x200B;&#x2212;1&#x200B;&#x200B;(y&#x200B;s&#x200B;&#x200B;&#x2212;Hb)&#x2212;&#x200B;2&#x200B;&#x200B;1&#x200B;&#x200B;log&#x2223;K&#x200B;y&#x200B;&#x200B;+H&#x200B;T&#x200B;&#x200B;BH&#x2223;&#x2212;&#x200B;2&#x200B;&#x200B;n&#x200B;&#x200B;log2&#x3C0;&#x200B;&#x200B; where nnn is number of training data points. Utilizing the determinant counterpart of matrix inversion lemma, &#x2223;A+UCVT&#x2223;=&#x2223;A&#x2223;&#x2223;C&#x2223;&#x2223;C&#x2212;1+VTA&#x2212;1U&#x2223;\\displaystyle |{\\mathbf{A}}+{\\mathbf{U}}{\\mathbf{C}}{\\mathbf{V}}^T| = |{\\mathbf{A}}| |{\\mathbf{C}}| |{\\mathbf{C}}^{-1} + {\\mathbf{V}}^T{\\mathbf{A}}^{-1}{\\mathbf{U}}| &#x2223;A+UCV&#x200B;T&#x200B;&#x200B;&#x2223;=&#x2223;A&#x2223;&#x2223;C&#x2223;&#x2223;C&#x200B;&#x2212;1&#x200B;&#x200B;+V&#x200B;T&#x200B;&#x200B;A&#x200B;&#x2212;1&#x200B;&#x200B;U&#x2223; and let b=0{\\mathbf{b}}=0b=0 and B&#x2212;1&#x2192;O{\\mathbf{B}}^{-1}\\rightarrow{\\mathbf{O}}B&#x200B;&#x2212;1&#x200B;&#x200B;&#x2192;O as was done last time, &#x2212;2L=ysT[Ky&#x2212;1&#x2212;Ky&#x2212;1H(HTKy&#x2212;1H)&#x2212;1HTKy&#x2212;1]ys+log&#x2223;Ky&#x2223;+log&#x2223;HTKy&#x2212;1H&#x2223;+(n&#x2212;m)log2&#x3C0;\\displaystyle -2{\\mathcal{L}}= {\\mathbf{y}}_s^T [{\\mathbf{K}_y^{-1}}- {\\mathbf{K}_y^{-1}}{\\mathbf{H}}({\\mathbf{H}}^T{\\mathbf{K}_y^{-1}}{\\mathbf{H}})^{-1} {\\mathbf{H}}^T {\\mathbf{K}_y^{-1}}] {\\mathbf{y}}_s + \\log|{\\mathbf{K}}_y| + \\log|{\\mathbf{H}}^T{\\mathbf{K}_y^{-1}}{\\mathbf{H}}| + (n-m)\\log 2\\pi &#x2212;2L=y&#x200B;s&#x200B;T&#x200B;&#x200B;[K&#x200B;y&#x200B;&#x2212;1&#x200B;&#x200B;&#x2212;K&#x200B;y&#x200B;&#x2212;1&#x200B;&#x200B;H(H&#x200B;T&#x200B;&#x200B;K&#x200B;y&#x200B;&#x2212;1&#x200B;&#x200B;H)&#x200B;&#x2212;1&#x200B;&#x200B;H&#x200B;T&#x200B;&#x200B;K&#x200B;y&#x200B;&#x2212;1&#x200B;&#x200B;]y&#x200B;s&#x200B;&#x200B;+log&#x2223;K&#x200B;y&#x200B;&#x200B;&#x2223;+log&#x2223;H&#x200B;T&#x200B;&#x200B;K&#x200B;y&#x200B;&#x2212;1&#x200B;&#x200B;H&#x2223;+(n&#x2212;m)log2&#x3C0; where mmm is number of basis functions, and was introduced due to the singularity caused by &#x2223;B&#x2223;|{\\mathbf{B}}|&#x2223;B&#x2223;. An interesting simplification can be done to the first term in the above expression, I1=ysT[Ky&#x2212;1&#x2212;Ky&#x2212;1H(HTKy&#x2212;1H)&#x2212;1HTKy&#x2212;1]ys=ysTKy&#x2212;1(ys&#x2212;Hb&#xAF;)&#x2261;I2I1=(ys&#x2212;Hb&#xAF;)TKy&#x2212;1ys&#x2261;I3I1=ysTKy&#x2212;1ys&#x2212;b&#xAF;THTKy&#x2212;1Hb&#xAF;&#x2261;I4I1=I2+I3&#x2212;I4=(ys&#x2212;Hb&#xAF;)TKy&#x2212;1(ys&#x2212;Hb&#xAF;)\\displaystyle \\begin{aligned} I_1 &amp;= {\\mathbf{y}}_s^T [{\\mathbf{K}_y^{-1}}- {\\mathbf{K}_y^{-1}}{\\mathbf{H}}({\\mathbf{H}}^T{\\mathbf{K}_y^{-1}}{\\mathbf{H}})^{-1} {\\mathbf{H}}^T {\\mathbf{K}_y^{-1}}] {\\mathbf{y}}_s \\\\ &amp;= {\\mathbf{y}}_s^T {\\mathbf{K}_y^{-1}}({\\mathbf{y}}_s - {\\mathbf{H}}\\bar{\\mathbf{b}}) \\equiv I_2 \\\\ I_1 &amp;= ({\\mathbf{y}}_s - {\\mathbf{H}}\\bar{\\mathbf{b}})^T {\\mathbf{K}_y^{-1}}{\\mathbf{y}}_s \\equiv I_3 \\\\ I_1 &amp;= {\\mathbf{y}}_s^T {\\mathbf{K}_y^{-1}}{\\mathbf{y}}_s - \\bar{\\mathbf{b}}^T{\\mathbf{H}}^T {\\mathbf{K}_y^{-1}}{\\mathbf{H}}\\bar{\\mathbf{b}}\\equiv I_4 \\\\ I_1 &amp;= I_2+I_3-I_4 = ({\\mathbf{y}}_s - {\\mathbf{H}}\\bar{\\mathbf{b}})^T {\\mathbf{K}_y^{-1}}({\\mathbf{y}}_s - {\\mathbf{H}}\\bar{\\mathbf{b}}) \\end{aligned} &#x200B;I&#x200B;1&#x200B;&#x200B;&#x200B;&#x200B;I&#x200B;1&#x200B;&#x200B;&#x200B;I&#x200B;1&#x200B;&#x200B;&#x200B;I&#x200B;1&#x200B;&#x200B;&#x200B;&#x200B;&#x200B;=y&#x200B;s&#x200B;T&#x200B;&#x200B;[K&#x200B;y&#x200B;&#x2212;1&#x200B;&#x200B;&#x2212;K&#x200B;y&#x200B;&#x2212;1&#x200B;&#x200B;H(H&#x200B;T&#x200B;&#x200B;K&#x200B;y&#x200B;&#x2212;1&#x200B;&#x200B;H)&#x200B;&#x2212;1&#x200B;&#x200B;H&#x200B;T&#x200B;&#x200B;K&#x200B;y&#x200B;&#x2212;1&#x200B;&#x200B;]y&#x200B;s&#x200B;&#x200B;&#x200B;=y&#x200B;s&#x200B;T&#x200B;&#x200B;K&#x200B;y&#x200B;&#x2212;1&#x200B;&#x200B;(y&#x200B;s&#x200B;&#x200B;&#x2212;H&#x200B;b&#x200B;&#xAF;&#x200B;&#x200B;)&#x2261;I&#x200B;2&#x200B;&#x200B;&#x200B;=(y&#x200B;s&#x200B;&#x200B;&#x2212;H&#x200B;b&#x200B;&#xAF;&#x200B;&#x200B;)&#x200B;T&#x200B;&#x200B;K&#x200B;y&#x200B;&#x2212;1&#x200B;&#x200B;y&#x200B;s&#x200B;&#x200B;&#x2261;I&#x200B;3&#x200B;&#x200B;&#x200B;=y&#x200B;s&#x200B;T&#x200B;&#x200B;K&#x200B;y&#x200B;&#x2212;1&#x200B;&#x200B;y&#x200B;s&#x200B;&#x200B;&#x2212;&#x200B;b&#x200B;&#xAF;&#x200B;&#x200B;&#x200B;T&#x200B;&#x200B;H&#x200B;T&#x200B;&#x200B;K&#x200B;y&#x200B;&#x2212;1&#x200B;&#x200B;H&#x200B;b&#x200B;&#xAF;&#x200B;&#x200B;&#x2261;I&#x200B;4&#x200B;&#x200B;&#x200B;=I&#x200B;2&#x200B;&#x200B;+I&#x200B;3&#x200B;&#x200B;&#x2212;I&#x200B;4&#x200B;&#x200B;=(y&#x200B;s&#x200B;&#x200B;&#x2212;H&#x200B;b&#x200B;&#xAF;&#x200B;&#x200B;)&#x200B;T&#x200B;&#x200B;K&#x200B;y&#x200B;&#x2212;1&#x200B;&#x200B;(y&#x200B;s&#x200B;&#x200B;&#x2212;H&#x200B;b&#x200B;&#xAF;&#x200B;&#x200B;)&#x200B;&#x200B; Indicating that the term I1I_1I&#x200B;1&#x200B;&#x200B; behaves as if it is centered at Hb&#xAF;{\\mathbf{H}}\\bar{\\mathbf{b}}H&#x200B;b&#x200B;&#xAF;&#x200B;&#x200B;, with a covariance matrix Ky{\\mathbf{K}}_yK&#x200B;y&#x200B;&#x200B;. Furthermore, factor L{\\mathcal{L}}L with &#x3C3;f2{\\sigma_f^2}&#x3C3;&#x200B;f&#x200B;2&#x200B;&#x200B;, &#x2212;2L~1=&#x3C3;f&#x2212;2(ys&#x2212;Hb~)TK~y&#x2212;1(ys&#x2212;Hb~)+log&#x2223;K~y&#x2223;+log&#x2223;HTK~y&#x2212;1H&#x2223;+(n&#x2212;m)log&#x3C3;f2\\displaystyle -2{\\tilde{\\mathcal{L}}}_1 = \\sigma_f^{-2} ({\\mathbf{y}}_s - {\\mathbf{H}}{\\tilde{\\mathbf{b}}})^T {\\tilde{\\mathbf{K}}_y^{-1}}({\\mathbf{y}}_s - {\\mathbf{H}}{\\tilde{\\mathbf{b}}}) + \\log|{\\tilde{\\mathbf{K}}}_y| + \\log|{\\mathbf{H}}^T{\\tilde{\\mathbf{K}}_y^{-1}}{\\mathbf{H}}| + (n-m)\\log{\\sigma_f^2}&#x2212;2&#x200B;L&#x200B;~&#x200B;&#x200B;&#x200B;1&#x200B;&#x200B;=&#x3C3;&#x200B;f&#x200B;&#x2212;2&#x200B;&#x200B;(y&#x200B;s&#x200B;&#x200B;&#x2212;H&#x200B;b&#x200B;~&#x200B;&#x200B;)&#x200B;T&#x200B;&#x200B;&#x200B;K&#x200B;~&#x200B;&#x200B;&#x200B;y&#x200B;&#x2212;1&#x200B;&#x200B;(y&#x200B;s&#x200B;&#x200B;&#x2212;H&#x200B;b&#x200B;~&#x200B;&#x200B;)+log&#x2223;&#x200B;K&#x200B;~&#x200B;&#x200B;&#x200B;y&#x200B;&#x200B;&#x2223;+log&#x2223;H&#x200B;T&#x200B;&#x200B;&#x200B;K&#x200B;~&#x200B;&#x200B;&#x200B;y&#x200B;&#x2212;1&#x200B;&#x200B;H&#x2223;+(n&#x2212;m)log&#x3C3;&#x200B;f&#x200B;2&#x200B;&#x200B; where the constant term is neglected. If the prior on the coefficients of the basis functions is ignored, the log-likelihood would be simplified to, &#x2212;2L~2=&#x3C3;f&#x2212;2(ys&#x2212;Hb~)TK~y&#x2212;1(ys&#x2212;Hb~)+log&#x2223;K~y&#x2223;+nlog&#x3C3;f2\\displaystyle -2{\\tilde{\\mathcal{L}}}_2 = \\sigma_f^{-2} ({\\mathbf{y}}_s - {\\mathbf{H}}{\\tilde{\\mathbf{b}}})^T {\\tilde{\\mathbf{K}}_y^{-1}}({\\mathbf{y}}_s - {\\mathbf{H}}{\\tilde{\\mathbf{b}}}) + \\log|{\\tilde{\\mathbf{K}}}_y| + n\\log{\\sigma_f^2}&#x2212;2&#x200B;L&#x200B;~&#x200B;&#x200B;&#x200B;2&#x200B;&#x200B;=&#x3C3;&#x200B;f&#x200B;&#x2212;2&#x200B;&#x200B;(y&#x200B;s&#x200B;&#x200B;&#x2212;H&#x200B;b&#x200B;~&#x200B;&#x200B;)&#x200B;T&#x200B;&#x200B;&#x200B;K&#x200B;~&#x200B;&#x200B;&#x200B;y&#x200B;&#x2212;1&#x200B;&#x200B;(y&#x200B;s&#x200B;&#x200B;&#x2212;H&#x200B;b&#x200B;~&#x200B;&#x200B;)+log&#x2223;&#x200B;K&#x200B;~&#x200B;&#x200B;&#x200B;y&#x200B;&#x200B;&#x2223;+nlog&#x3C3;&#x200B;f&#x200B;2&#x200B;&#x200B; Process variances A natural step next would be finding &#x3C3;f2{\\sigma_f^2}&#x3C3;&#x200B;f&#x200B;2&#x200B;&#x200B; by setting &#x2202;(&#x2212;2L~)/&#x2202;&#x3C3;f2=0\\partial(-2{\\tilde{\\mathcal{L}}})/\\partial{\\sigma_f^2}=0&#x2202;(&#x2212;2&#x200B;L&#x200B;~&#x200B;&#x200B;)/&#x2202;&#x3C3;&#x200B;f&#x200B;2&#x200B;&#x200B;=0 and solving for &#x3C3;f2{\\sigma_f^2}&#x3C3;&#x200B;f&#x200B;2&#x200B;&#x200B;, &#x3C3;f2=1N(ys&#x2212;Hb~)TK~y&#x2212;1(ys&#x2212;Hb~)\\displaystyle {\\sigma_f^2}= \\frac{1}{N}({\\mathbf{y}}_s - {\\mathbf{H}}{\\tilde{\\mathbf{b}}})^T {\\tilde{\\mathbf{K}}_y^{-1}}({\\mathbf{y}}_s - {\\mathbf{H}}{\\tilde{\\mathbf{b}}}) &#x3C3;&#x200B;f&#x200B;2&#x200B;&#x200B;=&#x200B;N&#x200B;&#x200B;1&#x200B;&#x200B;(y&#x200B;s&#x200B;&#x200B;&#x2212;H&#x200B;b&#x200B;~&#x200B;&#x200B;)&#x200B;T&#x200B;&#x200B;&#x200B;K&#x200B;~&#x200B;&#x200B;&#x200B;y&#x200B;&#x2212;1&#x200B;&#x200B;(y&#x200B;s&#x200B;&#x200B;&#x2212;H&#x200B;b&#x200B;~&#x200B;&#x200B;) where N=n&#x2212;mN=n-mN=n&#x2212;m for L~1{\\tilde{\\mathcal{L}}}_1&#x200B;L&#x200B;~&#x200B;&#x200B;&#x200B;1&#x200B;&#x200B;, and N=nN=nN=n for L~2{\\tilde{\\mathcal{L}}}_2&#x200B;L&#x200B;~&#x200B;&#x200B;&#x200B;2&#x200B;&#x200B;. The former case is the center estimate of the variance, while the latter the MLE. When there are multiple outputs, the output variables are usually assumed to be independent, and &#x3C3;f2{\\sigma_f^2}&#x3C3;&#x200B;f&#x200B;2&#x200B;&#x200B; can be computed separately for each output. Plug the value back to the likelihood, and remove the constant terms [Welch1992], one obtains reduced log likelihood, &#x2212;F1=log&#x2223;K~y&#x2223;+log&#x2223;HTK~y&#x2212;1H&#x2223;+(n&#x2212;m)log&#x3C3;f2&#x2212;F2=log&#x2223;K~y&#x2223;+nlog&#x3C3;f2\\displaystyle \\begin{aligned} -{\\mathcal{F}}_1 &amp;= \\log|{\\tilde{\\mathbf{K}}}_y| + \\log|{\\mathbf{H}}^T{\\tilde{\\mathbf{K}}_y^{-1}}{\\mathbf{H}}| + (n-m)\\log{\\sigma_f^2}\\\\ -{\\mathcal{F}}_2 &amp;= \\log|{\\tilde{\\mathbf{K}}}_y| + n\\log{\\sigma_f^2}\\end{aligned} &#x200B;&#x2212;F&#x200B;1&#x200B;&#x200B;&#x200B;&#x2212;F&#x200B;2&#x200B;&#x200B;&#x200B;&#x200B;&#x200B;=log&#x2223;&#x200B;K&#x200B;~&#x200B;&#x200B;&#x200B;y&#x200B;&#x200B;&#x2223;+log&#x2223;H&#x200B;T&#x200B;&#x200B;&#x200B;K&#x200B;~&#x200B;&#x200B;&#x200B;y&#x200B;&#x2212;1&#x200B;&#x200B;H&#x2223;+(n&#x2212;m)log&#x3C3;&#x200B;f&#x200B;2&#x200B;&#x200B;&#x200B;=log&#x2223;&#x200B;K&#x200B;~&#x200B;&#x200B;&#x200B;y&#x200B;&#x200B;&#x2223;+nlog&#x3C3;&#x200B;f&#x200B;2&#x200B;&#x200B;&#x200B;&#x200B; where the only remaining unknown hyperparameters are the length scales l{\\mathbf{l}}l. Note that F2{\\mathcal{F}}_2F&#x200B;2&#x200B;&#x200B; should be used if a general mean function, without priors on its coefficients, is employed. Finding the hyperparameters There appears to be two strategies for determining the hyperparameters, the two-step and the one-step methods. The two-step method utilizes the reduced log likelihood. This is the method used in the DACE toolbox and its Python translation in sklearn. The hyperparameters are divided into two groups: (1) length scales l{\\mathbf{l}}l, (2) variances &#x3C3;f2{\\sigma_f^2}&#x3C3;&#x200B;f&#x200B;2&#x200B;&#x200B; and &#x3C3;n2{\\sigma_n^2}&#x3C3;&#x200B;n&#x200B;2&#x200B;&#x200B;. The primary unknown is l{\\mathbf{l}}l, &#x3C3;f2{\\sigma_f^2}&#x3C3;&#x200B;f&#x200B;2&#x200B;&#x200B; is a function of l{\\mathbf{l}}l, and &#x3C3;n2{\\sigma_n^2}&#x3C3;&#x200B;n&#x200B;2&#x200B;&#x200B; is externally set, mainly as a device for numerical stability (namely the &#x201C;nugget&#x201D;). The objective function is F2{\\mathcal{F}}_2F&#x200B;2&#x200B;&#x200B;. In the multi-output case, F{\\mathcal{F}}F for each output is computed using the same set of l{\\mathbf{l}}l, and summed up as the final objective function. The one-step method tries to determine all hyperparameters, even including b&#xAF;\\bar{\\mathbf{b}}&#x200B;b&#x200B;&#xAF;&#x200B;&#x200B;, using gradient-based method. The difficulties are the efficiency of gradient-based method for the many variables and the implementation of the gradients. The first item is not a major issue with the developments in modern computational science. The second item could be indeed troublesome. But that is where the elegance of GPflow is revealed. It is based on TensorFlow, and TF handles the gradients efficiently with the computation graph model. In GPflow, one can focus on the objective functions. In its GPR implementation, L~2{\\tilde{\\mathcal{L}}}_2&#x200B;L&#x200B;~&#x200B;&#x200B;&#x200B;2&#x200B;&#x200B; is employed. A limitation is that, in the multi-output case, all the outputs have to use the same &#x3C3;f2{\\sigma_f^2}&#x3C3;&#x200B;f&#x200B;2&#x200B;&#x200B;. A remedy is to add a wrapper to its GPR class, and compute the MLE&#x2019;s of &#x3C3;f2{\\sigma_f^2}&#x3C3;&#x200B;f&#x200B;2&#x200B;&#x200B; for each output. In the newer version of GPR in sklearn, the gradient of F2{\\mathcal{F}}_2F&#x200B;2&#x200B;&#x200B; w.r.t. l{\\mathbf{l}}l is introduced, and gradient-based optimization methods like L-BFGS-B are employed. However, in the new implementation, the mean function is hardcoded to be zero, meaning that F1=F2{\\mathcal{F}}_1={\\mathcal{F}}_2F&#x200B;1&#x200B;&#x200B;=F&#x200B;2&#x200B;&#x200B;. Furthermore, the variance &#x3C3;f2{\\sigma_f^2}&#x3C3;&#x200B;f&#x200B;2&#x200B;&#x200B; is fixed to be one, probably for easier computation of the gradients. This version essentially rules out the second group of the hyperparameters and determines the first group using gradient-based method. Therefore, the approach in this version is closer to the one-step method. The GPy implementation will not be discussed here, as I am not familiar with it."},{"title":"Gaussian Process Regressor - Part I","permalink":"http://smanist.github.io/2017/09/22/Gaussian-process-regressor-part-1/","text":"This time let&#x2019;s talk about a non-parametric model. Introduction A non-parametric model uses all the training data to do predictions. In contrast, a parametric model obtains its &#x201C;parameters&#x201D; from the training data before prediction, and only uses those parameters for prediction. The non-parametric model based on Gaussian process (GPR) has been around for quite a while. It has deep connections to methods such as radial basis function network (RBFN). In geostatistics, and later in the field of engineering, the method is called kriging. The GPR with explicit mean function is also called generalized least squares (GLS). There are two good properties of GPR. First, GPR can handle the noise in the sample data. Second, the model not only provides the interpolated value, but also the uncertainty of the prediction. These properties can be particularly useful in engineering applications - if there is time, this matter will be explained. The idea of GPR is simple. It assumes that all data points are sampled from a Gaussian process, and therefore these points subject to a joint Gaussian distribution. The new data point should subject to a Gaussian distribution as well, determined by the training data. In that Gaussian distribution, the mean becomes the prediction, and the variance becomes the error estimation. In this article, the derivation of GPR will be presented, with some discussion in computational aspects. Most of the materials are based on the GPML book (for derivation) and the manual of the DACE toolbox (for computation). The DACE manual also provides the derivation from the pointview of GLS. Derivation The basic form Assume the unknown function subjects to a GP, f(x)&#x223C;GP(m(x),k(x,x&#x2032;))\\displaystyle f({\\mathbf{x}}) \\sim {\\mathcal{GP}}(m({\\mathbf{x}}),k({\\mathbf{x}},{\\mathbf{x}}&apos;)) f(x)&#x223C;GP(m(x),k(x,x&#x200B;&#x2032;&#x200B;&#x200B;)) where m(x)m({\\mathbf{x}})m(x) is the mean function and k(x,x&#x2032;)k({\\mathbf{x}},{\\mathbf{x}}&apos;)k(x,x&#x200B;&#x2032;&#x200B;&#x200B;) is the covariance function. By definition, they satisfies, m(x)=E[f(x)]k(x,x&#x2032;)=E[(f(x)&#x2212;m(x))(f(x&#x2032;)&#x2212;m(x&#x2032;))]\\displaystyle \\begin{aligned} m({\\mathbf{x}}) &amp;= \\mathrm{E}[f({\\mathbf{x}})] \\\\ k({\\mathbf{x}},{\\mathbf{x}}&apos;) &amp;= \\mathrm{E}[(f({\\mathbf{x}})-m({\\mathbf{x}}))(f({\\mathbf{x}}&apos;)-m({\\mathbf{x}}&apos;))] \\end{aligned} &#x200B;m(x)&#x200B;k(x,x&#x200B;&#x2032;&#x200B;&#x200B;)&#x200B;&#x200B;&#x200B;=E[f(x)]&#x200B;=E[(f(x)&#x2212;m(x))(f(x&#x200B;&#x2032;&#x200B;&#x200B;)&#x2212;m(x&#x200B;&#x2032;&#x200B;&#x200B;))]&#x200B;&#x200B; The probabilistic distribution of a set of points D={X,y}{\\mathcal{D}}=\\{ {\\mathbf{X}},{\\mathbf{y}}\\}D={X,y} sampled from GP is Gaussian, y&#x223C;N(m,K)\\displaystyle {\\mathbf{y}}\\sim{\\mathcal{N}}({\\mathbf{m}},{\\mathbf{K}}) y&#x223C;N(m,K) where [m]i=m(Xi)[{\\mathbf{m}}]_i=m({\\mathbf{X}}_i)[m]&#x200B;i&#x200B;&#x200B;=m(X&#x200B;i&#x200B;&#x200B;) and [K]ij=k(Xi,Xj)[{\\mathbf{K}}]_{ij}=k({\\mathbf{X}}_i,{\\mathbf{X}}_j)[K]&#x200B;ij&#x200B;&#x200B;=k(X&#x200B;i&#x200B;&#x200B;,X&#x200B;j&#x200B;&#x200B;). Here the input variable X{\\mathbf{X}}X can be a matrix with each row being one sample, but only scalar output is considered for now. Now slipt the points into two sets: the training set Xs{\\mathbf{X}}_sX&#x200B;s&#x200B;&#x200B; with known output ys{\\mathbf{y}}_sy&#x200B;s&#x200B;&#x200B;, and the target set Xu{\\mathbf{X}}_uX&#x200B;u&#x200B;&#x200B; with unknown output ys{\\mathbf{y}}_sy&#x200B;s&#x200B;&#x200B;. The joint distribution is still Gaussian, with the following mean, mT=[m(Xs)T,m(Xu)T]&#x2261;[msT,muT]\\displaystyle {\\mathbf{m}}^T = [{\\mathbf{m}}({\\mathbf{X}}_s)^T, {\\mathbf{m}}({\\mathbf{X}}_u)^T] \\equiv [{\\mathbf{m}}_s^T, {\\mathbf{m}}_u^T] m&#x200B;T&#x200B;&#x200B;=[m(X&#x200B;s&#x200B;&#x200B;)&#x200B;T&#x200B;&#x200B;,m(X&#x200B;u&#x200B;&#x200B;)&#x200B;T&#x200B;&#x200B;]&#x2261;[m&#x200B;s&#x200B;T&#x200B;&#x200B;,m&#x200B;u&#x200B;T&#x200B;&#x200B;] and the block covariance matrix, K=[KssKsuKusKuu]\\displaystyle {\\mathbf{K}}= \\begin{bmatrix} {\\mathbf{K}}_{ss} &amp; {\\mathbf{K}}_{su} \\\\ {\\mathbf{K}}_{us} &amp; {\\mathbf{K}}_{uu} \\end{bmatrix} K=[&#x200B;K&#x200B;ss&#x200B;&#x200B;&#x200B;K&#x200B;us&#x200B;&#x200B;&#x200B;&#x200B;&#x200B;K&#x200B;su&#x200B;&#x200B;&#x200B;K&#x200B;uu&#x200B;&#x200B;&#x200B;&#x200B;] where the i,ji,ji,jth element of K{\\mathbf{K}}K is associated with the iiith and jjjth rows of X{\\mathbf{X}}X, [Kab]ij=k([Xa]i,[Xb]j)\\displaystyle [{\\mathbf{K}}_{ab}]_{ij} = k([{\\mathbf{X}}_a]_i, [{\\mathbf{X}}_b]_j) [K&#x200B;ab&#x200B;&#x200B;]&#x200B;ij&#x200B;&#x200B;=k([X&#x200B;a&#x200B;&#x200B;]&#x200B;i&#x200B;&#x200B;,[X&#x200B;b&#x200B;&#x200B;]&#x200B;j&#x200B;&#x200B;) In the case that ys{\\mathbf{y}}_sy&#x200B;s&#x200B;&#x200B; is noisy, a white noise term with variance &#x3C3;n2\\sigma_n^2&#x3C3;&#x200B;n&#x200B;2&#x200B;&#x200B; is added to the Gaussian distribution, adding a diagonal matrix to Kss{\\mathbf{K}}_{ss}K&#x200B;ss&#x200B;&#x200B; Ky=Kss+&#x3C3;n2Iss\\displaystyle {\\mathbf{K}}_y = {\\mathbf{K}}_{ss} + \\sigma_n^2 {\\mathbf{I}}_{ss} K&#x200B;y&#x200B;&#x200B;=K&#x200B;ss&#x200B;&#x200B;+&#x3C3;&#x200B;n&#x200B;2&#x200B;&#x200B;I&#x200B;ss&#x200B;&#x200B; The distribution of yu{\\mathbf{y}}_uy&#x200B;u&#x200B;&#x200B; given ys{\\mathbf{y}}_sy&#x200B;s&#x200B;&#x200B; is found by conditional probability, yu&#x2223;ys&#x223C;N(mp,Kp)\\displaystyle {\\mathbf{y}}_u|{\\mathbf{y}}_s \\sim {\\mathcal{N}}({\\mathbf{m}}_p, {\\mathbf{K}}_p) y&#x200B;u&#x200B;&#x200B;&#x2223;y&#x200B;s&#x200B;&#x200B;&#x223C;N(m&#x200B;p&#x200B;&#x200B;,K&#x200B;p&#x200B;&#x200B;) where the predictive mean is, mp=mu&#x2212;KusKy&#x2212;1(ys&#x2212;ms)\\displaystyle {\\mathbf{m}}_p = {\\mathbf{m}}_u - {\\mathbf{K}}_{us}{\\mathbf{K}}_y^{-1}({\\mathbf{y}}_s-{\\mathbf{m}}_s) m&#x200B;p&#x200B;&#x200B;=m&#x200B;u&#x200B;&#x200B;&#x2212;K&#x200B;us&#x200B;&#x200B;K&#x200B;y&#x200B;&#x2212;1&#x200B;&#x200B;(y&#x200B;s&#x200B;&#x200B;&#x2212;m&#x200B;s&#x200B;&#x200B;) and the covariance is, Kp=Kuu&#x2212;KusKy&#x2212;1Ksu\\displaystyle {\\mathbf{K}}_p = {\\mathbf{K}}_{uu} - {\\mathbf{K}}_{us}{\\mathbf{K}}_y^{-1}{\\mathbf{K}}_{su} K&#x200B;p&#x200B;&#x200B;=K&#x200B;uu&#x200B;&#x200B;&#x2212;K&#x200B;us&#x200B;&#x200B;K&#x200B;y&#x200B;&#x2212;1&#x200B;&#x200B;K&#x200B;su&#x200B;&#x200B; Using basis functions for the mean function The form of mean function is usually unknown beforehand, so it is more common to use a set of basis functions, m(x)=h(x)Tb\\displaystyle m({\\mathbf{x}}) = {\\mathbf{h}}({\\mathbf{x}})^T{\\mathcal{b}}m(x)=h(x)&#x200B;T&#x200B;&#x200B;b The coefficients b{\\mathcal{b}}b have to be fitted from the sample data. Under a Bayesian framework, b{\\mathcal{b}}b is assumed to subject to, b&#x223C;N(b,B)\\displaystyle {\\mathcal{b}}\\sim {\\mathcal{N}}({\\mathbf{b}}, {\\mathbf{B}}) b&#x223C;N(b,B) Taking b{\\mathcal{b}}b into account, the GP from previous section is modified as, f(x)&#x223C;GP(h(x)Tb,k(x,x&#x2032;)+h(x)TBh(x))\\displaystyle f({\\mathbf{x}}) \\sim {\\mathcal{GP}}({\\mathbf{h}}({\\mathbf{x}})^T{\\mathbf{b}},k({\\mathbf{x}},{\\mathbf{x}}&apos;)+{\\mathbf{h}}({\\mathbf{x}})^T{\\mathbf{B}}{\\mathbf{h}}({\\mathbf{x}})) f(x)&#x223C;GP(h(x)&#x200B;T&#x200B;&#x200B;b,k(x,x&#x200B;&#x2032;&#x200B;&#x200B;)+h(x)&#x200B;T&#x200B;&#x200B;Bh(x)) Extra terms due to the basis functions shall be added to the covariance matrix, Kab=K(Xa,Xb)+HaBHbT,[H&#x2217;]i=h([X&#x2217;]i)T\\displaystyle {\\mathbf{K}}_{ab} = {\\mathbf{K}}({\\mathbf{X}}_a, {\\mathbf{X}}_b) + {\\mathbf{H}}_a {\\mathbf{B}}{\\mathbf{H}}_b^T,\\quad [{\\mathbf{H}}_*]_i={\\mathbf{h}}([{\\mathbf{X}}_*]_i)^T K&#x200B;ab&#x200B;&#x200B;=K(X&#x200B;a&#x200B;&#x200B;,X&#x200B;b&#x200B;&#x200B;)+H&#x200B;a&#x200B;&#x200B;BH&#x200B;b&#x200B;T&#x200B;&#x200B;,[H&#x200B;&#x2217;&#x200B;&#x200B;]&#x200B;i&#x200B;&#x200B;=h([X&#x200B;&#x2217;&#x200B;&#x200B;]&#x200B;i&#x200B;&#x200B;)&#x200B;T&#x200B;&#x200B; The extra terms make the predictive mean and covariance from the previous section extremely cumbersome to compute. Simplifications are needed and enabled by invoking the matrix inversion lemma, (A+UCVT)&#x2212;1=A&#x2212;1&#x2212;A&#x2212;1U(C&#x2212;1+VTA&#x2212;1U)&#x2212;1VTA&#x2212;1\\displaystyle ({\\mathbf{A}}+{\\mathbf{U}}{\\mathbf{C}}{\\mathbf{V}}^T)^{-1} = {\\mathbf{A}}^{-1} - {\\mathbf{A}}^{-1}{\\mathbf{U}}({\\mathbf{C}}^{-1}+{\\mathbf{V}}^T{\\mathbf{A}}^{-1}{\\mathbf{U}})^{-1} {\\mathbf{V}}^T{\\mathbf{A}}^{-1} (A+UCV&#x200B;T&#x200B;&#x200B;)&#x200B;&#x2212;1&#x200B;&#x200B;=A&#x200B;&#x2212;1&#x200B;&#x200B;&#x2212;A&#x200B;&#x2212;1&#x200B;&#x200B;U(C&#x200B;&#x2212;1&#x200B;&#x200B;+V&#x200B;T&#x200B;&#x200B;A&#x200B;&#x2212;1&#x200B;&#x200B;U)&#x200B;&#x2212;1&#x200B;&#x200B;V&#x200B;T&#x200B;&#x200B;A&#x200B;&#x2212;1&#x200B;&#x200B; In current case, the lemma is applied as follows, (Ky+HBHT)&#x2212;1=Ky&#x2212;1&#x2212;Ky&#x2212;1HC&#x2212;1HTKy&#x2212;1&#x2261;Ky&#x2212;1&#x2212;A\\displaystyle ({\\mathbf{K}}_y + {\\mathbf{H}}{\\mathbf{B}}{\\mathbf{H}}^T)^{-1} = {\\mathbf{K}_y^{-1}}-{\\mathbf{K}_y^{-1}}{\\mathbf{H}}{\\mathbf{C}}^{-1} {\\mathbf{H}}^T {\\mathbf{K}_y^{-1}}\\equiv {\\mathbf{K}_y^{-1}}-{\\mathbf{A}}(K&#x200B;y&#x200B;&#x200B;+HBH&#x200B;T&#x200B;&#x200B;)&#x200B;&#x2212;1&#x200B;&#x200B;=K&#x200B;y&#x200B;&#x2212;1&#x200B;&#x200B;&#x2212;K&#x200B;y&#x200B;&#x2212;1&#x200B;&#x200B;HC&#x200B;&#x2212;1&#x200B;&#x200B;H&#x200B;T&#x200B;&#x200B;K&#x200B;y&#x200B;&#x2212;1&#x200B;&#x200B;&#x2261;K&#x200B;y&#x200B;&#x2212;1&#x200B;&#x200B;&#x2212;A where C=B&#x2212;1+HTKy&#x2212;1H{\\mathbf{C}}={\\mathbf{B}}^{-1} + {\\mathbf{H}}^T {\\mathbf{K}_y^{-1}}{\\mathbf{H}}C=B&#x200B;&#x2212;1&#x200B;&#x200B;+H&#x200B;T&#x200B;&#x200B;K&#x200B;y&#x200B;&#x2212;1&#x200B;&#x200B;H and the subscript sss is dropped in Hs{\\mathbf{H}}_sH&#x200B;s&#x200B;&#x200B;. Furthermore, the following identities can be derived, BHT(Ky&#x2212;1&#x2212;A)=C&#x2212;1HTKy&#x2212;1(Ky&#x2212;1&#x2212;A)HB=Ky&#x2212;1HC&#x2212;1\\displaystyle \\begin{aligned} {\\mathbf{B}}{\\mathbf{H}}^T({\\mathbf{K}_y^{-1}}-{\\mathbf{A}}) &amp;= {\\mathbf{C}}^{-1}{\\mathbf{H}}^T{\\mathbf{K}_y^{-1}}\\\\ ({\\mathbf{K}_y^{-1}}-{\\mathbf{A}}){\\mathbf{H}}{\\mathbf{B}}&amp;= {\\mathbf{K}_y^{-1}}{\\mathbf{H}}{\\mathbf{C}}^{-1} \\end{aligned} &#x200B;BH&#x200B;T&#x200B;&#x200B;(K&#x200B;y&#x200B;&#x2212;1&#x200B;&#x200B;&#x2212;A)&#x200B;(K&#x200B;y&#x200B;&#x2212;1&#x200B;&#x200B;&#x2212;A)HB&#x200B;&#x200B;&#x200B;=C&#x200B;&#x2212;1&#x200B;&#x200B;H&#x200B;T&#x200B;&#x200B;K&#x200B;y&#x200B;&#x2212;1&#x200B;&#x200B;&#x200B;=K&#x200B;y&#x200B;&#x2212;1&#x200B;&#x200B;HC&#x200B;&#x2212;1&#x200B;&#x200B;&#x200B;&#x200B; The simplification procedure is bascally to cancel out matrices by combining the H{\\mathbf{H}}H and (Ky&#x2212;1&#x2212;A)({\\mathbf{K}_y^{-1}}-{\\mathbf{A}})(K&#x200B;y&#x200B;&#x2212;1&#x200B;&#x200B;&#x2212;A) terms. The predictive mean is simplified to, mp&#x2217;=Hub+(Kus+HuBHT)(Ky+HBHT)&#x2212;1(ys&#x2212;Hb)=KusKy&#x2212;1ys+DTC&#x2212;1(HTKy&#x2212;1ys+B&#x2212;1b)\\displaystyle \\begin{aligned} {\\mathbf{m}}_p^* &amp;= {\\mathbf{H}}_u{\\mathbf{b}}+ ({\\mathbf{K}}_{us} + {\\mathbf{H}}_u{\\mathbf{B}}{\\mathbf{H}}^T)({\\mathbf{K}}_y + {\\mathbf{H}}{\\mathbf{B}}{\\mathbf{H}}^T)^{-1}({\\mathbf{y}}_s-{\\mathbf{H}}{\\mathbf{b}}) \\\\ &amp;= {\\mathbf{K}}_{us}{\\mathbf{K}_y^{-1}}{\\mathbf{y}}_s + {\\mathbf{D}}^T {\\mathbf{C}}^{-1} ({\\mathbf{H}}^T {\\mathbf{K}_y^{-1}}{\\mathbf{y}}_s + {\\mathbf{B}}^{-1}{\\mathbf{b}}) \\end{aligned} &#x200B;m&#x200B;p&#x200B;&#x2217;&#x200B;&#x200B;&#x200B;&#x200B;&#x200B;&#x200B;=H&#x200B;u&#x200B;&#x200B;b+(K&#x200B;us&#x200B;&#x200B;+H&#x200B;u&#x200B;&#x200B;BH&#x200B;T&#x200B;&#x200B;)(K&#x200B;y&#x200B;&#x200B;+HBH&#x200B;T&#x200B;&#x200B;)&#x200B;&#x2212;1&#x200B;&#x200B;(y&#x200B;s&#x200B;&#x200B;&#x2212;Hb)&#x200B;=K&#x200B;us&#x200B;&#x200B;K&#x200B;y&#x200B;&#x2212;1&#x200B;&#x200B;y&#x200B;s&#x200B;&#x200B;+D&#x200B;T&#x200B;&#x200B;C&#x200B;&#x2212;1&#x200B;&#x200B;(H&#x200B;T&#x200B;&#x200B;K&#x200B;y&#x200B;&#x2212;1&#x200B;&#x200B;y&#x200B;s&#x200B;&#x200B;+B&#x200B;&#x2212;1&#x200B;&#x200B;b)&#x200B;&#x200B; where D=HuT&#x2212;HTKy&#x2212;1Ksu{\\mathbf{D}}={\\mathbf{H}}_u^T-{\\mathbf{H}}^T {\\mathbf{K}_y^{-1}}{\\mathbf{K}}_{su}D=H&#x200B;u&#x200B;T&#x200B;&#x200B;&#x2212;H&#x200B;T&#x200B;&#x200B;K&#x200B;y&#x200B;&#x2212;1&#x200B;&#x200B;K&#x200B;su&#x200B;&#x200B;. The covariance matrix is simplied to, Kp&#x2217;=Kuu+HuBHuT&#x2212;(Kus+HuBHT)(Ky+HBHT)&#x2212;1(Ksu+HBHuT)=Kp+DTC&#x2212;1D\\displaystyle \\begin{aligned} {\\mathbf{K}}_p^* &amp;= {\\mathbf{K}}_{uu} + {\\mathbf{H}}_u{\\mathbf{B}}{\\mathbf{H}}_u^T - ({\\mathbf{K}}_{us}+{\\mathbf{H}}_u{\\mathbf{B}}{\\mathbf{H}}^T) ({\\mathbf{K}}_y + {\\mathbf{H}}{\\mathbf{B}}{\\mathbf{H}}^T)^{-1} ({\\mathbf{K}}_{su}+{\\mathbf{H}}{\\mathbf{B}}{\\mathbf{H}}_u^T) \\\\ &amp;= {\\mathbf{K}}_p + {\\mathbf{D}}^T {\\mathbf{C}}^{-1} {\\mathbf{D}}\\end{aligned} &#x200B;K&#x200B;p&#x200B;&#x2217;&#x200B;&#x200B;&#x200B;&#x200B;&#x200B;&#x200B;=K&#x200B;uu&#x200B;&#x200B;+H&#x200B;u&#x200B;&#x200B;BH&#x200B;u&#x200B;T&#x200B;&#x200B;&#x2212;(K&#x200B;us&#x200B;&#x200B;+H&#x200B;u&#x200B;&#x200B;BH&#x200B;T&#x200B;&#x200B;)(K&#x200B;y&#x200B;&#x200B;+HBH&#x200B;T&#x200B;&#x200B;)&#x200B;&#x2212;1&#x200B;&#x200B;(K&#x200B;su&#x200B;&#x200B;+HBH&#x200B;u&#x200B;T&#x200B;&#x200B;)&#x200B;=K&#x200B;p&#x200B;&#x200B;+D&#x200B;T&#x200B;&#x200B;C&#x200B;&#x2212;1&#x200B;&#x200B;D&#x200B;&#x200B; Finally, consider the case that the coefficients are distributed uniformly, instead of Gaussian. That means b&#x2192;0{\\mathbf{b}}\\rightarrow\\mathrm{0}b&#x2192;0 and B&#x2212;1&#x2192;O{\\mathbf{B}}^{-1}\\rightarrow {\\mathbf{O}}B&#x200B;&#x2212;1&#x200B;&#x200B;&#x2192;O. With that, we arrive at the commonly used form of GPR, mp&#x2217;=KusKy&#x2212;1ys+DT(HTKy&#x2212;1H)&#x2212;1HKy&#x2212;1ys=Kusg&#xAF;+Hub&#xAF;Kp&#x2217;=Kp+DT(HTKy&#x2212;1H)&#x2212;1D\\displaystyle \\begin{aligned} {\\mathbf{m}}_p^* &amp;= {\\mathbf{K}}_{us}{\\mathbf{K}_y^{-1}}{\\mathbf{y}}_s + {\\mathbf{D}}^T ({\\mathbf{H}}^T{\\mathbf{K}_y^{-1}}{\\mathbf{H}})^{-1} {\\mathbf{H}}{\\mathbf{K}_y^{-1}}{\\mathbf{y}}_s \\\\ &amp;= {\\mathbf{K}}_{us}\\bar{\\mathbf{g}}+ {\\mathbf{H}}_u\\bar{\\mathbf{b}}\\\\ {\\mathbf{K}}_p^* &amp;= {\\mathbf{K}}_p + {\\mathbf{D}}^T ({\\mathbf{H}}^T{\\mathbf{K}_y^{-1}}{\\mathbf{H}})^{-1} {\\mathbf{D}}\\end{aligned} &#x200B;m&#x200B;p&#x200B;&#x2217;&#x200B;&#x200B;&#x200B;&#x200B;K&#x200B;p&#x200B;&#x2217;&#x200B;&#x200B;&#x200B;&#x200B;&#x200B;=K&#x200B;us&#x200B;&#x200B;K&#x200B;y&#x200B;&#x2212;1&#x200B;&#x200B;y&#x200B;s&#x200B;&#x200B;+D&#x200B;T&#x200B;&#x200B;(H&#x200B;T&#x200B;&#x200B;K&#x200B;y&#x200B;&#x2212;1&#x200B;&#x200B;H)&#x200B;&#x2212;1&#x200B;&#x200B;HK&#x200B;y&#x200B;&#x2212;1&#x200B;&#x200B;y&#x200B;s&#x200B;&#x200B;&#x200B;=K&#x200B;us&#x200B;&#x200B;&#x200B;g&#x200B;&#xAF;&#x200B;&#x200B;+H&#x200B;u&#x200B;&#x200B;&#x200B;b&#x200B;&#xAF;&#x200B;&#x200B;&#x200B;=K&#x200B;p&#x200B;&#x200B;+D&#x200B;T&#x200B;&#x200B;(H&#x200B;T&#x200B;&#x200B;K&#x200B;y&#x200B;&#x2212;1&#x200B;&#x200B;H)&#x200B;&#x2212;1&#x200B;&#x200B;D&#x200B;&#x200B; where b&#xAF;=(HTKy&#x2212;1H)&#x2212;1HTKy&#x2212;1ys\\bar{\\mathbf{b}}=({\\mathbf{H}}^T{\\mathbf{K}_y^{-1}}{\\mathbf{H}})^{-1}{\\mathbf{H}}^T{\\mathbf{K}_y^{-1}}{\\mathbf{y}}_s&#x200B;b&#x200B;&#xAF;&#x200B;&#x200B;=(H&#x200B;T&#x200B;&#x200B;K&#x200B;y&#x200B;&#x2212;1&#x200B;&#x200B;H)&#x200B;&#x2212;1&#x200B;&#x200B;H&#x200B;T&#x200B;&#x200B;K&#x200B;y&#x200B;&#x2212;1&#x200B;&#x200B;y&#x200B;s&#x200B;&#x200B; and g&#xAF;=Ky&#x2212;1(ys&#x2212;Hb&#xAF;)\\bar{\\mathbf{g}}={\\mathbf{K}_y^{-1}}({\\mathbf{y}}_s-{\\mathbf{H}}\\bar{\\mathbf{b}})&#x200B;g&#x200B;&#xAF;&#x200B;&#x200B;=K&#x200B;y&#x200B;&#x2212;1&#x200B;&#x200B;(y&#x200B;s&#x200B;&#x200B;&#x2212;H&#x200B;b&#x200B;&#xAF;&#x200B;&#x200B;). The term b&#xAF;\\bar{\\mathbf{b}}&#x200B;b&#x200B;&#xAF;&#x200B;&#x200B; is essentially the coefficients of the mean function fitted from the sample data. Also, note that some people argue that the last term in Kp&#x2217;{\\mathbf{K}}_p^*K&#x200B;p&#x200B;&#x2217;&#x200B;&#x200B; can neglected for simplicity [Sasena2002]. Computational aspects The computation of mp&#x2217;{\\mathbf{m}}_p^*m&#x200B;p&#x200B;&#x2217;&#x200B;&#x200B; and Kp&#x2217;{\\mathbf{K}}_p^*K&#x200B;p&#x200B;&#x2217;&#x200B;&#x200B; can be tricky due to the ill-conditioned matrix inversion. The strategy is to combine cholesky decomposition and QR decomposition to stabilize the inversions, i.e. Ky&#x2212;1{\\mathbf{K}}_y^{-1}K&#x200B;y&#x200B;&#x2212;1&#x200B;&#x200B; and (HTKy&#x2212;1H)&#x2212;1({\\mathbf{H}}^T{\\mathbf{K}_y^{-1}}{\\mathbf{H}})^{-1}(H&#x200B;T&#x200B;&#x200B;K&#x200B;y&#x200B;&#x2212;1&#x200B;&#x200B;H)&#x200B;&#x2212;1&#x200B;&#x200B;. For inversion of Ky{\\mathbf{K}}_yK&#x200B;y&#x200B;&#x200B;, Ky&#x2212;1x=(LLT)&#x2212;1x=L&#x2212;T(L&#x2212;1x)\\displaystyle {\\mathbf{K}_y^{-1}}{\\mathbf{x}}= ({\\mathbf{L}}{\\mathbf{L}}^T)^{-1}{\\mathbf{x}}= {\\mathbf{L}}^{-T} ({\\mathbf{L}}^{-1}{\\mathbf{x}}) K&#x200B;y&#x200B;&#x2212;1&#x200B;&#x200B;x=(LL&#x200B;T&#x200B;&#x200B;)&#x200B;&#x2212;1&#x200B;&#x200B;x=L&#x200B;&#x2212;T&#x200B;&#x200B;(L&#x200B;&#x2212;1&#x200B;&#x200B;x) where L{\\mathbf{L}}L is a lower triangular matrix, and the matrix inversion is converted to two consecutive triangular solves. To inverse HTKy&#x2212;1H{\\mathbf{H}}^T{\\mathbf{K}_y^{-1}}{\\mathbf{H}}H&#x200B;T&#x200B;&#x200B;K&#x200B;y&#x200B;&#x2212;1&#x200B;&#x200B;H, HTKy&#x2212;1H=(L&#x2212;1H)T(L&#x2212;1H)&#x2261;FTF=RTR\\displaystyle {\\mathbf{H}}^T{\\mathbf{K}_y^{-1}}{\\mathbf{H}}= ({\\mathbf{L}}^{-1}{\\mathbf{H}})^T ({\\mathbf{L}}^{-1}{\\mathbf{H}}) \\equiv {\\mathbf{F}}^T{\\mathbf{F}}= {\\mathbf{R}}^T{\\mathbf{R}}H&#x200B;T&#x200B;&#x200B;K&#x200B;y&#x200B;&#x2212;1&#x200B;&#x200B;H=(L&#x200B;&#x2212;1&#x200B;&#x200B;H)&#x200B;T&#x200B;&#x200B;(L&#x200B;&#x2212;1&#x200B;&#x200B;H)&#x2261;F&#x200B;T&#x200B;&#x200B;F=R&#x200B;T&#x200B;&#x200B;R where QR decomposition is used QR=F{\\mathbf{Q}}{\\mathbf{R}}={\\mathbf{F}}QR=F, Q{\\mathbf{Q}}Q is an orthogonal matrix, and R{\\mathbf{R}}R is an upper triangular matrix. Q{\\mathbf{Q}}Q is tall and slim, because the number of rows equals to the number of samples, while the number of columns equals to the number of basis functions. With the stabilized matrix inversion introduced above, the quantities b&#xAF;\\bar{\\mathbf{b}}&#x200B;b&#x200B;&#xAF;&#x200B;&#x200B; and g&#xAF;\\bar{\\mathbf{g}}&#x200B;g&#x200B;&#xAF;&#x200B;&#x200B; in mp&#x2217;{\\mathbf{m}}_p^*m&#x200B;p&#x200B;&#x2217;&#x200B;&#x200B; are computed as follows, b&#xAF;=(HTKy&#x2212;1H)&#x2212;1HTKy&#x2212;1ys=R&#x2212;1[QT(L&#x2212;1ys)]g&#xAF;=Ky&#x2212;1(ys&#x2212;Hb&#xAF;)=L&#x2212;T[L&#x2212;1(ys&#x2212;Hb&#xAF;)]\\displaystyle \\begin{aligned} \\bar{\\mathbf{b}}&amp;= ({\\mathbf{H}}^T{\\mathbf{K}_y^{-1}}{\\mathbf{H}})^{-1}{\\mathbf{H}}^T{\\mathbf{K}_y^{-1}}{\\mathbf{y}}_s = {\\mathbf{R}}^{-1} [{\\mathbf{Q}}^T({\\mathbf{L}}^{-1}{\\mathbf{y}}_s)] \\\\ \\bar{\\mathbf{g}}&amp;= {\\mathbf{K}_y^{-1}}({\\mathbf{y}}_s-{\\mathbf{H}}\\bar{\\mathbf{b}}) = {\\mathbf{L}}^{-T} [{\\mathbf{L}}^{-1} ({\\mathbf{y}}_s-{\\mathbf{H}}\\bar{\\mathbf{b}})] \\end{aligned} &#x200B;&#x200B;b&#x200B;&#xAF;&#x200B;&#x200B;&#x200B;&#x200B;g&#x200B;&#xAF;&#x200B;&#x200B;&#x200B;&#x200B;&#x200B;=(H&#x200B;T&#x200B;&#x200B;K&#x200B;y&#x200B;&#x2212;1&#x200B;&#x200B;H)&#x200B;&#x2212;1&#x200B;&#x200B;H&#x200B;T&#x200B;&#x200B;K&#x200B;y&#x200B;&#x2212;1&#x200B;&#x200B;y&#x200B;s&#x200B;&#x200B;=R&#x200B;&#x2212;1&#x200B;&#x200B;[Q&#x200B;T&#x200B;&#x200B;(L&#x200B;&#x2212;1&#x200B;&#x200B;y&#x200B;s&#x200B;&#x200B;)]&#x200B;=K&#x200B;y&#x200B;&#x2212;1&#x200B;&#x200B;(y&#x200B;s&#x200B;&#x200B;&#x2212;H&#x200B;b&#x200B;&#xAF;&#x200B;&#x200B;)=L&#x200B;&#x2212;T&#x200B;&#x200B;[L&#x200B;&#x2212;1&#x200B;&#x200B;(y&#x200B;s&#x200B;&#x200B;&#x2212;H&#x200B;b&#x200B;&#xAF;&#x200B;&#x200B;)]&#x200B;&#x200B; The covariance matrix is computed as follows, Kp&#x2217;=Kuu&#x2212;(L&#x2212;1Ksu)2+(R&#x2212;T[HuT&#x2212;FT(L&#x2212;1Ksu)])2\\displaystyle {\\mathbf{K}}_p^* = {\\mathbf{K}}_{uu} - ({\\mathbf{L}}^{-1}{\\mathbf{K}}_{su})^2 + ({\\mathbf{R}}^{-T} [{\\mathbf{H}}_u^T - {\\mathbf{F}}^T({\\mathbf{L}}^{-1}{\\mathbf{K}}_{su})])^2 K&#x200B;p&#x200B;&#x2217;&#x200B;&#x200B;=K&#x200B;uu&#x200B;&#x200B;&#x2212;(L&#x200B;&#x2212;1&#x200B;&#x200B;K&#x200B;su&#x200B;&#x200B;)&#x200B;2&#x200B;&#x200B;+(R&#x200B;&#x2212;T&#x200B;&#x200B;[H&#x200B;u&#x200B;T&#x200B;&#x200B;&#x2212;F&#x200B;T&#x200B;&#x200B;(L&#x200B;&#x2212;1&#x200B;&#x200B;K&#x200B;su&#x200B;&#x200B;)])&#x200B;2&#x200B;&#x200B; where (&#x25A1;)2=&#x25A1;T&#x25A1;(\\Box)^2=\\Box^T\\Box(&#x25A1;)&#x200B;2&#x200B;&#x200B;=&#x25A1;&#x200B;T&#x200B;&#x200B;&#x25A1;. Implementations for GPR There are a lot of libraries that implements GPR. Here provides a big list, which is last updated in 2011. Besides those in the list, there are four noteworthy libraries. The first one is the DACE MATLAB toolbox, which has some GLS flavor. It appears to be very popular in the engineering fields, especially those that relies on the MATLAB ecosystem heavily. The second one is the sklearn Python package. Up to version 0.17, the GPR is implemented in the gaussian_process.GaussianProcess class, as a translation of the DACE toolbox. Afterwards, the GPR is re-implemented in the gaussian_process.GaussianProcessRegressor class using the formulation in GPML. Unfortunately, the new implementation only supports zero mean function. The third library is GPy, which is a large, comprehensive repository of GP-related models. Finally, the fourth library is the GPflow, which is an elegant implementation under the TensorFlow framework with roots from GPy. Modern variants of GPR are also included, some of which will be discussed in the follow-up articles."},{"title":"Working on the Same hg Repository","permalink":"http://smanist.github.io/2017/09/18/Working-on-the-same-hg-repository/","text":"What do we do when two users need to work on the same hg repository? Problem By &#x201C;same&#x201D;, I mean the same folder in the filesystem. In the case that I encountered, I need to modify the repository on another user&#x2019;s account, directly, and do the regular commits, pulls, and pushes as if I were working on my own repository. Discussion Usually this scenario should not happen. Whenever there are two users, each user usually has his/her own repository. Modifications contributed by the two users are merged using standard version control methods. Furthermore, the ecosystem that the repository relies on should be in a shared state, e.g.&#xA0;in the /opt folder, so that the users only need to take care of the repository itself. Now, what happened is that, only the first user will be the main contributor to the repository. Moreover, the repository relies on a heavy ecosystem, which is cumbersome to setup in a new account. Yes, historically, the ecosystem is setup under the second user&#x2019;s account, and not shared by the first user. Workaround One can always do something like following to enforce the manipulation of the repository, 1sudo hg -u USER OPERATION To avoid invoking the super user privilege, add writing permissions to the files in the .hg folder of the repository. 12sudo find .hg -type d -exec chmod 757 {} \\;sudo find .hg -type f -exec chmod 646 {} \\; When the user commits any changes to the repository, the writing permission is required to modify the .hg files. Then add following information to the hgrc file in the repository 1234[paths]dev = PATH_TO_REPO[ui]username = USER &lt;USER_EMAIL&gt; Then when doing push and pull, make sure to interact with the dev repository defined in the hgrc file. 12hg push devhg pull dev In this manner, the commits are directed to the dev path under the specified user. Finally, in .hgrc file, add 12[trusted]users = trokita to avoid some annoying outputs from the commandline."},{"title":"Getting Browser History in Chrome","permalink":"http://smanist.github.io/2017/09/18/Getting-browser-history-in-chrome/","text":"I mean, through command line. It is surprisingly simple, at least in Linux. First find the location of the user profile of the Chrome browser. There is a file History that is a sqlite3 database containing all the browsing history of this user. Then, if there is no available sqlite client, install 1apt-get install sqlite3 Just make sure to use sqlite3 instead of sqlite2. The latter has been deprecated for a while. Finally, do 1sqlite3 History &quot;select datetime(last_visit_time/1000000-11644473600,&apos;unixepoch&apos;),url from urls order by last_visit_time desc&quot; &gt; history_export.txt References: one source an older source"},{"title":"SSH to a host","permalink":"http://smanist.github.io/2017/09/11/SSH-to-a-host/","text":"Some notes for setting up SSH connection to a remote computer. The most straightforward way is apparently 1ssh user@host For frequent access, it would be nice to create an alias in the .bashrc file, 1alias myssh=&apos;ssh user@host&apos; Naive connection to host would require the password of username. So a better way is to setup the public key authentication, i.e.&#xA0;a security key pair on the local and the remote computers. The steps are simple. First, run ssh-keygen to generate the private and the public keys using the specified algorithm, which by default is the RSA. Then, the public key needs to be copied to the host and installed in the authorized_keys file. One can either do it manually, or using a handy tool, 1ssh-copy-id -i path_to_key user@host Finally, scp can be used to transfer files to and from the host. The usage is just like the cp command, 12scp user@host:path_to_file_to_copy path_to_copied_filescp path_to_file_to_copy user@host:path_to_copied_file Again, for frequent access to a particular host, it would be nice to avoid user@host in the scp command. Something like below is expected, 12myscp -d path_to_file_to_copy path_to_copied_filemyscp -u path_to_file_to_copy path_to_copied_file The myscp command can be implemented as follows, 1234function myscp() { user=&quot;user@host:&quot; scpwrapper $user &quot;$@&quot;} And the scpwrapper function is defined as, 12345678910111213141516171819202122232425262728293031323334353637383940414243444546function scpwrapper() { user=$1 # Default: file from local to server opt=&quot;&quot; u1=&quot;&quot; u2=$user if [ $# -le 5 ]; then if [ &quot;$1&quot; == &quot;-h&quot; ]; then echo &quot;Wrapper for scp to a given server&quot; echo &quot; -u Upload to server&quot; echo &quot; -d Download from server&quot; echo &quot; -* Options for scp&quot; return 0 fi while [[ $# &gt; 3 ]] do key=&quot;$2&quot; case $key in -u) u1=&quot;&quot; u2=$user shift ;; -d) u1=$user u2=&quot;&quot; shift ;; *) opt=$key shift ;; esac done else echo &quot;Too many arguments&quot; echo &quot;Exiting&quot; return 1 fi f1=$2 f2=$3 echo &quot;Executing: scp $opt $u1$f1 $u2$f2&quot; scp $opt $u1$f1 $u2$f2} References: ssh-keygen RSA"},{"title":"Mosasaurus","permalink":"http://smanist.github.io/2017/08/16/Mosasaurus/","text":"The lizard from the Meuse river. There is a huge marine reptile mounted in the Havard Natural History Museum. But not to be confused with another marine reptile appeared in a recent movie. The one in the movie is Mosasaurus, which is from one of the 38 genera of Mosasaurs. Mosasaurs literally means Meuse reptile, or lizards. The Meuse river is where their first fossil remains were discovered. Recent research indicated that Mosasaurs swam like sharks and were endothermic and viviparous. The one in the museum is Kronosaurus, one genus from Pliosauroidae. The pliosaurs were short-necked plesiosaurs, as indicated by the plio prefix, and were distant cousins of modern turtles. The pliosaurs had large heads and massive toothed jaws and swum like a turtle. Interestingly, the specimen in Havard is probably reconstructed with too many vertebrae. Mosasaurus and Kronosaurus do have common relatives in the evolutionary tree. To start with, they both belong to class Sauropsida, &#x201C;lizard faces&#x201D;, including all existing birds and reptiles and their extinct relatives. Note that there is a class Reptilia for reptiles, semi-deprecated due to the advent of phylogenetic nomenclature. Then clade Eureptilia, &#x201C;true reptiles&#x201D;, characterized by two disconnected groups of bones in the skull. Then clade Diapsida, &#x201C;two arches&#x201D;, the only clade that survives through the Permian period, characterized by two holes in the skull. Then clade Neodiapsida, &#x201C;new two arches&#x201D;, including all the diapsids since the early Permian period. Finally, the clade Sauria, a crowned-group of all modern reptiles including birds (and their extinct relatives of course). Sauria divides into two clades. One is Lepidosauromorpha, &#x201C;scaled lizard forms&#x201D;, including all diapsids closer to lizards than to crocodiles and birds. The other is Archosauromorpha, &#x201C;ruling lizard forms&#x201D;, including the rest diapsids in Sauria. Mosasaurus belongs to the order Squamata, containing scaled reptiles comprising all lizards and snakes. Squamata belongs to the clade Lepidosauria under Lepidosauromorpha, &#x201C;scaled lizards&#x201D;, i.e.&#xA0;reptiles with overlapping scales. Kronosaurus under Plesiosauria belongs to clade Sauropterygia, &#x201C;lizard flippers&#x201D;, aquatic reptiles swimming with flippers. Sauropterygia belongs to the clade Pantestudines under Archosauromorpha, containing tetrapods more closely related to turtles. During the late Cretaceous period, with the extinction of the ichthyosaurs and pliosaurs, mosasaurs became the dominant marine predators. So it is a little wired that a Cretaceous creature appeared in a movie themed Jurassic period. References: A movie Skull of Eureptilia"},{"title":"The Barnstar","permalink":"http://smanist.github.io/2017/06/26/Barnstar/","text":"The five-pointed star as a popular decoration for barns and households. The star is usually called a &#x201C;Amish star&#x201D; or a &#x201C;Pennsylvania star&#x201D;, but maybe more officially the barnstar. It does originate from Pennsylvania, but it is not from the Amish culture. The story begins in the eighteenth century, in Palatinate of the Rhine, when groups of people were religiously presecuted. These people are Anabaptists, who are Christians who believe that &#x201C;baptism is only valid when the candidate confesses his or her faith in Christ and wants to be baptized&#x201D;. The Anabaptists refused to take oaths and participate in military actions or civil government because of their belief, which resulted in the presecution. The group of Anabaptists who followed Jakob Ammann is called Amish. In 1775, the german-speaking anabaptists, including the Amish and the non-Amish, immigrated to Pennsylvania to seek religious freedom. These people were referred to first using the word &#x201C;Deutsch&#x201D; by the English Colonists, and later a more collective term &#x201C;Pennsylvania Dutch&#x201D;. However, the Amish (and also the Mennonite) people, called the &#x201C;plain people&#x201D;, are quite different from the rest of the Pennsylvania Dutch people, called the &#x201C;fancy people&#x201D;. The plain people adhere to strict religious beliefs and austere dress. Some of the communities only use four colors in their life, which are considered natural, white (cloud), blue (sky), brown (dirt), and green (plants). The fancy people introduced their form of folk art style to the local culture, including the barnstar. Originally, the barnstars were meant to represent the mark of the builder. Later the symbol becames more frequently used for decoration and considered a good sign for the farmers. The star-in-circle form evolves into what is nowadays called &#x201C;hex sign&#x201D;. The misconception between the Amish and the barnstar/hex sign is driven by commercial purposes to a degree. Again, the Amish do not use the hex signs. References: Wikipedia Meanings of barnstar More on &#x201C;Amish&#x201D; star"},{"title":"Math for Hexo","permalink":"http://smanist.github.io/2017/06/08/Math-for-Hexo/","text":"The issue of type-setting Math formulae in Hexo-based GitHub site. This is more twisted than I expected. Trial 1: kramed + MathJax First, the mathjax support is needed. If not supported by the theme, mathjax can be installed by, 1npm install hexo-renderer-mathjax --save Then, the renderers for markdown and mathjax have known conflict. To resolve the issue, an alternative renderer for markdown is needed, 12npm uninstall hexo-renderer-marked --savenpm install hexo-renderer-kramed --save This solution works fine locally. However, it does not work on GitHub when it is deployed. The reason is probably that the renderer for MathJax requires the calling of external js scripts, which is banned by the GitHub for safety issues. Similar thing happened before, when this site was started. There was an external javascript that randomly generates some quotes to be displayed on the main webpage. It did not work on GitHub. Eventually, I replaced it with my own local version. Trial 2: pandoc + MathJax After some googling, I encountered with another solution based on pandoc. This is essentially using an alternative renderer for Markdown, with the hope that the Math formulae can be generated &#x201C;statically&#x201D;. 1npm install hexo-renderer-pandoc --save Some files have to be added to the theme, as indicated by the webpage above. Yet, this solution does not work for me for the same reason as the first solution. Trial 3: pandoc + KaTeX So looks like the problem is with MathJax. What about a different processor for Math formulae, like KaTeX? The support for KaTeX is straight forward, 1npm install hexo-katex --save Then add the following to _config.yml 12pandoc: mathEngine: katex And it works! It seems the Math is directly injected into the html file, so the calling of external javascript can be avoided. pandoc has a slightly different way in rendering Markdown, which introduces more flavors. For example, the newcommand in LaTeX can be enabled by adding extensions in the preamble area of the markdown file, 1variant: markdown+latex_macros Testing Inline math: x=y+1x=y+1x=y+1 Between line: xy=f\\displaystyle \\frac{x}{y}=f&#x200B;y&#x200B;&#x200B;x&#x200B;&#x200B;=f Another line Verify if the conflict is resolved: &#x222B;abf1dx\\displaystyle \\int_a^bf_1dx&#x222B;&#x200B;a&#x200B;b&#x200B;&#x200B;f&#x200B;1&#x200B;&#x200B;dx Katex supports the newcommand directives. However, using a user-defined command inside newcommand will result in an error. Additional references: Trial 1 Trial 2 Trial 3"},{"title":"Roadworkers to Aviators","permalink":"http://smanist.github.io/2017/05/27/Roadworkers_to_Pilots/","text":"A story of Chinese-Americans in the early years of American aviation. A study on the lives of Chinese railroad workers and their descendents revealed a serendipity finding that, three of the familifies are connected by the Flying Tigers. The name &#x201C;Flying Tigers&#x201D; refers to three successive organizations: The American Volunteer Group (1941-1942), The China Air Task Force (1942-1943), and The 14th Air Force (1943-). The commander is Claire Chennault. There is an exhibition on the Flying Tigers in the San Diego Air and Space Museum. In the article, the lives of six people are described. Three of them, Chin Lin Sou, Jim King, and Chan Fong, are first-generation immigrants from China. They share some characteristics. First, they are all from Guangdong, a province in southern China. This is not uncommon. A lot of Cantonese in that era took the harsh voyage to America for gold rush, or/and escape from warfares in their homeland. Then, the three are educated, which distinguishes them from the other workers. Most Chinese workers could not speak fluent English, and are led by white foremans. After the road construction, Chin became one of the pioneers of Colorado, and King ended up being a tenent farmer in California. The life of Chan were a little more twisted. He had a business in Mississipi first, but had to move to Ohio due to then hostility towards Chinese. Chan and his wife passed away in their early ages, leaving behind ten children. That is another characteristic of the three people: They have a lot of children. Not sure if that was common in that era, or was that also due to some Chinese beliefs. The other three, W. C. Chin, Bill King, and Moon Chen are the descendents. They are all graduated from college or specialized school. In particular, Chen had to earn his own tuitions due to the loss of his parents. In the Flying Tigers, Chin worked as communication officers, King was a fighter pilot. Chen was the personal representative of Chennault and flew the Hump routes. After war, Chin and King returned to their hometowns and started their local businesses. Chen stepped further. He continued to work with Chennault for airlines supporting the post-war rehabilitation of China. Later he worked with Northrop on the F-5E jet fighter program. Reference: See the links above"},{"title":"The Second Jaw of the Eels","permalink":"http://smanist.github.io/2017/05/27/Eel/","text":"Some eels possess two sets of movable jaws, so are Xenomorphs. The first set of jaw is regular one, namely oral jaw. The second set of jaw is called pharyngeal jaw. The usage of the jaw is best illustrated by this gif. Not all eels have pharyngeal jaws. The eels with this feature belong to Muraenidae, i.e.&#xA0;Moray eels. And not only eels have pharyngeal jaws. Cichlids have that too. In fact, the pharyngeal jaw structure has made cichlids one of the most diverge species of fish. As for moray eels, the pharyngeal jaw helps the eating process. Most bony fish eat by suction. However, the moray eels do not have strong muscles to create the low pressure inside their body to suck in their prey. Instead, they bite and swallow with the help of the second jaw. Maybe this is the result of evolution. The moray eels are concealed inside crevices and alcoves, which are narrow - No space for the large muscles needed for suction. The restriction of the environment induced the gill arches of the moray eels to develop into movable jaws. The function of the pharyngeal jaws in moray eels are not (re)discovered until 2007, by the work conducted people from UC Davis. The researchers found that in 1960s, similar studies have been published (but did not got popular). Another example of Stigler&#x2019;s law of eponymy. Func facts: 1. Moray eels sometimes cooperate with groupers for hunting, which is probably the only known example interspecies cooperative hunting in fish. 2. Eel swims by generating a travelling waving along its body. This enables swimming in the reversed direction. It would be fun to observe the vortex-shedding from the eel body. 3. H. R. Giger indicated that he has not studied any animals when creating the Aliens in 1979. He and the director just wanted to make it frightening. Weel, the nature always acts ahead. Reference: Pharyngeal jaw Moray eel And the linkes included in the article."},{"title":"Google Drive on Linux, A Command-line Tool","permalink":"http://smanist.github.io/2017/05/26/Google_drive_on_linux/","text":"This works on Ubuntu 12.04. As of 05/26/2017, Google has not provided a tool for Google Drive on Linux. Third party softwares have been developed to fill this gap. Some are GUI-based, such as the support added in the GNOME project and some are command-line, such as google-drive-ocamlfuse. Yet, I have no plan to upgrade to higher version of GNOME, nor spend money on the GUI tools (Some are commercial). The PPA source of google-drive-ocamlfuse seems to be non-exist. However, later I encountered with this commline-line tool drive. The tool caught my eyes immediately, because it is based on the go language. It looks neat to me to resolve an issue with a Google service using a Google product. The steps are simple: Install the go language from here Make sure to add PATH and GOPATH to the shell environment Follow the steps to install drive In particular, one needs to do, 123drive init &lt;folder_to_mount_google_drive&gt;cd &lt;folder_to_mount_google_drive&gt;drive pull One can also add a .driveignore file to ignore some files for syncronizing. Just like git or hg."},{"title":"Interesting/Useful Shell Commands/Tools","permalink":"http://smanist.github.io/2017/05/12/Interesting-shell-commands/","text":"This is a gathering of shell commands or tools that look interesting - some are amazing. The list is in alphabetical order. ag ag, the silver searcher, is a tool similar to ack. Well, I have been using grep only all the time. But indeed, ag is fast, and by default it does recursive search, returns line numbers too, and have highlighting. So I probably would migrate from grep to ag. One thing to note, since it&#x2019;s recursive, it&#x2019;s necessary to specify the scope of search. One can use -G [regexpr] for files to include, and --ignore [regexpr] to exclude some files. There is a good guide for this tool. cloc cloc stands for &#x201C;Count Lines of Code&#x201D;. Basically it analyzes given file(s)/folder, counts the lines, returns the number of lines of code, comment, and blank. Its website provides a good introduction to this tool. There are a lot of similar tools available, as listed here. cloc supports more languages than most of other ones. I used to use wc to count the sizes of my projects, which typically look like the following, 1find . -regex &quot;.*\\.\\(cc\\|h\\|py\\|pyx\\|pxd\\|txt\\)&quot; ! -regex &quot;blah&quot; ! -path &quot;blah&quot; | xargs wc -l | tail -1 I have to use find to identify the files I want to take into account, then send to wc to count lines of each file, and finally output the last line, which is the sum of all lines. With cloc, I can simply do, 1cloc . [--exclude-ext=blah] It identifies all code-related files - so I don&#x2019;t need to manually exclude files related to documentation. I use doxygen and it generates numerous html files. And it provides a summary of the code files categorized by language - provides more info than my home-made shell command. cloc can also diff codes. I have not seen this type of needs. When I need to compare different versions of my projects, version-control software is sufficient for me. fasd fasd is tool for faster access to files and directories, as described in its webpage. It is inspired by autojump, z and v. In fact, initially I wanted to write about autojump, which is a Python-based tool. Then I came across fasd, purely Shell. I prefer to use shell-based tool in shell. fasd records the places one have visited, and ranks those by &#x201C;frecency&#x201D; i.e. &#x201C;frequency+recency&#x201D;, just like webpages. Later on, it would be able to guess which place to visit when the user types in only a few letters. fasd comes with a list of aliases. Some of them are, 1234alias a=&apos;fasd -a&apos; # List all files and directories in the databasealias d=&apos;fasd -d&apos; # List only the directories in the databasealias f=&apos;fasd -f&apos; # List only the files in the databasealias z=&apos;fasd_cd -d&apos; # cd, same functionality as j in autojump My favorite is z. Suppose I have visited a place called foo/bar very frequently and recently, then wherever I am, I can do something like z fo to jump to foo/bar. fasd just estimates where I want to go most likely. For the other three, a, d, and f can be used to check the current frecency of the entries in the database. htop An enhanced version of top. It visualizes the usage of the CPU, memory, and swap. More importantly, it is interactive! One can click on the entries to sort the processes. For a lazy guy like me, it saves the trouble of memorizing the short-cuts. Its functionalities are detailed in its help. Its website is pretty cool as well. thefuck This tool corrects the previous mis-typed console command. Its awesomeness is explained by this video. I think no more explanation is needed here. tmux tmux is termed &#x201C;terminal multiplexer&#x201D;. According to its website, it lets you switch easily between several programs in one terminal, detach them and reattach them to a different terminal. However, I personally use terminator, mainly for splitting the terminal into several panes for multiple tasks. It is easy to use and can record/modify the configuration just like tmux. There is a guy switched from terminator to tmux. Following advantages of tmux are pointed out, Portability - tmux works on all systems able to handle plain, old terminal. Scriptability - tmux can be scripted, so that setting up windows and panes takes nothing more than one or two keystrokes. Server-client architecture - tmux can be used to share sessions between users. Tweaks and options - both tmux and Terminator are easy to get with, but it&#x2019;s tmux that allows to go further and offers wide range of configuration hacks. Well, the best tool is determined by the working environment, right? yapf yapf stands for &#x201C;Yet Another Python Formatter&#x201D;. As the name indicates, there are already some Python formatter out there. These formatters try to conform the Python code with the PEP8 standard. It looks like yapf uses some smarter algorithms for this purpose. Well, somehow I prefer my formatting, esp. the dictionaries and argument lists. yapf provides the identifier to avoid formatting some regions of the code, 123# yapf: disableYour code# yapf: enable This is not convenient enough. I would just continue to use pylint. you-get you-get behaves like wget. As described by its webpage, it is a &#x201C;Dumb downloader that scrapes the web&#x201D;. I have not used this one yet though. No such need yet. asciinema I ran into this when I collect materials for this post."},{"title":"The Raccoon","permalink":"http://smanist.github.io/2017/04/24/Raccoon/","text":"The names of the animal raccoon in different languages turn out to be describing the same characteristic behavior of a raccoon. That is washing. It tends to wash its food, whatever food, before eating it. Raccoon&#x2019;s scientific name is Procyon lotor, where &#x201C;Procyon&#x201D; is the genus for raccoons (meaning dog-like), and &#x201C;lotor&#x201D; is literally &#x201C;washer&#x201D;. Following is an incomplete list of languages that describe raccoons as &#x201C;washing bear&#x201D; German: waschbar, wash::bear Italian: orsetto lavatore, bear cub::washer Hungarian: mos&#xF3;medve, wash::bear Chinese: &#x6D63;&#x718A;, wash::bear Japanese: &#x30A2;&#x30E9;&#x30A4;&#x30B0;&#x30DE;, wash::bear French: raton laveur, rat::washer (well, rat&#x2026;) Portuguese: rat&#xE3;o-lavadeiro, rat::washer Even the English name, &#x201C;raccoon&#x201D;, is somewhat related to washing too. It is believed that the word is adopted from the Powhatan language in the Virginia Colony. The Powhatan word for raccoon is &#x201C;ahrah-koon-em&#x201D;, which means &#x201C;[the] one who rubs, scrubs and scratches with its hands&#x201D;. So why on earth raccoons &#x201C;wash&#x201D; their food? It is due to its senses. Raccoons do not have great vision, in fact, they are thought to be color blind. On the contrary, Raccoons&#x2019; paws have excellent sense of touch. So they need to &#x201C;rub&#x201D; an object to gain more information on it, e.g.&#xA0;is it edible? Furthermore, the sensors on their paws becomes more sensitive when wet, so raccoons tend to &#x201C;wash&#x201D; their paws before sensing their food. So they looks like washing their food. References: Wikipedia Google translation"},{"title":"The Rosetta Project","permalink":"http://smanist.github.io/2017/04/19/The-rosetta-project/","text":"As the name implies, the Rosetta project is for linguistic acquisition by inferring, and hopefully mastering, the underlying structure of unfamiliar languages from translation. Posts under this project: A Vision Seen After A Rain"},{"title":"A Vision Seen After A Rain","permalink":"http://smanist.github.io/2017/04/14/A-vision-seen-after-a-rain/","text":"A translation of &#x2018;&#x96E8;&#x4E0A;&#x304C;&#x308A;&#x306B;&#x898B;&#x305F;&#x5E7B;&#x2019; by The Pillows. The Japanese version is from here. The English translation is based on this. Title translation is from wiki. Modified according to this video. Lyric Section 1 &#x30B8;&#x30E7;&#x30FC;&#x30AF;&#x306F;&#x7B11;(&#x308F;&#x3089;)&#x3046;&#x306E;&#x304C;&#x793C;&#x5100;(&#x308C;&#x3044;&#x304E;)&#x3055; To laugh at a joke is good manners &#x5446;(&#x3042;&#x304D;)&#x308C;&#x308B;&#x306A;&#x3088; &#x7B11;(&#x308F;&#x3089;)&#x3063;&#x3066;&#x3088; Don&#x2019;t be surprised, laugh &#x805E;(&#x304D;)&#x304D;&#x98FD;(&#x3042;)&#x304D;&#x3066;&#x308B;&#x3068;&#x3057;&#x3066;&#x3082; Even if you&#x2019;re sick of hearing it. &#x601D;(&#x304A;&#x3082;)&#x3063;&#x305F;&#x3088;&#x308A;&#x9060;(&#x3068;&#x304A;)&#x304F;&#x307E;&#x3067;&#x6765;(&#x304D;)&#x305F; I made it farther than I thought I would &#x524D;(&#x307E;&#x3048;)&#x3070;&#x304B;&#x308A;&#x3092;&#x898B;(&#x307F;)&#x3066;&#x305F;&#x304B;&#x3089; Just because I was only looking back &#x30AD;&#x30DF;&#x306E;&#x9854;(&#x304B;&#x304A;)&#x5FD8;(&#x308F;&#x3059;)&#x308C;&#x305F;&#x3051;&#x3069; I forgot your face but&#x2026; Section 2 &#x8DB3;&#x8DE1;(&#x3042;&#x3057;&#x3042;&#x3068;)&#x306E;&#x7121;(&#x306A;)&#x3044;&#x9053;(&#x307F;&#x3061;)&#x3092;&#x9078;(&#x3048;&#x3089;)&#x3093;&#x3067; We chose a road without footprints &#x305A;&#x3044;&#x3076;&#x3093;&#x6B69;(&#x3042;&#x308B;)&#x3044;&#x305F;&#x306A; And we walk it well. &#x5E7C;(&#x304A;&#x3055;&#x306A;)&#x3044;&#x5922;(&#x3086;&#x3081;)&#x50B7;(&#x304D;&#x305A;)&#x3064;&#x3044;&#x3066;&#x3082; Even if I realized the dream was childish &#x4ECA;(&#x3044;&#x307E;)&#x3082;&#x773A;(&#x306A;&#x304C;)&#x3081;&#x3066;&#x308B; I&#x2019;m still gazing at it &#x305D;&#x3046; &#x4F55;&#x5EA6;(&#x306A;&#x3093;&#x3069;)&#x3082; &#x305D;&#x3046; &#x4F55;&#x5EA6;(&#x306A;&#x3093;&#x3069;)&#x3082; &#x4F55;&#x5EA6;(&#x306A;&#x3093;&#x3069;)&#x3082; Over and over; over and over; again and again &#x30AD;&#x30DF;&#x3068;&#x3068;&#x3082;&#x306B; With you. Section 3 &#x5168;(&#x3059;&#x3079;)&#x3066;&#x304C;&#x5909;(&#x304B;)&#x308F;&#x308B;&#x304B;&#x3082;&#x3057;&#x308C;&#x306A;&#x3044; It might be that everything will change &#x8718;&#x86DB;(&#x304F;&#x3082;)&#x306E;&#x7CF8;(&#x3044;&#x3068;)&#x3092;&#x3088;&#x3058;&#x767B;(&#x306E;&#x307C;)&#x3063;&#x3066; We climb the spider&#x2019;s thread &#x8A8D;(&#x307F;&#x3068;)&#x3081;&#x5408;(&#x3042;)&#x3063;&#x305F;&#x50D5;(&#x307C;&#x304F;)&#x3089;&#x306F; We agreed that this &#x6642;&#x4EE3;(&#x3058;&#x3060;&#x3044;)&#x3082;&#x80CC;&#x666F;(&#x306F;&#x3044;&#x3051;&#x3044;)&#x3082;&#x305D;&#x3050;&#x308F;&#x306A;&#x3044; Age and setting didn&#x2019;t match up. &#x907A;&#x7269;(&#x3044;&#x3076;&#x3064;)&#x306A;&#x3093;&#x3060;&#x3068;&#x601D;(&#x304A;&#x3082;)&#x3044;&#x77E5;(&#x3057;)&#x3063;&#x305F; We realized our memento was &#x629C;(&#x306C;)&#x3051;&#x51FA;(&#x3060;)&#x3057;&#x305F;&#x58C1;&#x753B;(&#x3078;&#x304D;&#x304C;)&#x306E;&#x5922;(&#x3086;&#x3081;) A mural dream that slipped away. Section 4 &#x5343;&#x5E74;(&#x305B;&#x3093;&#x3048;&#x3093;)&#x5F8C;(&#x3054;)&#x306E;&#x96E8;(&#x3042;&#x3081;)&#x306B;&#x306A;&#x3063;&#x3066; After being rain for one thousand years &#x50D5;(&#x307C;&#x304F;)&#x3089;&#x306F;&#x964D;(&#x3075;)&#x308B;&#x3060;&#x308D;&#x3046; We will fall. &#x592A;&#x967D;(&#x305F;&#x3044;&#x3088;&#x3046;)&#x3068;&#x3082;&#x89E3;(&#x308F;&#x304B;)&#x308A;&#x5408;(&#x3042;)&#x3063;&#x3066; I wonder if the rainbow that comes &#x8679;(&#x306B;&#x3058;)&#x3092;&#x51FA;(&#x3060;)&#x305B;&#x308B;&#x304B;&#x306A; To understand the sun will come out. &#x53F6;(&#x304B;&#x306A;)&#x3063;&#x305F;&#x3089; &#x53F6;(&#x304B;&#x306A;)&#x3063;&#x305F;&#x3089; &#x53F6;(&#x304B;&#x306A;)&#x3063;&#x305F;&#x3089; If it comes true, if it comes true, if it comes true &#x7DBA;&#x9E97;(&#x304D;&#x308C;&#x3044;)&#x3060;&#x308D;&#x3046;&#x306A; Wouldn&#x2019;t it be beautiful Section 5 &#x8E0F;(&#x3075;)&#x307F;&#x5916;(&#x306F;&#x305A;)&#x3057;&#x305F;&#x5D16;&#x3063;&#x6DF5;(&#x304C;&#x3051;&#x3063;&#x3077;&#x3061;)&#x3067;&#x3082; Even if I lose my footing at the cliff&#x2019;s edge &#x624B;(&#x3066;)&#x3092;&#x63B4;(&#x3064;&#x304B;)&#x3093;&#x3067;&#x304F;&#x308C;&#x305F; You would catch my hand. &#x96E8;(&#x3042;&#x3081;)&#x4E0A;(&#x3042;)&#x304C;&#x308A;&#x306B;&#x898B;(&#x307F;)&#x305F;&#x5E7B;(&#x307E;&#x307C;&#x308D;&#x3057;)&#x3092; I still remember the vision &#x4ECA;(&#x3044;&#x307E;)&#x3082;&#x899A;(&#x304A;&#x307C;)&#x3048;&#x3066;&#x308B; Seen after the rain. Section 6 &#x8DB3;&#x8DE1;(&#x3042;&#x3057;&#x3042;&#x3068;)&#x306E;&#x7121;(&#x306A;)&#x3044;&#x9053;(&#x307F;&#x3061;)&#x3092;&#x9078;(&#x3048;&#x3089;)&#x3093;&#x3067; We chose a road without footprints &#x305A;&#x3044;&#x3076;&#x3093;&#x6B69;(&#x3042;&#x308B;)&#x3044;&#x305F;&#x306A; And we walk it well. &#x8352;&#x91CE;(&#x3053;&#x3046;&#x3084;)&#x306E;&#x679C;(&#x306F;)&#x3066; &#x4F55;&#x51E6;(&#x3069;&#x3053;)&#x304B;&#x306B;&#x304D;&#x3063;&#x3068; To the ends of the wastelands and beyond &#x8DB3;&#x8DE1;(&#x3042;&#x3057;&#x3042;&#x3068;)&#x6B8B;(&#x306E;&#x3053;)&#x3063;&#x3066;&#x308B; Our footprints will surely be left behind. &#x305D;&#x308C;&#x3060;&#x3051;&#x304C; &#x305D;&#x308C;&#x3060;&#x3051;&#x304C; &#x305D;&#x308C;&#x3060;&#x3051;&#x304C; And that&#x2019;s just, and that&#x2019;s just, and that&#x2019;s just &#x751F;(&#x3044;)&#x304D;&#x305F;&#x8A3C;(&#x3042;&#x304B;&#x3057;) Proof that we lived &#x305D;&#x308C;&#x3060;&#x3051;&#x304C; &#x305D;&#x308C;&#x3060;&#x3051;&#x304C; &#x305D;&#x308C;&#x3060;&#x3051;&#x304C; And that&#x2019;s just, and that&#x2019;s just, and that&#x2019;s just &#x50D5;(&#x307C;&#x304F;)&#x3089;&#x306E;&#x8A87;(&#x307B;&#x3053;)&#x308A; Our pride. Discussion Particles Let&#x2019;s start with particles. Particles &#x306F; and &#x304C; The first line is a good example of distinction between &#x306F; and &#x304C;. &gt; &#x30B8;&#x30E7;&#x30FC;&#x30AF;&#x306F;&#x7B11;&#x3046;&#x306E;&#x304C;&#x793C;&#x5100;&#x3055; In general, &#x306F; marks the topic of the context, which is more like &#x201C;Speaking of &#x2026;&#x201D;. &#x304C; marks the subject of the context. In particular, it introduces the subject that is new to the context, which is like the new operator in C++. Often, &#x304C; is also used for emphasis. In the case of the lyric, &#x306F; and &#x304C; form a subordinate clause. &#x306F; labels the subject of the subordinate, and &#x304C; the main clause. For more discussion, see this post Verb Again the fisrt line. Noticing the verb &#x7B11;&#x3046; in the subordinate. &gt; &#x30B8;&#x30E7;&#x30FC;&#x30AF;&#x306F;&#x7B11;&#x3046;&#x306E;&#x304C;&#x793C;&#x5100;&#x3055; &#x4E00;&#x6BB5;(&#x3044;&#x3061;&#x3060;&#x3093;) and &#x4E94;&#x6BB5;(&#x3054;&#x3060;&#x3093;) verbs The verbs are categorized into &#x4E00;&#x6BB5; (ru-verbs) and &#x4E94;&#x6BB5; (u-verbs) verbs based on suffixes/conjugation. They are roughly categorized as follows, 1234567if not &apos;end with -&#x308B;&apos;: &#x4E94;&#x6BB5; verbelse: if &apos;end with &#x3059;&#x308B; and &#x304F;&#x308B;&apos;: Irregular else: might be &#x4E00;&#x6BB5; verb The states of the verbs are indicated by the conjugations. There are 5 forms, which are associated with the vowels. &#x3046; form: dictionary This is the most basic form, which would appear on dictionary, and hence the name. The other conjugations are based on this form. The transformation is done by changing the ending from &#x3046;-stage to the corresponding character in other stages, and then add more suffixes if necessary. &#x3044; form: infinitive, &#x201C;to do&#x201D; &#x3042; form: negative With an &#x3042;-stage ending and an extra suffix, such as &#x306A;&#x3044;, the verb becomes its negative form. &#x3048; form: imperative/conditional With an &#x3048;-stage ending, the verb becomes imperative. Further, adding a suffix &#x3070; makes it conditional. &#x304A; form: volitional, &#x201C;Let&#x2019;s do&#x201D; Summary Form State Casual Polite &#x4E94;&#x6BB5; Positive -u -i&#x307E;&#x3059; &#x4E94;&#x6BB5; Negative -a&#x306A;&#x3044; -i&#x307E;&#x305B;&#x3093; &#x4E00;&#x6BB5; Positive -&#x308B; -&#x307E;&#x3059; &#x4E00;&#x6BB5; Negative -&#x306A;&#x3044; -&#x307E;&#x305B;&#x3093; Form Imperative Conditional Volitional &#x4E94;&#x6BB5; -e -e&#x3070; -o(&#x3046;) &#x4E00;&#x6BB5; -&#x308D; -&#x308C;&#x3070; -&#x3088;&#x3046; Exceptions: &#x4E94;&#x6BB5; verbs ending with -&#x3046; Form State Casual Polite &#x4E94;&#x6BB5; Positive -&#x3046; -&#x3044;&#x307E;&#x3059; &#x4E94;&#x6BB5; Negative -&#x308F;&#x306A;&#x3044; -&#x3044;&#x307E;&#x305B;&#x3093; &#x201C;do&#x201D; State Casual Polite Positive &#x3059;&#x308B; &#x3057;&#x307E;&#x3059; Negative &#x3057;&#x306A;&#x3044; &#x3057;&#x307E;&#x305B;&#x3093; &#x3059;&#x308B; is very useful because it can be attached to a noun and making it a verb. The conjugation of the compound verb behaves like &#x3059;&#x308B;. &#x201C;Come&#x201D; State Casual Polite Positive &#x6765;(&#x304F;)&#x308B; &#x6765;(&#x304D;)&#x307E;&#x3059; Negative &#x6765;(&#x3053;)&#x306A;&#x3044; &#x6765;(&#x304D;)&#x307E;&#x305B;&#x3093; &#x201C;Exist&#x201D; State Casual Polite Positive &#x3042;&#x308B; &#x3042;&#x308A;&#x307E;&#x3059; Negative &#x306A;&#x3044; &#x3042;&#x308A;&#x307E;&#x305B;&#x3093; For more discussion, see this and this Updated on 04/30/17. To be continued."},{"title":"Configuring a Hexo-based blog","permalink":"http://smanist.github.io/2017/03/25/Configuring-a-Hexo-based-blog/","text":"Now let&#x2019;s customize the blog. Picking a theme A lot of themes are available from here. The theme currently used in this blog is MaterialFlow by kevintan. The installation and basic configuration of MaterialFlow is straight forward, as described in its GitHub page. Adding a widget A widget can be a container of tags, categories, friendly links, etc. This reference provides a good discussion on adding widgets to the blog. The widgets are stored in &lt;blog&gt;/theme/&lt;your theme&gt;/layout/_widget. To enable a widget, add several lines to the _config.yml in the theme folder, 12widgets:- &lt;your widget&gt; In MaterialFlow, this specification of widgets is modularized, and described in a seperate file widgets.yml Adding a page A page is an important building block of a Hexo-based blog. For example, to enable the &#x201C;Category&#x201D; widget, one needs to generate a page, 1hexo new page categories which generates a folder source\\categories and a file index.md under that folder. Further, modify this file 123title: Categoriesdate: &lt;date time&gt;type: &quot;categories&quot; Same procedure for generating a page for &#x201C;Tagcloud&#x201D;, &#x201C;About&#x201D;, etc. Enable comments using Disqus The procedure is well described in this article. All one needs to do is to get a disqus account, and generate a shortname for the blog, then in the main _config.yml file, add 1disqus_shortname: &lt;your short name&gt; Tips for Markdown To add categories and tags, in the title section, add, 12categories: &lt;your category&gt;tags: &lt;your tags&gt; To make a partial display of the article content, i.e. &#x201C;Read more&#x201D;, on the main site, add 1&lt;!-- more --&gt; before the contents to be hidden from the main site in the Markdown file. To disable comments, in the title section, add, 1comments: false Additional reference: Configuring Hexo"},{"title":"Setting up a blog using Hexo","permalink":"http://smanist.github.io/2017/03/22/Setting-up-a-blog-using-Hexo/","text":"This applies to Windows 10 and Ubuntu 12.04. Step 1: A GitHub repository for the website On GitHub, create a repository 1&lt;yourname&gt;.github.io Make sure the .gitignore type is Node. Step 2: Setup the Node.js environment Install Node.js. Then install necessary component: 1npm install -g hexo-cli Step 3: Setup the website Initialize local folder Then, in a given folder, initialize the website 1hexo init [folder] In this folder, install a module for commiting to GitHub. Be sure to add --save so that the module is installed inside this folder and can be used by the server. 1npm install hexo-deployer-git --save Basic configurations for the website Modify the configuration file The site section The deployment section, e.g. 1234deploy: type: git repo: https://github.com/&lt;yourname&gt;/&lt;yourname&gt;.github.io.git branch: master An alternative for repo is 1repo: git@github.com:&lt;yourname&gt;/&lt;yourname&gt;.github.io.git In my case, the https works for Win10, while the git version works for Ubuntu. Editing the website locally To generate and check the website locally 123hexo cleanhexo generatehexo server And the website is hosted on 1https://localhost:4000 More info: Generating Server To add a new article 1hexo new [title] Then modify the corresponding .md file in source/_posts. More info: Writing Step 4: Deployment on GitHub To deploy 1hexo deploy More info: Deployment Step 5: Version control (Optional) Deployment only pushes the generated contents (the public folder) to GitHub, not the source files. To work on multiple machines, it is beneficial to create an online repository. In this repository, some folders do not have to be tracked: public and db.json: Generated automatically every time before deployment. node_modules: Quite large, and not all are necessary. One can repeat Step 3 to create these modules. .deploy_git: Not essential. It can be generated every time hexo deploys the website. An issue might be the slowness due to a large website. Other useful links: Hexo documentation troubleshooting and GitHub References zhangslob.github"},{"title":"Meeting with Program Managers","permalink":"http://smanist.github.io/1020/05/03/Meeting-with-program-managers/","text":"Talking to a special kind of people. Based on a talk by JM. Finally, the new font in emacs is set by 1(set-face-attribute &apos;default nil :font [FONTNAME])"}]}